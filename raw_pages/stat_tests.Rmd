# Simple statistical tests {.tabset .tabset-fade}

<!-- ======================================================= -->

## Overview {.tabset .tabset-fade .tabset-pills}

This tab demonstrates the use of **gtstummary** and regression packages to 
look at associations between variables (e.g. odds ratios, risk ratios and hazard
ratios)

1.  Univariate: two-by-two tables 
2.  Stratified: mantel-haenszel estimates 
3.  Multivariable: variable selection, model selection, final table
4.  Forest plot


<!-- ======================================================= -->

## Preparation {.tabset .tabset-fade .tabset-pills}
<h2>

Preparation

</h2>

### Packages

This code chunk shows the loading of packages required for the analyses.

```{r}
pacman::p_load(rio,          # File import
               here,         # File locator
               tidyverse,    # data management + ggplot2 graphics, 
               stringr,      # manipulate text strings 
               purrr,        # loop over objects in a tidy way
               gtsummary,    # summary statistics and tests 
               broom,        # tidy up results from regressions
               parameters,   # alternative to tidy up results from regressions
               see
               )
```

### Load data

The example dataset used in this section:

-   Linelist of individual cases from a simulated epidemic

The dataset is imported using the `import()` function from the *rio* package. See the *page on importing data* for various ways to import data.

```{r echo=F}
# import the linelist into R
linelist <- rio::import(here::here("data", "linelist_cleaned.rds"))

```

```{r eval=F}
# import the linelist
linelist <- rio::import("linelist_cleaned.xlsx")
```

The first 50 rows of the linelist are displayed below.

```{r, message=FALSE, echo=F}
# display the linelist data as a table
DT::datatable(head(linelist, 50), rownames = FALSE, filter="top", options = list(pageLength = 5, scrollX=T) )
```

### Clean data

```{r}

## make sure that age variable is numeric 
linelist <- linelist %>% 
  mutate(age = as.numeric(age))

## define variables of interest 
explanatory_vars <- c("gender", "fever", "chills", "cough", "aches", "vomit")

## make dichotomous variables in to 0/1 
linelist <- linelist %>% 
  mutate(
    ## for each of the variables listed
    across(
      all_of(c(explanatory_vars, "outcome")), 
      ## recode male, yes and death to 1; female, no and recover to 0
      ## otherwise set to missing
           ~case_when(
             . %in% c("m", "yes", "Death")   ~ 1,
             . %in% c("f", "no",  "Recover") ~ 0, 
             TRUE ~ NA_real_
           ))
  )

## add in age_category to the explanatory vars 
explanatory_vars <- c(explanatory_vars, "age_cat")

## drop rows with missing information for variables of interest 
linelist <- linelist %>% 
  drop_na(any_of(c("outcome", explanatory_vars)))

```

<!-- ======================================================= -->

## Univariate {.tabset .tabset-fade .tabset-pills}

There are two options for doing univariate analysis. 
You can use the `gtsummary` package or you can use the individual regression 
functions available in `base` together with the `broom` package. 

<!-- ======================================================= -->

### `gtsummary` package {.tabset .tabset-fade .tabset-pills}

```{r odds_gt}

univ_tab <- linelist %>% 
  ## select variables of interest
  select(explanatory_vars, outcome) %>% 
  ## produce univariate table
  tbl_uvregression(
    ## define regression want to run (generalised linear model)
    method = glm, 
    ## define outcome variable
    y = outcome, 
    ## define what type of glm want to run (logistic)
    method.args = list(family = binomial), 
    ## exponentiate the outputs to produce odds ratios (rather than log odds)
    exponentiate = TRUE
    )

## view univariate results table 
univ_tab
```


<!-- ======================================================= -->

### `base` {.tabset .tabset-fade .tabset-pills}

Using the `glm` function from the **stats** package (part of base R), you can 
produce odds ratios. 

For a single exposure variable, pass the names to `glm` and then use `tidy` from 
the **broom** package to get the exponentiated odds ratio estimates and confidence
intervals. Here we demonstrate how to combine model outputs with a table of 
counts. 

```{r odds_base_single}

model <- glm(
  ## define the variables of interest
  outcome ~ age_cat, 
  ## define the type of regression (logistic)
  family = "binomial", 
  ## define your dataset
  data = linelist) %>% 
  ## clean up the outputs of the regression (exponentiate and produce CIs)
  tidy(
      exponentiate = TRUE, 
      conf.int = TRUE)


linelist %>% 
  ## get counts of variable of interest grouped by outcome
  group_by(outcome) %>% 
  count(age_cat) %>% 
  ## spread to wide format (as in cross-tabulation)
  pivot_wider(names_from = outcome, values_from = n) %>% 
  ## drop rows with missings
  filter(!is.na(age_cat)) %>% 
  ## merge with the outputs of the regression 
  bind_cols(., model) %>% 
  ## only keep columns interested in 
  select(term, 2:3, estimate, conf.low, conf.high, p.value)


```


To run over several exposure variables to produce univariate odds ratios (i.e. 
not controlling for each other), you can pass a vector of variable names to the 
`map` function in the **purrr** package. This will loop over each of the variables
running regressions for each one. 

```{r odds_base_multiple}

models <- explanatory_vars %>% 
  ## combine each name of the variables of interest with the name of outcome variable
  str_c("outcome ~ ", .) %>% 
  ## for each string above (outcome ~ "variable of interest)
  map(
    ## run a general linear model 
    ~glm(
      ## define formula as each of the strings above
      as.formula(.x), 
      ## define type of glm (logistic)
      family = "binomial", 
      ## define your dataset
      data = linelist)
  ) %>% 
  ## for each of the output regressions from above 
  map(
    ## tidy the output
    ~tidy(
      ## each of the regressions 
      .x, 
      ## exponentiate and produce CIs
      exponentiate = TRUE, 
      conf.int = TRUE)
  ) %>% 
  ## collapse the list of regressions outputs in to one data frame
  bind_rows()



## for each explanatory variable
univ_tab_base <- map(explanatory_vars, 
      ~{linelist %>% 
          ## group data set by outcome
          group_by(outcome) %>% 
          ## produce counts for variable of interest
          count(.data[[.x]]) %>% 
          ## spread to wide format (as in cross-tabulation)
          pivot_wider(names_from = outcome, values_from = n) %>% 
          ## drop rows with missings
          filter(!is.na(.data[[.x]])) %>% 
          ## change the variable of interest column to be called "variable"
          rename("variable" = .x) %>% 
          ## change the variable of interest column to be a character 
          ## otherwise non-dichotomous (categorical) variables come out as factor and cant be merged
          mutate(variable = as.character(variable))
                 }
      ) %>% 
  ## collapse the list of count outputs in to one data frame
  bind_rows() %>% 
  ## merge with the outputs of the regression 
  bind_cols(., models) %>% 
  ## only keep columns interested in 
  select(term, 2:3, estimate, conf.low, conf.high, p.value)

```



<!-- ======================================================= -->

## Stratified {.tabset .tabset-fade .tabset-pills}

Stratified analysis is currently still being worked on for `gtsummary`, 
this page will be updated in due course. 


<!-- ======================================================= -->

### `gtsummary` package {.tabset .tabset-fade .tabset-pills}

TODO

<!-- ======================================================= -->

### `base` {.tabset .tabset-fade .tabset-pills}

TODO

<!-- ======================================================= -->

## Multivariable {.tabset .tabset-fade .tabset-pills}

For multivariable analysis you can use a combination there is not much difference 
between using `gtsummary` or `broom` to present the data. 
The workflow is the same for both, as below, and only the last step of pulling a 
table together is different. 

```{r mv_regression}

## run a regression with all variables of interest 
mv_reg <- explanatory_vars %>% 
  ## combine all names of the variables of interest separated by a plus
  str_c(collapse = "+") %>% 
  ## combined the names of variables of interest with outcome in formula style
  str_c("outcome ~ ", .) %>% 
  glm(## define type of glm (logistic)
      family = "binomial", 
      ## define your dataset
      data = linelist) 

## choose a model using forward selection based on AIC
## you can also do "backward" or "both" by adjusting the direction
final_mv_reg <- mv_reg %>%
  step(direction = "forward", trace = FALSE)

```


<!-- ======================================================= -->

### `gtsummary` package {.tabset .tabset-fade .tabset-pills}

The `gtsummary` package provides the `tbl_regression` function, which will 
take the outputs from a regression (`glm` in this case) and produce an easy 
summary table. 
You can also combine several different output tables produced by `gtsummary` with 
the `tbl_mege` function. 
```{r mv_regression_gt}

## show results table of final regression 
mv_tab <- tbl_regression(final_mv_reg, exponentiate = TRUE)

## combine with univariate results 
tbl_merge(
  tbls = list(univ_tab, mv_tab), 
  tab_spanner = c("**Univariate**", "**Multivariable**"))

```


<!-- ======================================================= -->

### `base` {.tabset .tabset-fade .tabset-pills}

```{r mv_regression_base}

mv_tab_base <- final_mv_reg %>% 
  ## get a tidy dataframe of estimates 
  broom::tidy(exponentiate = TRUE, conf.int = TRUE)

## combine univariate and multivariable tables 
left_join(univ_tab_base, mv_tab_base, by = "term") %>% 
  ## choose columns and rename them
  select(
    "characteristic" = term, 
    "recovered"      = "0", 
    "dead"           = "1", 
    "univ_or"        = estimate.x, 
    "univ_ci_low"    = conf.low.x, 
    "univ_ci_high"   = conf.high.x,
    "univ_pval"      = p.value.x, 
    "mv_or"          = estimate.y, 
    "mvv_ci_low"     = conf.low.y, 
    "mv_ci_high"     = conf.high.y,
    "mv_pval"        = p.value.y 
  )

```



<!-- ======================================================= -->

## Forest plot {.tabset .tabset-fade .tabset-pills}

This section shows how to produce a plot with the outputs of your regression.
There are two options, you can build a plot yourself using `ggplot2` or use a 
package called 


<!-- ======================================================= -->

### `ggplot2` package {.tabset .tabset-fade .tabset-pills}

```{r ggplot_forest}

## remove the intercept term from your multivariable results
mv_tab_base %>% 
  filter(term != "(Intercept)") %>% 
  ## plot with variable on the y axis and estimate (OR) on the x axis
  ggplot(aes(x = estimate, y = term)) +
  ## show the estimate as a point
  geom_point() + 
  ## add in an error bar for the confidence intervals
  geom_errorbar(aes(xmin = conf.low, xmax = conf.high)) + 
  ## show where OR = 1 is for reference as a dashed line
  geom_vline(xintercept = 1, linetype = "dashed")
  
```


<!-- ======================================================= -->

### `easytats` packages {.tabset .tabset-fade .tabset-pills}

The alternative if you do not want to decide all of the different things required
for a `ggplot`, is to use a combination of `easystats` packages. 
In this case the `paramaters` package function `model_paramets` does the equivalent
of `broom` package function `tidy`. The `see` package then accepts those outputs
and creates a default forest plot as a `ggplot` object. 

```{r easystats_forest}

## remove the intercept term from your multivariable results
final_mv_reg %>% 
  model_parameters(exponentiate = TRUE) %>% 
  plot()
  
```


<!-- ======================================================= -->

## Resources {.tabset .tabset-fade .tabset-pills}

Much of the information in this page is adapted from these resources and vignettes online:  

[gtsummary](http://www.danieldsjoberg.com/gtsummary/articles/tbl_regression.html)  

[sthda stepwise regression](http://www.sthda.com/english/articles/36-classification-methods-essentials/150-stepwise-logistic-regression-essentials-in-r/)   

