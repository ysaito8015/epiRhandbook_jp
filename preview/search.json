[{"path":"index.html","id":"section","chapter":"","heading":"","text":"","code":""},{"path":"index.html","id":"r-for-applied-epidemiology-and-public-health","chapter":"","heading":"R for applied epidemiology and public health","text":"handbook strives :Serve quick epi R code reference manualProvide task-centered examples addressing common epidemiological problemsAssist epidemiologists transitioning RBe accessible settings low internet-connectivity via offline version \r\nWritten epidemiologists, epidemiologistsWe applied epis around world, writing spare time offer resource community. encouragement feedback welcome:Structured feedback formEmail epiRhandbook@gmail.com tweet @epiRhandbookSubmit issues Github repository","code":""},{"path":"index.html","id":"how-to-use-this-handbook","chapter":"","heading":"How to use this handbook","text":"Browse pages Table Contents, use search boxClick “copy” icons copy codeYou can follow-along [example data][Download handbook data]See “Resources” section page materialOffline versionSee instructions [Download handbook data] page.LanguagesWe want translate languages English. can help, please contact us.","code":""},{"path":"index.html","id":"acknowledgements","chapter":"","heading":"Acknowledgements","text":"handbook produced collaboration epidemiologists around world drawing upon experience organizations including local, state, provincial, national health agencies, World Health Organization (), Médecins Sans Frontières / Doctors without Borders (MSF), hospital systems, academic institutions.handbook approved product specific organization. Although strive accuracy, provide guarantee content book.","code":""},{"path":"index.html","id":"contributors","chapter":"","heading":"Contributors","text":"Editor--Chief: Neale BatraProject core team: Neale Batra, Alex Spina, Amrish Baidjoe, Pat Keating, Henry Laurenson-Schafer, Finlay CampbellAuthors: Neale Batra, Alex Spina, Paula Blomquist, Finlay Campbell, Henry Laurenson-Schafer, Isaac Florence, Natalie Fischer, Aminata Ndiaye, Liza Coyer, Jonathan Polonsky, Yurie Izawa, Chris Bailey, Daniel Molling, Isha Berry, Emma Buajitti, Mathilde Mousset, Sara Hollis, Wen LinReviewers: Pat Keating, Annick Lenglet, Margot Charette, Daniely Xavier, Esther Kukielka, Michelle Sloan, Aybüke Koyuncu, Rachel Burke, Kate Kelsey, Berhe Etsay, John Rossow, Mackenzie Zendt, James Wright, Laura Haskins, Flavio Finger, Tim Taylor, Jae Hyoung Tim Lee, Brianna Bradley, Wayne Enanoria, Manual Albela Miranda, Molly Mantus, Pattama Ulrich, Joseph Timothy, Adam Vaughan, Olivia Varsaneux, Lionel Monteiro, Joao MuiangaIllustrations: Calder Fong","code":""},{"path":"index.html","id":"funding-and-support","chapter":"","heading":"Funding and support","text":"handbook received supportive funding via COVID-19 emergency capacity-building grant TEPHINET, global network Field Epidemiology Training Programs (FETPs).Administrative support provided EPIET Alumni Network (EAN), special thanks Annika Wendland. EPIET European Programme Intervention Epidemiology Training.Special thanks Médecins Sans Frontières (MSF) Operational Centre Amsterdam (OCA) support development handbook.publication supported Cooperative Agreement number NU2GGH001873, funded Centers Disease Control Prevention TEPHINET, program Task Force Global Health. contents solely responsibility authors necessarily represent official views Centers Disease Control Prevention, Department Health Human Services, Task Force Global Health, Inc. TEPHINET.","code":""},{"path":"index.html","id":"inspiration","chapter":"","heading":"Inspiration","text":"multitude tutorials vignettes provided knowledge development handbook content credited within respective pages.generally, following sources provided inspiration handbook:“R4Epis” project (collaboration MSF RECON)R Epidemics Consortium (RECON)R Data Science book (R4DS)bookdown: Authoring Books Technical Documents R MarkdownNetlify hosts website","code":""},{"path":"index.html","id":"terms-of-use-and-license","chapter":"","heading":"Terms of Use and License","text":"work licensed Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.Academic courses epidemiologist training programs welcome use handbook students. questions intended use, email epirhandbook@gmail.com.","code":""},{"path":"epidemic-curves.html","id":"epidemic-curves","chapter":"1 Epidemic curves","heading":"1 Epidemic curves","text":"epidemic curve (also known “epi curve”) core epidemiological chart typically used visualize temporal pattern illness onset among cluster epidemic cases.Analysis epicurve can reveal temporal trends, outliers, magnitude outbreak, likely time period exposure, time intervals case generations, can even help identify mode transmission unidentified disease (e.g. point source, continuous common source, person--person propagation). One online lesson interpretation epi curves can found website US CDC.page demonstrate two approaches producing epicurves R:incidence2 package, can produce epi curve simple commandsThe ggplot2 package, allows advanced customizability via complex commandsAlso addressed specific use-cases :Plotting aggregated count dataFaceting producing small-multiplesApplying moving averagesShowing data “tentative” subject reporting delaysOverlaying cumulative case incidence using second axis","code":""},{"path":"epidemic-curves.html","id":"preparation","chapter":"1 Epidemic curves","heading":"1.1 Preparation","text":"","code":""},{"path":"epidemic-curves.html","id":"packages","chapter":"1 Epidemic curves","heading":"Packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load installed packages library() base R. See page [R basics] information R packages.","code":"\npacman::p_load(\n  rio,          # file import/export\n  here,         # relative filepaths \n  lubridate,    # working with dates/epiweeks\n  aweek,        # alternative package for working with dates/epiweeks\n  incidence2,   # epicurves of linelist data\n  i2extras,     # supplement to incidence2\n  stringr,      # search and manipulate character strings\n  forcats,      # working with factors\n  RColorBrewer, # Color palettes from colorbrewer2.org\n  tidyverse     # data management + ggplot2 graphics\n) "},{"path":"epidemic-curves.html","id":"import-data","chapter":"1 Epidemic curves","heading":"Import data","text":"Two example datasets used section:Linelist individual cases simulated epidemicAggregated counts hospital simulated epidemicThe datasets imported using import() function rio package. See page [Import export] various ways import data.Case linelistWe import dataset cases simulated Ebola epidemic. want download data follow step--step, see instruction [Download handbook data] page. assume file working directory sub-folders specified file path.first 50 rows displayed .Case counts aggregated hospitalFor purposes handbook, dataset weekly aggregated counts hospital created linelist following code.first 50 rows displayed :","code":"\nlinelist <- import(\"linelist_cleaned.xlsx\")\n# import the counts data into R\ncount_data <- linelist %>% \n  group_by(hospital, date_hospitalisation) %>% \n  summarize(n_cases = dplyr::n()) %>% \n  filter(date_hospitalisation > as.Date(\"2013-06-01\")) %>% \n  ungroup()"},{"path":"epidemic-curves.html","id":"set-parameters","chapter":"1 Epidemic curves","heading":"Set parameters","text":"production report, may want set editable parameters date data current (“data date”). can reference object data_date code applying filters dynamic captions.","code":"\n## set the report date for the report\n## note: can be set to Sys.Date() for the current date\ndata_date <- as.Date(\"2015-05-15\")"},{"path":"epidemic-curves.html","id":"verify-dates","chapter":"1 Epidemic curves","heading":"Verify dates","text":"Verify relevant date column class Date appropriate range values. can simply using hist() histograms, range() na.rm=TRUE, ggplot() .","code":"\n# check range of onset dates\nggplot(data = linelist)+\n  geom_histogram(aes(x = date_onset))"},{"path":"epidemic-curves.html","id":"epicurves-with-incidence2-package","chapter":"1 Epidemic curves","heading":"1.2 Epicurves with incidence2 package","text":"demonstrate make epicurves using incidence2 package. authors package tried allow user create modify epicurves without needing know ggplot2 syntax. Much page adapted package vignettes, can found incidence2 github page.","code":""},{"path":"epidemic-curves.html","id":"simple-example","chapter":"1 Epidemic curves","heading":"Simple example","text":"2 steps required plot epidemic curve incidence2 package:Create incidence object (using function incidence())\r\nProvide data\r\nSpecify date column date_index =\r\nSpecify interval = cases aggregated (daily, weekly, monthly..)\r\nSpecify grouping columns (e.g. gender, hospital, outcome)\r\nProvide dataSpecify date column date_index =Specify interval = cases aggregated (daily, weekly, monthly..)Specify grouping columns (e.g. gender, hospital, outcome)Plot incidence object\r\nSpecify labels, colors, titles, etc.\r\nSpecify labels, colors, titles, etc., load incidence2 package, create incidence object linelist column date_onset aggregated cases day. print summary incidence object.incidence2 object looks like tibble (like data frame) can printed manipulated like data frame.looks like printed. date_index column count column.can also print summary object:plot incidence object, use plot() name incidence object. background, function plot.incidence2() called, read incidence2-specific documentation run ?plot.incidence2.notice lots tiny white vertical lines (like ) try adjust size image. example, export plot ggsave(), can provide numbers width = height =. widen plot lines may disappear.","code":"\n# load incidence2 package\npacman::p_load(incidence2)\n\n# create the incidence object, aggregating cases by day\nepi_day <- incidence(       # create incidence object\n  x = linelist,             # dataset\n  date_index = date_onset,  # date column\n  interval = \"day\"          # date grouping interval\n  )\nclass(epi_day)## [1] \"incidence2\" \"tbl_df\"     \"tbl\"        \"data.frame\"\nepi_day## An incidence2 object: 367 x 2\r\n## 5632 cases from 2014-04-07 to 2015-04-30\r\n## interval: 1 day\r\n## cumulative: FALSE\r\n## \r\n##    date_index count\r\n##    <date>     <int>\r\n##  1 2014-04-07     1\r\n##  2 2014-04-15     1\r\n##  3 2014-04-21     2\r\n##  4 2014-04-25     1\r\n##  5 2014-04-26     1\r\n##  6 2014-04-27     1\r\n##  7 2014-05-01     2\r\n##  8 2014-05-03     1\r\n##  9 2014-05-04     1\r\n## 10 2014-05-05     1\r\n## # ... with 357 more rows\n# print summary of the incidence object\nsummary(epi_day)## An incidence2 object: 367 x 2\r\n## 5632 cases from 2014-04-07 to 2015-04-30\r\n## interval: 1 day\r\n## cumulative: FALSE\r\n## timespan: 389 days\n# plot the incidence object\nplot(epi_day)"},{"path":"epidemic-curves.html","id":"change-time-interval-of-case-aggregation","chapter":"1 Epidemic curves","heading":"Change time interval of case aggregation","text":"interval argument incidence() defines observations grouped vertical bars.Specify intervalincidence2 provides flexibility understandable syntax specifying want aggregate cases epicurve bars. Provide value like ones interval = argument:examples different intervals look applied linelist. Note default format frequency date labels x-axis change date interval changes.Begin first caseIf want intervals begin first case, can add argument standard = TRUE incidence() command. works interval either “week”, “month”, “quarter” “year”.First late dateYou can optionally specify first_date = last_date = incidence() command. given, data trimmed range.","code":"\n# Create the incidence objects (with different intervals)\n##############################\n# Weekly (Monday week by default)\nepi_wk      <- incidence(linelist, date_onset, interval = \"Monday week\")\n\n# Sunday week\nepi_Sun_wk  <- incidence(linelist, date_onset, interval = \"Sunday week\")\n\n# Three weeks (Monday weeks by default)\nepi_2wk     <- incidence(linelist, date_onset, interval = \"2 weeks\")\n\n# Monthly\nepi_month   <- incidence(linelist, date_onset, interval = \"month\")\n\n# Quarterly\nepi_quarter   <- incidence(linelist, date_onset, interval = \"quarter\")\n\n# Years\nepi_year   <- incidence(linelist, date_onset, interval = \"year\")\n\n\n# Plot the incidence objects (+ titles for clarity)\n############################\nplot(epi_wk)+      labs(title = \"Monday weeks\")\nplot(epi_Sun_wk)+  labs(title = \"Sunday weeks\")\nplot(epi_2wk)+     labs(title = \"2 (Monday) weeks\")\nplot(epi_month)+   labs(title = \"Months\")\nplot(epi_quarter)+ labs(title = \"Quarters\")\nplot(epi_year)+    labs(title = \"Years\")"},{"path":"epidemic-curves.html","id":"groups","chapter":"1 Epidemic curves","heading":"Groups","text":"Groups specified incidence() command, can used color bars facet data. specify groups data provide column name(s) groups = argument incidence() command (quotes). specifying multiple columns, put names within c().can specify cases missing values grouping columns listed distinct NA group setting na_as_group = TRUE. Otherwise, excluded plot.color bars grouping column*, must provide column name fill = plot() command.color bars grouping column*, must provide column name fill = plot() command.facet based grouping column*, see section facets incidence2.facet based grouping column*, see section facets incidence2.example , cases whole outbreak grouped age category. Missing values included group. epicurve interval weeks.TIP: Change title legend adding + ggplot2 command labs(fill = \"title\") incidence2 plot.can also grouped bars display side--side setting stack = FALSE plot(), shown :","code":"\n# Create incidence object, with data grouped by age category\nage_outbreak <- incidence(\n  linelist,                # dataset\n  date_index = date_onset, # date column\n  interval = \"week\",       # Monday weekly aggregation of cases\n  groups = age_cat,        # age_cat is set as a group\n  na_as_group = TRUE)      # missing values assigned their own group\n\n# plot the grouped incidence object\nplot(\n  age_outbreak,             # incidence object with age_cat as group\n  fill = age_cat)+          # age_cat is used for bar fill color (must have been set as a groups column above)\nlabs(fill = \"Age Category\") # change legend title from default \"age_cat\" (this is a ggplot2 modification)\n# Make incidence object of monthly counts. \nmonthly_gender <- incidence(\n linelist,\n date_index = date_onset,\n interval = \"month\",\n groups = gender            # set gender as grouping column\n)\n\nplot(\n  monthly_gender,   # incidence object\n  fill = gender,    # display bars colored by gender\n  stack = FALSE)    # side-by-side (not stacked)"},{"path":"epidemic-curves.html","id":"filtered-data","chapter":"1 Epidemic curves","heading":"Filtered data","text":"plot epicurve subset data:Filter linelist dataProvide filtered data incidence() commandPlot incidence objectThe example uses data filtered show cases Central Hospital.","code":"\n# filter the linelist\ncentral_data <- linelist %>% \n  filter(hospital == \"Central Hospital\")\n\n# create incidence object using filtered data\ncentral_outbreak <- incidence(central_data, date_index = date_onset, interval = \"week\")\n\n# plot the incidence object\nplot(central_outbreak) + labs(title = \"Weekly case incidence at Central Hospital\")"},{"path":"epidemic-curves.html","id":"aggregated-counts","chapter":"1 Epidemic curves","heading":"Aggregated counts","text":"original data aggregated (counts), provide name column contains case counts count = argument creating incidence object.example, data frame count_data linelist aggregated daily counts hospital. first 50 rows look like :beginning analysis daily count data like dataset , incidence() command convert weekly epicurve hospital look like :","code":"\nepi_counts <- incidence(\n  count_data,                         # dataset with counts aggregated by day\n  date_index = date_hospitalisation,  # column with dates\n  count = n_cases,                    # column with counts\n  interval = \"week\",                  # aggregate daily counts up to weeks\n  groups = hospital                   # group by hospital\n  )\n\n# plot the weekly incidence epi curve, with stacked bars by hospital\nplot(epi_counts,                      # incidence object\n     fill = hospital)                 # color the bars by hospital"},{"path":"epidemic-curves.html","id":"facetssmall-multiples","chapter":"1 Epidemic curves","heading":"Facets/small multiples","text":"facet data group (.e. produce “small multiples”):Specify faceting column groups = create incidence objectUse facet_plot() command instead plot()Specify grouping columns use fill = use facets =, set columns hospital outcome grouping columns incidence() command. , facet_plot() plot epicurve, specifying want different epicurve hospital within epicurve bars stacked colored outcome.Note package ggtree (used displaying phylogenetic trees) also function facet_plot() - specified incidence2::facet_plot() .","code":"\nepi_wks_hosp_out <- incidence(\n  linelist,                      # dataset\n  date_index = date_onset,       # date column\n  interval = \"month\",            # monthly bars  \n  groups = c(outcome, hospital)  # both outcome and hospital are given as grouping columns\n  )\n\n# plot\nincidence2::facet_plot(\n  x = epi_wks_hosp_out,    # incidence object\n  facets = hospital,   # facet column\n  fill = outcome)      # fill column"},{"path":"epidemic-curves.html","id":"modifications-with-plot","chapter":"1 Epidemic curves","heading":"Modifications with plot()","text":"epicurve produced incidence2 can modified via arguments within incidence2 plot() function.plot() arguments relating bars:plot() arguments relating date axis:TIP: breaks every “nth” interval (e.g. every 4th), use n_breaks = nrow()/n (“” incidence object name “n” number). data grouped, need multiply “n” number unique groups.plot() arguments relating labels:example using many arguments:adjust plot appearance, see section applying ggplot() incidence plot.","code":"\n# filter the linelist\ncentral_data <- linelist %>% \n  filter(hospital == \"Central Hospital\")\n\n# create incidence object using filtered data\ncentral_outbreak <- incidence(\n  central_data,\n  date_index = date_onset,\n  interval = \"week\",\n  groups = c(outcome))\n\n# plot incidence object\nplot(\n  central_outbreak,\n  fill = outcome,                       # box/bar color\n  legend = \"top\",                       # legend on top\n  title = \"Cases at Central Hospital\",  # title\n  xlab = \"Week of onset\",               # x-axis label\n  ylab = \"Week of onset\",               # y-axis label\n  show_cases = TRUE,                    # show each case as an individual box\n  alpha = 0.7,                          # transparency \n  border = \"grey\",                      # box border\n  n_breaks = nrow(central_outbreak)/15, # date labels every X weeks\n  angle = 45                            # angle of date labels\n  )"},{"path":"epidemic-curves.html","id":"modifications-with-ggplot2","chapter":"1 Epidemic curves","heading":"Modifications with ggplot2","text":"can modify incidence2 plot adding ggplot2 modifications + close incidence plot() function, demonstrated ., incidence2 plot finishes ggplot2 commands used modify axes, add caption, adjust bold font text size.Note add scale_x_date(), date formatting plot() overwritten. See ggplot() epicurves section Handbook page [ggplot tips] options.","code":"\n# filter the linelist\ncentral_data <- linelist %>% \n  filter(hospital == \"Central Hospital\")\n\n# create incidence object using filtered data\ncentral_outbreak <- incidence(\n  central_data,\n  date_index = date_onset,\n  interval = \"week\",\n  groups = c(outcome))\n\n# plot incidence object\nplot(\n  central_outbreak,\n  fill = outcome,                       # box/bar color\n  legend = \"top\",                       # legend on top\n  title = \"Cases at Central Hospital\",  # title\n  xlab = \"Week of onset\",               # x-axis label\n  ylab = \"Week of onset\",               # y-axis label\n  show_cases = TRUE,                    # show each case as an individual box\n  #centre_ticks = TRUE,                  # ticks appear in center of interval\n  alpha = 0.7,                          # transparency \n  n_breaks = 20,\n  border = \"grey\",                      # box border\n  #format = \"%a %d %B\\n%Y (Week %W)\",    # overwritten below\n  #n_breaks = nrow(central_outbreak)/15, # overwritten below\n  angle = 45                           # angle of date labels\n  )+\n  \n  # Add modifications using ggplot() functions\n  # NOT CURRENTLY FUNCTIONAL WITH VERSION 1.0.0 OF INCIDENCE 2\n  #############################################################\n  # scale_x_date(                              # converts to ggplot date scale (changes default label format)\n  #   expand = c(0,0),                         # remove excess space on left and right\n  #   date_labels = \"%a %d %B\\n%Y (Week %W)\",  # set how dates appear\n  #   date_breaks = \"6 weeks\"                  # set how often dates appear\n  #   )+      \n  \n  scale_y_continuous(\n    breaks = seq(from = 0, to = 30, by = 5),  # specify y-axis increments by 5\n    expand = c(0,0))+                         # remove excess space below 0 on y-axis\n  \n  # add dynamic caption\n  labs(\n    fill = \"Patient outcome\",                               # Legend title\n    caption = stringr::str_glue(                            # dynamic caption - see page on characters and strings for details\n      \"n = {central_cases} from Central Hospital\n      Case onsets range from {earliest_date} to {latest_date}. {missing_onset} cases are missing date of onset and not shown\",\n      central_cases = nrow(central_data),\n      earliest_date = format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y'),\n      latest_date = format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y'),      \n      missing_onset = nrow(central_data %>% filter(is.na(date_onset)))))+\n  \n  # adjust bold face, and caption position\n  theme(\n    axis.title = element_text(size = 12, face = \"bold\"),    # axis titles larger and bold\n    axis.text = element_text(size = 10, face = \"bold\"),     # axis text size and bold\n    plot.caption = element_text(hjust = 0, face = \"italic\") # move caption to left\n  )"},{"path":"epidemic-curves.html","id":"change-colors","chapter":"1 Epidemic curves","heading":"Change colors","text":"","code":""},{"path":"epidemic-curves.html","id":"specify-a-palette","chapter":"1 Epidemic curves","heading":"Specify a palette","text":"Provide name pre-defined palette col_pal = argument plot(). incidence2 package comes 2 pre-defined paletted: “vibrant” “muted”. “vibrant” first 6 colors distinct “muted” first 9 colors distinct. numbers, colors interpolations/intermediaries colors. pre-defined palettes can found website. palettes exclude grey, reserved missing data (use na_color = change default).can also use one base R palettes (put name palette without quotes).can also add color palette viridis package RColorBrewer package. First packages must loaded, add respective scale_fill_*() functions +, shown .","code":"\n# Create incidence object, with data grouped by age category  \nage_outbreak <- incidence(\n  linelist,\n  date_index = date_onset,   # date of onset for x-axis\n  interval = \"week\",         # weekly aggregation of cases\n  groups = age_cat)\n\n# plot the epicurve with default palette\nplot(age_outbreak, fill = age_cat, title = \"'vibrant' default incidence2 palette\")\n\n# plot with different color palette\n#plot(age_outbreak, fill = age_cat, col_pal = muted, title = \"'muted' incidence2 palette\")\n# plot with base R palette\nplot(age_outbreak, fill = age_cat, col_pal = heat.colors, title = \"base R heat.colors palette\")\n\n# plot with base R palette\nplot(age_outbreak, fill = age_cat, col_pal = rainbow, title = \"base R rainbow palette\")\npacman::p_load(RColorBrewer, viridis)\n\n# plot with color palette\nplot(age_outbreak, fill = age_cat, title = \"Viridis palette\")+\n  scale_fill_viridis_d(\n    option = \"inferno\",     # color scheme, try also \"plasma\" or the default\n    name = \"Age Category\",  # legend name\n    na.value = \"grey\")      # for missing values\n\n# plot with color palette\nplot(age_outbreak, fill = age_cat, title = \"RColorBrewer palette\")+\n  scale_fill_brewer(\n    palette = \"Dark2\",      # color palette, try also Accent, Dark2, Paired, Pastel1, Pastel2, Set1, Set2, Set3\n    name = \"Age Category\",  # legend name\n    na.value = \"grey\")      # for missing values"},{"path":"epidemic-curves.html","id":"specify-manually","chapter":"1 Epidemic curves","heading":"Specify manually","text":"specify colors manually, add ggplot2 function scale_fill_manual() plot() + provide vector colors names HEX codes argument values =. number colors listed must equal number groups. aware whether missing values group - can converted character value like “Missing” data preparation function fct_explicit_na() explained page [Factors].mentioned [ggplot tips] page, can create palettes using colorRampPalette() vector colors specifying number colors want return. good way get many colors ramp specifying .","code":"\n# manual colors\nplot(age_outbreak, fill = age_cat, title = \"Manually-specified colors\")+\n  scale_fill_manual(\n    values = c(\"darkgreen\", \"darkblue\", \"purple\", \"grey\", \"yellow\", \"orange\", \"red\", \"lightblue\"),  # colors\n    name = \"Age Category\")      # Name for legend\nmy_cols <- c(\"darkgreen\", \"darkblue\", \"purple\", \"grey\", \"yellow\", \"orange\")\nmy_palette <- colorRampPalette(my_cols)(12)  # expand the 6 colors above to 12 colors\nmy_palette##  [1] \"#006400\" \"#00363F\" \"#00097E\" \"#3A0BAF\" \"#821ADD\" \"#A84BE2\" \"#B592CB\" \"#C9C99B\" \"#E7E745\" \"#FFF600\" \"#FFCD00\" \"#FFA500\""},{"path":"epidemic-curves.html","id":"adjust-level-order","chapter":"1 Epidemic curves","heading":"Adjust level order","text":"adjust order group appearance (plot legend), grouping column must class Factor. See page [Factors] information.First, let’s see weekly epicurve hospital default ordering:Now, adjust order “Missing” “” top epicurve can following:Load package forcats, work factorsAdjust dataset - case ’ll define new dataset (plot_data) :\r\ngender column defined factor order levels set fct_relevel() “” “Missing” first, appear top bars\r\ngender column defined factor order levels set fct_relevel() “” “Missing” first, appear top barsThe incidence object created plotted beforeWe add ggplot2 modifications\r\nscale_fill_manual() manually assign colors “Missing” grey “” beige\r\nscale_fill_manual() manually assign colors “Missing” grey “” beigeTIP: want reverse order legend , add ggplot2 command guides(fill = guide_legend(reverse = TRUE)).","code":"\n# ORIGINAL - hospital NOT as factor\n###################################\n\n# create weekly incidence object, rows grouped by hospital and week\nhospital_outbreak <- incidence(\n  linelist,\n  date_index = date_onset, \n  interval = \"week\", \n  groups = hospital)\n\n# plot incidence object\nplot(hospital_outbreak, fill = hospital, title = \"ORIGINAL - hospital not a factor\")\n# MODIFIED - hospital as factor\n###############################\n\n# load forcats package for working with factors\npacman::p_load(forcats)\n\n# Convert hospital column to factor and adjust levels\nplot_data <- linelist %>% \n  mutate(hospital = fct_relevel(hospital, c(\"Missing\", \"Other\"))) # Set \"Missing\" and \"Other\" as top levels\n\n\n# Create weekly incidence object, grouped by hospital and week\nhospital_outbreak_mod <- incidence(\n  plot_data,\n  date_index = date_onset, \n  interval = \"week\", \n  groups = hospital)\n\n# plot incidence object\nplot(hospital_outbreak_mod, fill = hospital)+\n  \n  # manual specify colors\n  scale_fill_manual(values = c(\"grey\", \"beige\", \"darkgreen\", \"green2\", \"orange\", \"red\", \"pink\"))+                      \n\n  # labels added via ggplot\n  labs(\n      title = \"MODIFIED - hospital as factor\",   # plot title\n      subtitle = \"Other & Missing at top of epicurve\",\n      y = \"Weekly case incidence\",               # y axis title  \n      x = \"Week of symptom onset\",               # x axis title\n      fill = \"Hospital\")                         # title of legend     "},{"path":"epidemic-curves.html","id":"vertical-gridlines","chapter":"1 Epidemic curves","heading":"Vertical gridlines","text":"plot default incidence2 settings, may notice vertical gridlines appear date label date label. can result gridlines intersecting top bars.can remove gridlines adding ggplot2 command theme_classic().Note however, using weeks, date_breaks date_minor_breaks arguments work Monday weeks. weeks another day week need manually provide vector dates breaks = minor_breaks = arguments instead. See ggplot2 section examples using seq.Date().","code":"\n# make incidence object\na <- incidence(\n  central_data,\n  date_index = date_onset,\n  interval = \"Monday weeks\"\n)\n\n# Default gridlines\nplot(a, title = \"Default lines\")\n\n# Specified gridline intervals\n# NOT WORKING WITH INCIDENCE2 1.0.0\n# plot(a, title = \"Weekly lines\")+\n#   scale_x_date(\n#     date_breaks = \"4 weeks\",      # major vertical lines align on weeks\n#     date_minor_breaks = \"weeks\",  # minor vertical lines every week\n#     date_labels = \"%a\\n%d\\n%b\")   # format of date labels\n\n# No gridlines\nplot(a, title = \"No lines\")+\n  theme_classic()                 # remove all gridlines"},{"path":"epidemic-curves.html","id":"cumulative-incidence","chapter":"1 Epidemic curves","heading":"Cumulative incidence","text":"can easily produce plot cumulative incidence passing incidence object incidence2 command cumulate() plot(). also works facet_plot().See section farther page alternative method plot cumulative incidence ggplot2 - example overlay cumulative incidence line epicurve.","code":"\n# make weekly incidence object\nwkly_inci <- incidence(\n  linelist,\n  date_index = date_onset,\n  interval = \"week\"\n)## 256 missing observations were removed.\n# plot cumulative incidence\nwkly_inci %>% \n  cumulate() %>% \n  plot()"},{"path":"epidemic-curves.html","id":"rolling-average","chapter":"1 Epidemic curves","heading":"Rolling average","text":"can add rolling average incidence2 plot easily add_rolling_average() i2extras package. Pass incidence2 object function, plot(). Set = number previous days want included rolling average (default 2). data grouped, rolling average calculated per group.learn apply rolling averages generally data, see Handbook page Moving averages.","code":"\nrolling_avg <- incidence(                    # make incidence object\n  linelist,\n  date_index = date_onset,\n  interval = \"week\",\n  groups = gender) %>% \n  \n  i2extras::add_rolling_average(before = 6)  # add rolling averages (in this case, by gender)\n\n# plot\nplot(rolling_avg, n_breaks = 3) # faceted automatically because rolling average on groups"},{"path":"epidemic-curves.html","id":"epicurves-with-ggplot2","chapter":"1 Epidemic curves","heading":"1.3 Epicurves with ggplot2","text":"Using ggplot() build epicurve allows flexibility customization, requires effort understanding ggplot() works.Unlike using incidence2 package, must manually control aggregation cases time (weeks, months, etc) intervals labels date axis. must carefully managed.examples use subset linelist dataset - cases Central Hospital.produce epicurve ggplot() three main elements:histogram, linelist cases aggregated “bins” distinguished specific “break” pointsScales axes labelsThemes plot appearance, including titles, labels, captions, etc.","code":"\ncentral_data <- linelist %>% \n  filter(hospital == \"Central Hospital\")"},{"path":"epidemic-curves.html","id":"specify-case-bins","chapter":"1 Epidemic curves","heading":"Specify case bins","text":"show specify cases aggregated histogram bins (“bars”). important recognize aggregation cases histogram bins necessarily intervals dates appear x-axis.perhaps simple code produce daily weekly epicurves.-arching ggplot() command dataset provided data =. Onto foundation, geometry histogram added +. Within geom_histogram(), map aesthetics column date_onset mapped x-axis. Also within geom_histogram() within aes() set binwidth = histogram bins, days. ggplot2 syntax confusing, review page [ggplot basics].CAUTION: Plotting weekly cases using binwidth = 7 starts first 7-day bin first case, day week! create specific weeks, see section .Let us note first case Central Hospital dataset symptom onset :manually specify histogram bin breaks, use binwidth = argument, instead supply vector dates breaks =.Create vector dates base R function seq.Date(). function expects arguments =, =, =. example, command returns monthly dates starting Jan 15 ending June 28.vector can provided geom_histogram() breaks =:simple weekly date sequence can returned setting = \"week\". example:alternative supplying specific start end dates write dynamic code weekly bins begin Monday first case. use date vectors throughout examples .Let’s unpack rather daunting code :“” value (earliest date sequence) created follows: minimum date value (min() na.rm=TRUE) column date_onset fed floor_date() lubridate package. floor_date() set “week” returns start date cases’s “week”, given start day week Monday (week_start = 1).Likewise, “” value (end date sequence) created using inverse function ceiling_date() return Monday last case.“” argument seq.Date() can set number days, weeks, months.Use week_start = 7 Sunday weeksAs use date vectors throughout page, also define one whole outbreak (Central Hospital ).seq.Date() outputs can used create histogram bin breaks, also breaks date labels, may independent bins. Read date labels later sections.TIP: simple ggplot() command, save bin breaks date label breaks named vectors advance, simply provide names breaks =.","code":"\n# daily \nggplot(data = central_data) +          # set data\n  geom_histogram(                      # add histogram\n    mapping = aes(x = date_onset),     # map date column to x-axis\n    binwidth = 1)+                     # cases binned by 1 day \n  labs(title = \"Central Hospital - Daily\")                # title\n\n# weekly\nggplot(data = central_data) +          # set data \n  geom_histogram(                      # add histogram\n      mapping = aes(x = date_onset),   # map date column to x-axis\n      binwidth = 7)+                   # cases binned every 7 days, starting from first case (!) \n  labs(title = \"Central Hospital - 7-day bins, starting at first case\") # title\nformat(min(central_data$date_onset, na.rm=T), \"%A %d %b, %Y\")## [1] \"Thursday 01 May, 2014\"\nmonthly_breaks <- seq.Date(from = as.Date(\"2014-02-01\"),\n                           to = as.Date(\"2015-07-15\"),\n                           by = \"months\")\n\nmonthly_breaks   # print##  [1] \"2014-02-01\" \"2014-03-01\" \"2014-04-01\" \"2014-05-01\" \"2014-06-01\" \"2014-07-01\" \"2014-08-01\" \"2014-09-01\" \"2014-10-01\" \"2014-11-01\" \"2014-12-01\" \"2015-01-01\" \"2015-02-01\"\r\n## [14] \"2015-03-01\" \"2015-04-01\" \"2015-05-01\" \"2015-06-01\" \"2015-07-01\"\n# monthly \nggplot(data = central_data) +  \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    breaks = monthly_breaks)+         # provide the pre-defined vector of breaks                    \n  labs(title = \"Monthly case bins\")   # title\nweekly_breaks <- seq.Date(from = as.Date(\"2014-02-01\"),\n                          to = as.Date(\"2015-07-15\"),\n                          by = \"week\")\n# Sequence of weekly Monday dates for CENTRAL HOSPITAL\nweekly_breaks_central <- seq.Date(\n  from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 1), # monday before first case\n  to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 1), # monday after last case\n  by   = \"week\")\n# Sequence for the entire outbreak\nweekly_breaks_all <- seq.Date(\n  from = floor_date(min(linelist$date_onset, na.rm=T),   \"week\", week_start = 1), # monday before first case\n  to   = ceiling_date(max(linelist$date_onset, na.rm=T), \"week\", week_start = 1), # monday after last case\n  by   = \"week\")"},{"path":"epidemic-curves.html","id":"weekly-epicurve-example","chapter":"1 Epidemic curves","heading":"Weekly epicurve example","text":"detailed example code produce weekly epicurves Monday weeks, aligned bars, date labels, vertical gridlines. section user needs code quickly. understand aspect (themes, date labels, etc.) -depth, continue subsequent sections. note:histogram bin breaks defined seq.Date() explained begin Monday earliest case end Monday last caseThe interval date labels specified date_breaks = within scale_x_date()interval minor vertical gridlines date labels specified date_minor_breaks =expand = c(0,0) x y scales removes excess space side axes, also ensures date labels begin first bar.","code":"\n# TOTAL MONDAY WEEK ALIGNMENT\n#############################\n# Define sequence of weekly breaks\nweekly_breaks_central <- seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 1), # Monday before first case\n      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 1), # Monday after last case\n      by   = \"week\")    # bins are 7-days \n\n\nggplot(data = central_data) + \n  \n  # make histogram: specify bin break points: starts the Monday before first case, end Monday after last case\n  geom_histogram(\n    \n    # mapping aesthetics\n    mapping = aes(x = date_onset),  # date column mapped to x-axis\n    \n    # histogram bin breaks\n    breaks = weekly_breaks_central, # histogram bin breaks defined previously\n    \n    # bars\n    color = \"darkblue\",     # color of lines around bars\n    fill = \"lightblue\"      # color of fill within bars\n  )+ \n    \n  # x-axis labels\n  scale_x_date(\n    expand            = c(0,0),           # remove excess x-axis space before and after case bars\n    date_breaks       = \"4 weeks\",        # date labels and major vertical gridlines appear every 3 Monday weeks\n    date_minor_breaks = \"week\",           # minor vertical lines appear every Monday week\n    date_labels       = \"%a\\n%d %b\\n%Y\")+ # date labels format\n  \n  # y-axis\n  scale_y_continuous(\n    expand = c(0,0))+             # remove excess y-axis space below 0 (align histogram flush with x-axis)\n  \n  # aesthetic themes\n  theme_minimal()+                # simplify plot background\n  \n  theme(\n    plot.caption = element_text(hjust = 0,        # caption on left side\n                                face = \"italic\"), # caption in italics\n    axis.title = element_text(face = \"bold\"))+    # axis titles in bold\n  \n  # labels including dynamic caption\n  labs(\n    title    = \"Weekly incidence of cases (Monday weeks)\",\n    subtitle = \"Note alignment of bars, vertical gridlines, and axis labels on Monday weeks\",\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly incident cases reported\",\n    caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))"},{"path":"epidemic-curves.html","id":"sunday-weeks","chapter":"1 Epidemic curves","heading":"Sunday weeks","text":"achieve plot Sunday weeks modifications needed, date_breaks = \"weeks\" work Monday weeks.break points histogram bins must set Sundays (week_start = 7)Within scale_x_date(), similar date breaks provided breaks = minor_breaks = ensure date labels vertical gridlines align Sundays.example, scale_x_date() command Sunday weeks look like :","code":"scale_x_date(\r\n    expand = c(0,0),\r\n    \r\n    # specify interval of date labels and major vertical gridlines\r\n    breaks = seq.Date(\r\n      from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7), # Sunday before first case\r\n      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7), # Sunday after last case\r\n      by   = \"4 weeks\"),\r\n    \r\n    # specify interval of minor vertical gridline \r\n    minor_breaks = seq.Date(\r\n      from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7), # Sunday before first case\r\n      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7), # Sunday after last case\r\n      by   = \"week\"),\r\n   \r\n    # date label format\r\n    date_labels = \"%a\\n%d %b\\n%Y\")+         # day, above month abbrev., above 2-digit year"},{"path":"epidemic-curves.html","id":"groupcolor-by-value","chapter":"1 Epidemic curves","heading":"Group/color by value","text":"histogram bars can colored group “stacked”. designate grouping column, make following changes. See [ggplot basics] page details.Within histogram aesthetic mapping aes(), map column name group = fill = argumentsRemove fill = argument outside aes(), override one insideArguments inside aes() apply group, whereas outside apply bars (e.g. may still want color = outside, bar border)aes() command look like group color bars gender:applied:","code":"\naes(x = date_onset, group = gender, fill = gender)\nggplot(data = linelist) +     # begin with linelist (many hospitals)\n  \n  # make histogram: specify bin break points: starts the Monday before first case, end Monday after last case\n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = hospital,       # set data to be grouped by hospital\n      fill = hospital),       # bar fill (inside color) by hospital\n    \n    # bin breaks are Monday weeks\n    breaks = weekly_breaks_all,   # sequence of weekly Monday bin breaks for whole outbreak, defined in previous code       \n    \n    # Color around bars\n    color = \"black\")"},{"path":"epidemic-curves.html","id":"adjust-colors","chapter":"1 Epidemic curves","heading":"Adjust colors","text":"manually set fill group, use scale_fill_manual() (note: scale_color_manual() different!).\r\nUse values = argument apply vector colors.\r\nUse na.value = specify color NA values.\r\nUse labels = argument change text legend items. safe, provide named vector like c(\"old\" = \"new\", \"old\" = \"new\") adjust values data .\r\nUse name = give proper title legend\r\nUse values = argument apply vector colors.Use na.value = specify color NA values.Use labels = argument change text legend items. safe, provide named vector like c(\"old\" = \"new\", \"old\" = \"new\") adjust values data .Use name = give proper title legendFor tips color scales palettes, see page [ggplot basics].","code":"\nggplot(data = linelist)+           # begin with linelist (many hospitals)\n  \n  # make histogram\n  geom_histogram(\n    mapping = aes(x = date_onset,\n        group = hospital,          # cases grouped by hospital\n        fill = hospital),          # bar fill by hospital\n    \n    # bin breaks\n    breaks = weekly_breaks_all,        # sequence of weekly Monday bin breaks, defined in previous code\n    \n    # Color around bars\n    color = \"black\")+              # border color of each bar\n  \n  # manual specification of colors\n  scale_fill_manual(\n    values = c(\"black\", \"orange\", \"grey\", \"beige\", \"blue\", \"brown\"),\n    labels = c(\"St. Mark's Maternity Hospital (SMMH)\" = \"St. Mark's\"),\n    name = \"Hospital\") # specify fill colors (\"values\") - attention to order!"},{"path":"epidemic-curves.html","id":"adjust-level-order-1","chapter":"1 Epidemic curves","heading":"Adjust level order","text":"order grouped bars stacked best adjusted classifying grouping column class Factor. can designate factor level order (display labels). See page [Factors] [ggplot tips] details.making plot, use fct_relevel() function forcats package convert grouping column class factor manually adjust level order, detailed page [Factors].plot, differences previous column hospital consolidated , use guides() reverse legend order, “Missing” bottom legend.TIP: reverse order legend , add ggplot2 command: guides(fill = guide_legend(reverse = TRUE)).","code":"\n# load forcats package for working with factors\npacman::p_load(forcats)\n\n# Define new dataset with hospital as factor\nplot_data <- linelist %>% \n  mutate(hospital = fct_relevel(hospital, c(\"Missing\", \"Other\"))) # Convert to factor and set \"Missing\" and \"Other\" as top levels to appear on epicurve top\n\nlevels(plot_data$hospital) # print levels in order## [1] \"Missing\"                              \"Other\"                                \"Central Hospital\"                     \"Military Hospital\"                   \r\n## [5] \"Port Hospital\"                        \"St. Mark's Maternity Hospital (SMMH)\"\nggplot(plot_data) +                     # Use NEW dataset with hospital as re-ordered factor\n  \n  # make histogram\n  geom_histogram(\n    mapping = aes(x = date_onset,\n        group = hospital,               # cases grouped by hospital\n        fill = hospital),               # bar fill (color) by hospital\n    \n    breaks = weekly_breaks_all,         # sequence of weekly Monday bin breaks for whole outbreak, defined at top of ggplot section\n    \n    color = \"black\")+                   # border color around each bar\n    \n  # x-axis labels\n  scale_x_date(\n    expand            = c(0,0),         # remove excess x-axis space before and after case bars\n    date_breaks       = \"3 weeks\",      # labels appear every 3 Monday weeks\n    date_minor_breaks = \"week\",         # vertical lines appear every Monday week\n    date_labels       = \"%d\\n%b\\n'%y\")+ # date labels format\n  \n  # y-axis\n  scale_y_continuous(\n    expand = c(0,0))+                   # remove excess y-axis space below 0\n  \n  # manual specification of colors, ! attention to order\n  scale_fill_manual(\n    values = c(\"grey\", \"beige\", \"black\", \"orange\", \"blue\", \"brown\"),\n    labels = c(\"St. Mark's Maternity Hospital (SMMH)\" = \"St. Mark's\"),\n    name = \"Hospital\")+ \n  \n  # aesthetic themes\n  theme_minimal()+                      # simplify plot background\n  \n  theme(\n    plot.caption = element_text(face = \"italic\", # caption on left side in italics\n                                hjust = 0), \n    axis.title = element_text(face = \"bold\"))+   # axis titles in bold\n  \n  # labels\n  labs(\n    title    = \"Weekly incidence of cases by hospital\",\n    subtitle = \"Hospital as re-ordered factor\",\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly cases\")"},{"path":"epidemic-curves.html","id":"adjust-legend","chapter":"1 Epidemic curves","heading":"Adjust legend","text":"Read legends scales [ggplot tips] page. highlights:Edit legend title either scale function labs(fill = \"Legend title\") (using color = aesthetic, use labs(color = \"\"))theme(legend.title = element_blank()) legend titletheme(legend.position = \"top\") (“bottom”, “left”, “right”, “none” remove legend)theme(legend.direction = \"horizontal\") horizontal legendguides(fill = guide_legend(reverse = TRUE)) reverse order legend","code":""},{"path":"epidemic-curves.html","id":"bars-side-by-side","chapter":"1 Epidemic curves","heading":"Bars side-by-side","text":"Side--side display group bars (opposed stacked) specified within geom_histogram() position = \"dodge\" placed outside aes().two value groups, can become difficult read. Consider instead using faceted plot (small multiples). improve readability example, missing gender values removed.","code":"\nggplot(central_data %>% drop_na(gender))+   # begin with Central Hospital cases dropping missing gender\n    geom_histogram(\n        mapping = aes(\n          x = date_onset,\n          group = gender,         # cases grouped by gender\n          fill = gender),         # bars filled by gender\n        \n        # histogram bin breaks\n        breaks = weekly_breaks_central,   # sequence of weekly dates for Central outbreak - defined at top of ggplot section\n        \n        color = \"black\",          # bar edge color\n        \n        position = \"dodge\")+      # SIDE-BY-SIDE bars\n                      \n  \n  # The labels on the x-axis\n  scale_x_date(expand            = c(0,0),         # remove excess x-axis space below and after case bars\n               date_breaks       = \"3 weeks\",      # labels appear every 3 Monday weeks\n               date_minor_breaks = \"week\",         # vertical lines appear every Monday week\n               date_labels       = \"%d\\n%b\\n'%y\")+ # date labels format\n  \n  # y-axis\n  scale_y_continuous(expand = c(0,0))+             # removes excess y-axis space between bottom of bars and the labels\n  \n  #scale of colors and legend labels\n  scale_fill_manual(values = c(\"brown\", \"orange\"),  # specify fill colors (\"values\") - attention to order!\n                    na.value = \"grey\" )+     \n\n  # aesthetic themes\n  theme_minimal()+                                               # a set of themes to simplify plot\n  theme(plot.caption = element_text(face = \"italic\", hjust = 0), # caption on left side in italics\n        axis.title = element_text(face = \"bold\"))+               # axis titles in bold\n  \n  # labels\n  labs(title    = \"Weekly incidence of cases, by gender\",\n       subtitle = \"Subtitle\",\n       fill     = \"Gender\",                                      # provide new title for legend\n       x        = \"Week of symptom onset\",\n       y        = \"Weekly incident cases reported\")"},{"path":"epidemic-curves.html","id":"axis-limits","chapter":"1 Epidemic curves","heading":"Axis limits","text":"two ways limit extent axis values.Generally preferred way use command coord_cartesian(), accepts xlim = c(min, max) ylim = c(min, max) (provide min max values). acts “zoom” without actually removing data, important statistics summary measures.Alternatively, can set maximum minimum date values using limits = c() within scale_x_date(). example:Likewise, want x-axis extend specific date (e.g. current date), even new cases reported, can use:DANGER: cautious setting y-axis scale breaks limits (e.g. 0 30 5: seq(0, 30, 5)). static numbers can cut-plot short data changes exceed limit!.","code":"\nscale_x_date(limits = c(as.Date(\"2014-04-01\"), NA)) # sets a minimum date but leaves the maximum open.  scale_x_date(limits = c(NA, Sys.Date()) # ensures date axis will extend until current date  "},{"path":"epidemic-curves.html","id":"date-axis-labelsgridlines","chapter":"1 Epidemic curves","heading":"Date-axis labels/gridlines","text":"TIP: Remember date-axis labels independent aggregation data bars, visually can important align bins, date labels, vertical grid lines.modify date labels grid lines, use scale_x_date() one ways:histogram bins days, Monday weeks, months, years:\r\nUse date_breaks = specify interval labels major gridlines (e.g. “day”, “week”, “3 weeks”, “month”, “year”)\r\nUse date_minor_breaks = specify interval minor vertical gridlines (date labels)\r\nAdd expand = c(0,0) begin labels first bar\r\nUse date_labels = specify format date labels - see Dates page tips (use \\n new line)\r\nUse date_breaks = specify interval labels major gridlines (e.g. “day”, “week”, “3 weeks”, “month”, “year”)Use date_minor_breaks = specify interval minor vertical gridlines (date labels)Add expand = c(0,0) begin labels first barUse date_labels = specify format date labels - see Dates page tips (use \\n new line)histogram bins Sunday weeks:\r\nUse breaks = minor_breaks = providing sequence date breaks \r\ncan still use date_labels = expand = formatting described \r\nUse breaks = minor_breaks = providing sequence date breaks eachYou can still use date_labels = expand = formatting described aboveSome notes:See opening ggplot section instructions create sequence dates using seq.Date().See page [Working dates] page tips creating date labels.","code":""},{"path":"epidemic-curves.html","id":"demonstrations","chapter":"1 Epidemic curves","heading":"Demonstrations","text":"demonstration plots bins plot labels/grid lines aligned aligned:","code":"\n# 7-day bins + Monday labels\n#############################\nggplot(central_data) +\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    binwidth = 7,                 # 7-day bins with start at first case\n    color = \"darkblue\",\n    fill = \"lightblue\") +\n  \n  scale_x_date(\n    expand = c(0,0),               # remove excess x-axis space below and after case bars\n    date_breaks = \"3 weeks\",       # Monday every 3 weeks\n    date_minor_breaks = \"week\",    # Monday weeks\n    date_labels = \"%a\\n%d\\n%b\\n'%y\")+  # label format\n  \n  scale_y_continuous(\n    expand = c(0,0))+              # remove excess space under x-axis, make flush\n  \n  labs(\n    title = \"MISALIGNED\",\n    subtitle = \"! CAUTION: 7-day bars start Thursdays at first case\\nDate labels and gridlines on Mondays\\nNote how ticks don't align with bars\")\n\n\n\n# 7-day bins + Months\n#####################\nggplot(central_data) +\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    binwidth = 7,\n    color = \"darkblue\",\n    fill = \"lightblue\") +\n  \n  scale_x_date(\n    expand = c(0,0),                  # remove excess x-axis space below and after case bars\n    date_breaks = \"months\",           # 1st of month\n    date_minor_breaks = \"week\",       # Monday weeks\n    date_labels = \"%a\\n%d %b\\n%Y\")+    # label format\n  \n  scale_y_continuous(\n    expand = c(0,0))+                # remove excess space under x-axis, make flush \n  \n  labs(\n    title = \"MISALIGNED\",\n    subtitle = \"! CAUTION: 7-day bars start Thursdays with first case\\nMajor gridlines and date labels at 1st of each month\\nMinor gridlines weekly on Mondays\\nNote uneven spacing of some gridlines and ticks unaligned with bars\")\n\n\n# TOTAL MONDAY ALIGNMENT: specify manual bin breaks to be mondays\n#################################################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # histogram breaks set to 7 days beginning Monday before first case\n    breaks = weekly_breaks_central,    # defined earlier in this page\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),                   # remove excess x-axis space below and after case bars\n    date_breaks = \"4 weeks\",           # Monday every 4 weeks\n    date_minor_breaks = \"week\",        # Monday weeks \n    date_labels = \"%a\\n%d %b\\n%Y\")+      # label format\n  \n  scale_y_continuous(\n    expand = c(0,0))+                # remove excess space under x-axis, make flush \n  \n  labs(\n    title = \"ALIGNED Mondays\",\n    subtitle = \"7-day bins manually set to begin Monday before first case (28 Apr)\\nDate labels and gridlines on Mondays as well\")\n\n\n# TOTAL MONDAY ALIGNMENT WITH MONTHS LABELS:\n############################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # histogram breaks set to 7 days beginning Monday before first case\n    breaks = weekly_breaks_central,            # defined earlier in this page\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),                   # remove excess x-axis space below and after case bars\n    date_breaks = \"months\",            # Monday every 4 weeks\n    date_minor_breaks = \"week\",        # Monday weeks \n    date_labels = \"%b\\n%Y\")+          # label format\n  \n  scale_y_continuous(\n    expand = c(0,0))+                # remove excess space under x-axis, make flush \n  \n  theme(panel.grid.major = element_blank())+  # Remove major gridlines (fall on 1st of month)\n          \n  labs(\n    title = \"ALIGNED Mondays with MONTHLY labels\",\n    subtitle = \"7-day bins manually set to begin Monday before first case (28 Apr)\\nDate labels on 1st of Month\\nMonthly major gridlines removed\")\n\n\n# TOTAL SUNDAY ALIGNMENT: specify manual bin breaks AND labels to be Sundays\n############################################################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # histogram breaks set to 7 days beginning Sunday before first case\n    breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7),\n                      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                      by   = \"7 days\"),\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),\n    # date label breaks and major gridlines set to every 3 weeks beginning Sunday before first case\n    breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7),\n                      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                      by   = \"3 weeks\"),\n    \n    # minor gridlines set to weekly beginning Sunday before first case\n    minor_breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7),\n                            to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                            by   = \"7 days\"),\n    \n    date_labels = \"%a\\n%d\\n%b\\n'%y\")+  # label format\n  \n  scale_y_continuous(\n    expand = c(0,0))+                # remove excess space under x-axis, make flush \n  \n  labs(title = \"ALIGNED Sundays\",\n       subtitle = \"7-day bins manually set to begin Sunday before first case (27 Apr)\\nDate labels and gridlines manually set to Sundays as well\")"},{"path":"epidemic-curves.html","id":"aggregated-data","chapter":"1 Epidemic curves","heading":"Aggregated data","text":"Often instead linelist, begin aggregated counts facilities, districts, etc. can make epicurve ggplot() code slightly different. section utilize count_data dataset imported earlier, data preparation section. dataset linelist aggregated day-hospital counts. first 50 rows displayed .","code":""},{"path":"epidemic-curves.html","id":"plotting-daily-counts","chapter":"1 Epidemic curves","heading":"Plotting daily counts","text":"can plot daily epicurve daily counts. differences code:Within aesthetic mapping aes(), specify y = counts column (case, column name n_cases)Add argument stat = \"identity\" within geom_histogram(), specifies bar height y = value, number rows defaultAdd argument width = avoid vertical white lines bars. daily data set 1. weekly count data set 7. monthly count data, white lines issue (month different number days) - consider transforming x-axis categorical ordered factor (months) using geom_col().","code":"\nggplot(data = count_data)+\n  geom_histogram(\n   mapping = aes(x = date_hospitalisation, y = n_cases),\n   stat = \"identity\",\n   width = 1)+                # for daily counts, set width = 1 to avoid white space between bars\n  labs(\n    x = \"Date of report\", \n    y = \"Number of cases\",\n    title = \"Daily case incidence, from daily count data\")"},{"path":"epidemic-curves.html","id":"plotting-weekly-counts","chapter":"1 Epidemic curves","heading":"Plotting weekly counts","text":"data already case counts week, might look like dataset (called count_data_weekly):first 50 rows count_data_weekly displayed . can see counts aggregated weeks. week displayed first day week (Monday default).Now plot x = epiweek column. Remember add y = counts column aesthetic mapping, add stat = \"identity\" explained .","code":"\nggplot(data = count_data_weekly)+\n  \n  geom_histogram(\n    mapping = aes(\n      x = epiweek,           # x-axis is epiweek (as class Date)\n      y = n_cases_weekly,    # y-axis height in the weekly case counts\n      group = hospital,      # we are grouping the bars and coloring by hospital\n      fill = hospital),\n    stat = \"identity\")+      # this is also required when plotting count data\n     \n  # labels for x-axis\n  scale_x_date(\n    date_breaks = \"2 months\",      # labels every 2 months \n    date_minor_breaks = \"1 month\", # gridlines every month\n    date_labels = '%b\\n%Y')+       #labeled by month with year below\n     \n  # Choose color palette (uses RColorBrewer package)\n  scale_fill_brewer(palette = \"Pastel2\")+ \n  \n  theme_minimal()+\n  \n  labs(\n    x = \"Week of onset\", \n    y = \"Weekly case incidence\",\n    fill = \"Hospital\",\n    title = \"Weekly case incidence, from aggregated count data by hospital\")"},{"path":"epidemic-curves.html","id":"moving-averages","chapter":"1 Epidemic curves","heading":"Moving averages","text":"See page Moving averages detailed description several options. one option calculating moving averages package slider. approach, moving average calculated dataset prior plotting:Aggregate data counts necessary (daily, weekly, etc.) (see [Grouping data] page)Create new column hold moving average, created slide_index() slider packagePlot moving average geom_line() top () epicurve histogramSee helpful online vignette slider package","code":"\n# load package\npacman::p_load(slider)  # slider used to calculate rolling averages\n\n# make dataset of daily counts and 7-day moving average\n#######################################################\nll_counts_7day <- linelist %>%    # begin with linelist\n  \n  ## count cases by date\n  count(date_onset, name = \"new_cases\") %>%   # name new column with counts as \"new_cases\"\n  drop_na(date_onset) %>%                     # remove cases with missing date_onset\n  \n  ## calculate the average number of cases in 7-day window\n  mutate(\n    avg_7day = slider::slide_index(    # create new column\n      new_cases,                       # calculate based on value in new_cases column\n      .i = date_onset,                 # index is date_onset col, so non-present dates are included in window \n      .f = ~mean(.x, na.rm = TRUE),    # function is mean() with missing values removed\n      .before = 6,                     # window is the day and 6-days before\n      .complete = FALSE),              # must be FALSE for unlist() to work in next step\n    avg_7day = unlist(avg_7day))       # convert class list to class numeric\n\n\n# plot\n######\nggplot(data = ll_counts_7day) +  # begin with new dataset defined above \n    geom_histogram(              # create epicurve histogram\n      mapping = aes(\n        x = date_onset,          # date column as x-axis\n        y = new_cases),          # height is number of daily new cases\n        stat = \"identity\",       # height is y value\n        fill=\"#92a8d1\",          # cool color for bars\n        colour = \"#92a8d1\",      # same color for bar border\n        )+ \n    geom_line(                   # make line for rolling average\n      mapping = aes(\n        x = date_onset,          # date column for x-axis\n        y = avg_7day,            # y-value set to rolling average column\n        lty = \"7-day \\nrolling avg\"), # name of line in legend\n      color=\"red\",               # color of line\n      size = 1) +                # width of line\n    scale_x_date(                # date scale\n      date_breaks = \"1 month\",\n      date_labels = '%d/%m',\n      expand = c(0,0)) +\n    scale_y_continuous(          # y-axis scale\n      expand = c(0,0),\n      limits = c(0, NA)) +       \n    labs(\n      x=\"\",\n      y =\"Number of confirmed cases\",\n      fill = \"Legend\")+ \n    theme_minimal()+\n    theme(legend.title = element_blank())  # removes title of legend"},{"path":"epidemic-curves.html","id":"facetingsmall-multiples","chapter":"1 Epidemic curves","heading":"Faceting/small-multiples","text":"ggplots, can create facetted plots (“small multiples”). explained [ggplot tips] page handbook, can use either facet_wrap() facet_grid(). demonstrate facet_wrap(). epicurves, facet_wrap() typically easier likely need facet one column.general syntax facet_wrap(rows ~ cols), left tilde (~) name column spread across “rows” facetted plot, right tilde name column spread across “columns” facetted plot. simply, just use one column name, right tilde: facet_wrap(~age_cat).Free axes\r\nneed decide whether scales axes facet “fixed” dimensions (default), “free” (meaning change based data within facet). scales = argument within facet_wrap() specifying “free_x” “free_y”, “free”.Number cols rows facets\r\ncan specified ncol = nrow = within facet_wrap().Order panels\r\nchange order appearance, change underlying order levels factor column used create facets.Aesthetics\r\nFont size face, strip color, etc. can modified theme() arguments like:strip.text = element_text() (size, colour, face, angle…)strip.background = element_rect() (e.g. element_rect(fill=“grey”))strip.position = (position strip “bottom”, “top”, “left”, “right”)Strip labels\r\nLabels facet plots can modified “labels” column factor, use “labeller”.Make labeller like , using function as_labeller() ggplot2. provide labeller labeller = argument facet_wrap() shown .example facetted plot - facetted column age_cat.See link information labellers.","code":"\nmy_labels <- as_labeller(c(\n     \"0-4\"   = \"Ages 0-4\",\n     \"5-9\"   = \"Ages 5-9\",\n     \"10-14\" = \"Ages 10-14\",\n     \"15-19\" = \"Ages 15-19\",\n     \"20-29\" = \"Ages 20-29\",\n     \"30-49\" = \"Ages 30-49\",\n     \"50-69\" = \"Ages 50-69\",\n     \"70+\"   = \"Over age 70\"))\n# make plot\n###########\nggplot(central_data) + \n  \n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = age_cat,\n      fill = age_cat),    # arguments inside aes() apply by group\n      \n    color = \"black\",      # arguments outside aes() apply to all data\n        \n    # histogram breaks\n    breaks = weekly_breaks_central)+  # pre-defined date vector (see earlier in this page)\n                      \n  # The labels on the x-axis\n  scale_x_date(\n    expand            = c(0,0),         # remove excess x-axis space below and after case bars\n    date_breaks       = \"2 months\",     # labels appear every 2 months\n    date_minor_breaks = \"1 month\",      # vertical lines appear every 1 month \n    date_labels       = \"%b\\n'%y\")+     # date labels format\n  \n  # y-axis\n  scale_y_continuous(expand = c(0,0))+                       # removes excess y-axis space between bottom of bars and the labels\n  \n  # aesthetic themes\n  theme_minimal()+                                           # a set of themes to simplify plot\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # caption on left side in italics\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\",\n    strip.text = element_text(face = \"bold\", size = 10),\n    strip.background = element_rect(fill = \"grey\"))+         # axis titles in bold\n  \n  # create facets\n  facet_wrap(\n    ~age_cat,\n    ncol = 4,\n    strip.position = \"top\",\n    labeller = my_labels)+             \n  \n  # labels\n  labs(\n    title    = \"Weekly incidence of cases, by age category\",\n    subtitle = \"Subtitle\",\n    fill     = \"Age category\",                                      # provide new title for legend\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly incident cases reported\",\n    caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))"},{"path":"epidemic-curves.html","id":"total-epidemic-in-facet-background","chapter":"1 Epidemic curves","heading":"Total epidemic in facet background","text":"show total epidemic background facet, add function gghighlight() empty parentheses ggplot. package gghighlight. Note y-axis maximum facets now based peak entire epidemic. examples package [ggplot tips] page.","code":"\nggplot(central_data) + \n  \n  # epicurves by group\n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = age_cat,\n      fill = age_cat),  # arguments inside aes() apply by group\n    \n    color = \"black\",    # arguments outside aes() apply to all data\n    \n    # histogram breaks\n    breaks = weekly_breaks_central)+     # pre-defined date vector (see top of ggplot section)                \n  \n  # add grey epidemic in background to each facet\n  gghighlight::gghighlight()+\n  \n  # labels on x-axis\n  scale_x_date(\n    expand            = c(0,0),         # remove excess x-axis space below and after case bars\n    date_breaks       = \"2 months\",     # labels appear every 2 months\n    date_minor_breaks = \"1 month\",      # vertical lines appear every 1 month \n    date_labels       = \"%b\\n'%y\")+     # date labels format\n  \n  # y-axis\n  scale_y_continuous(expand = c(0,0))+  # removes excess y-axis space below 0\n  \n  # aesthetic themes\n  theme_minimal()+                                           # a set of themes to simplify plot\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # caption on left side in italics\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\",\n    strip.text = element_text(face = \"bold\", size = 10),\n    strip.background = element_rect(fill = \"white\"))+        # axis titles in bold\n  \n  # create facets\n  facet_wrap(\n    ~age_cat,                          # each plot is one value of age_cat\n    ncol = 4,                          # number of columns\n    strip.position = \"top\",            # position of the facet title/strip\n    labeller = my_labels)+             # labeller defines above\n  \n  # labels\n  labs(\n    title    = \"Weekly incidence of cases, by age category\",\n    subtitle = \"Subtitle\",\n    fill     = \"Age category\",                                      # provide new title for legend\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly incident cases reported\",\n    caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))"},{"path":"epidemic-curves.html","id":"one-facet-with-data","chapter":"1 Epidemic curves","heading":"One facet with data","text":"want one facet box contains data, duplicate entire dataset treat duplicates one faceting value. “helper” function CreateAllFacet() can assist (thanks blog post). run, number rows doubles new column called facet duplicated rows value “”, original rows original value faceting colum. Now just facet facet column.helper function. Run available .Now apply helper function dataset, column age_cat:Notable changes ggplot() command :data used now central_data2 (double rows, new column “facet”)Labeller need updated, usedOptional: achieve vertically stacked facets: facet column moved rows side equation right replaced “.” (facet_wrap(facet~.)), ncol = 1. may also need adjust width height saved png plot image (see ggsave() [ggplot tips]).","code":"\n# Define helper function\nCreateAllFacet <- function(df, col){\n     df$facet <- df[[col]]\n     temp <- df\n     temp$facet <- \"all\"\n     merged <-rbind(temp, df)\n     \n     # ensure the facet value is a factor\n     merged[[col]] <- as.factor(merged[[col]])\n     \n     return(merged)\n}\n# Create dataset that is duplicated and with new column \"facet\" to show \"all\" age categories as another facet level\ncentral_data2 <- CreateAllFacet(central_data, col = \"age_cat\") %>%\n  \n  # set factor levels\n  mutate(facet = fct_relevel(facet, \"all\", \"0-4\", \"5-9\",\n                             \"10-14\", \"15-19\", \"20-29\",\n                             \"30-49\", \"50-69\", \"70+\"))## Warning: Unknown levels in `f`: 70+\n# check levels\ntable(central_data2$facet, useNA = \"always\")## \r\n##   all   0-4   5-9 10-14 15-19 20-29 30-49 50-69  <NA> \r\n##   454    84    84    82    58    73    57     7     9\nggplot(central_data2) + \n  \n  # actual epicurves by group\n  geom_histogram(\n        mapping = aes(\n          x = date_onset,\n          group = age_cat,\n          fill = age_cat),  # arguments inside aes() apply by group\n        color = \"black\",    # arguments outside aes() apply to all data\n        \n        # histogram breaks\n        breaks = weekly_breaks_central)+    # pre-defined date vector (see top of ggplot section)\n                     \n  # Labels on x-axis\n  scale_x_date(\n    expand            = c(0,0),         # remove excess x-axis space below and after case bars\n    date_breaks       = \"2 months\",     # labels appear every 2 months\n    date_minor_breaks = \"1 month\",      # vertical lines appear every 1 month \n    date_labels       = \"%b\\n'%y\")+     # date labels format\n  \n  # y-axis\n  scale_y_continuous(expand = c(0,0))+  # removes excess y-axis space between bottom of bars and the labels\n  \n  # aesthetic themes\n  theme_minimal()+                                           # a set of themes to simplify plot\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # caption on left side in italics\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\")+               \n  \n  # create facets\n  facet_wrap(facet~. ,                            # each plot is one value of facet\n             ncol = 1)+            \n\n  # labels\n  labs(title    = \"Weekly incidence of cases, by age category\",\n       subtitle = \"Subtitle\",\n       fill     = \"Age category\",                                      # provide new title for legend\n       x        = \"Week of symptom onset\",\n       y        = \"Weekly incident cases reported\",\n       caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))"},{"path":"epidemic-curves.html","id":"tentative-data","chapter":"1 Epidemic curves","heading":"1.4 Tentative data","text":"recent data shown epicurves often marked tentative, subject reporting delays. can done adding vertical line /rectangle specified number days. two options:Use annotate():\r\nline use annotate(geom = \"segment\"). Provide x, xend, y, yend. Adjust size, linetype (lty), color.\r\nrectangle use annotate(geom = \"rect\"). Provide xmin/xmax/ymin/ymax. Adjust color alpha.\r\nline use annotate(geom = \"segment\"). Provide x, xend, y, yend. Adjust size, linetype (lty), color.rectangle use annotate(geom = \"rect\"). Provide xmin/xmax/ymin/ymax. Adjust color alpha.Group data tentative status color bars differentlyCAUTION: might try geom_rect() draw rectangle, adjusting transparency work linelist context. function overlays one rectangle observation/row!. Use either low alpha (e.g. 0.01), another approach. ","code":""},{"path":"epidemic-curves.html","id":"using-annotate","chapter":"1 Epidemic curves","heading":"Using annotate()","text":"Within annotate(geom = \"rect\"), xmin xmax arguments must given inputs class Date.Note data aggregated weekly bars, last bar extends Monday last data point, shaded region may appear cover 4 weeksHere annotate() online exampleThe black vertical line can achieved code , using geom_vline() lose ability control height:","code":"\nggplot(central_data) + \n  \n  # histogram\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    breaks = weekly_breaks_central,   # pre-defined date vector - see top of ggplot section\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") +\n\n  # scales\n  scale_y_continuous(expand = c(0,0))+\n  scale_x_date(\n    expand = c(0,0),                   # remove excess x-axis space below and after case bars\n    date_breaks = \"1 month\",           # 1st of month\n    date_minor_breaks = \"1 month\",     # 1st of month\n    date_labels = \"%b\\n'%y\")+          # label format\n  \n  # labels and theme\n  labs(\n    title = \"Using annotate()\\nRectangle and line showing that data from last 21-days are tentative\",\n    x = \"Week of symptom onset\",\n    y = \"Weekly case indicence\")+ \n  theme_minimal()+\n  \n  # add semi-transparent red rectangle to tentative data\n  annotate(\n    \"rect\",\n    xmin  = as.Date(max(central_data$date_onset, na.rm = T) - 21), # note must be wrapped in as.Date()\n    xmax  = as.Date(Inf),                                          # note must be wrapped in as.Date()\n    ymin  = 0,\n    ymax  = Inf,\n    alpha = 0.2,          # alpha easy and intuitive to adjust using annotate()\n    fill  = \"red\")+\n  \n  # add black vertical line on top of other layers\n  annotate(\n    \"segment\",\n    x     = max(central_data$date_onset, na.rm = T) - 21, # 21 days before last data\n    xend  = max(central_data$date_onset, na.rm = T) - 21, \n    y     = 0,         # line begins at y = 0\n    yend  = Inf,       # line to top of plot\n    size  = 2,         # line size\n    color = \"black\",\n    lty   = \"solid\")+   # linetype e.g. \"solid\", \"dashed\"\n\n  # add text in rectangle\n  annotate(\n    \"text\",\n    x = max(central_data$date_onset, na.rm = T) - 15,\n    y = 15,\n    label = \"Subject to reporting delays\",\n    angle = 90)\ngeom_vline(xintercept = max(central_data$date_onset, na.rm = T) - 21,\n           size = 2,\n           color = \"black\")"},{"path":"epidemic-curves.html","id":"bars-color","chapter":"1 Epidemic curves","heading":"Bars color","text":"alternative approach adjust color display tentative bars data . create new column data preparation stage use group data, aes(fill = ) tentative data can different color alpha bars.","code":"\n# add column\n############\nplot_data <- central_data %>% \n  mutate(tentative = case_when(\n    date_onset >= max(date_onset, na.rm=T) - 7 ~ \"Tentative\", # tenative if in last 7 days\n    TRUE                                       ~ \"Reliable\")) # all else reliable\n\n# plot\n######\nggplot(plot_data, aes(x = date_onset, fill = tentative)) + \n  \n  # histogram\n  geom_histogram(\n    breaks = weekly_breaks_central,   # pre-defined data vector, see top of ggplot page\n    color = \"black\") +\n\n  # scales\n  scale_y_continuous(expand = c(0,0))+\n  scale_fill_manual(values = c(\"lightblue\", \"grey\"))+\n  scale_x_date(\n    expand = c(0,0),                   # remove excess x-axis space below and after case bars\n    date_breaks = \"3 weeks\",           # Monday every 3 weeks\n    date_minor_breaks = \"week\",        # Monday weeks \n    date_labels = \"%d\\n%b\\n'%y\")+      # label format\n  \n  # labels and theme\n  labs(title = \"Show days that are tentative reporting\",\n    subtitle = \"\")+ \n  theme_minimal()+\n  theme(legend.title = element_blank())                 # remove title of legend"},{"path":"epidemic-curves.html","id":"multi-level-date-labels","chapter":"1 Epidemic curves","heading":"1.5 Multi-level date labels","text":"want multi-level date labels (e.g. month year) without duplicating lower label levels, consider one approaches :Remember - can can use tools like \\n within date_labels labels arguments put parts label new line . However, code helps take years months (example) lower line . notes code :Case counts aggregated weeks aesthetic reasons. See Epicurves page (aggregated data tab) details.geom_area() line used instead histogram, faceting approach work well histograms.Aggregate weekly countsMake plotsThe techniques adapted post stackoverflow.com.","code":"\n# Create dataset of case counts by week\n#######################################\ncentral_weekly <- linelist %>%\n  filter(hospital == \"Central Hospital\") %>%   # filter linelist\n  mutate(week = lubridate::floor_date(date_onset, unit = \"weeks\")) %>%  \n  count(week) %>%                              # summarize weekly case counts\n  drop_na(week) %>%                            # remove cases with missing onset_date\n  complete(                                    # fill-in all weeks with no cases reported\n    week = seq.Date(\n      from = min(week),   \n      to   = max(week),\n      by   = \"week\"),\n    fill = list(n = 0))                        # convert new NA values to 0 counts\n# plot with box border on year\n##############################\nggplot(central_weekly) +\n  geom_area(aes(x = week, y = n),    # make line, specify x and y\n            stat = \"identity\") +             # because line height is count number\n  scale_x_date(date_labels=\"%b\",             # date label format show month \n               date_breaks=\"month\",          # date labels on 1st of each month\n               expand=c(0,0)) +              # remove excess space on each end\n  scale_y_continuous(\n    expand  = c(0,0))+                       # remove excess space below x-axis\n  facet_grid(~lubridate::year(week), # facet on year (of Date class column)\n             space=\"free_x\",                \n             scales=\"free_x\",                # x-axes adapt to data range (not \"fixed\")\n             switch=\"x\") +                   # facet labels (year) on bottom\n  theme_bw() +\n  theme(strip.placement = \"outside\",         # facet labels placement\n        strip.background = element_rect(fill = NA, # facet labels no fill grey border\n                                        colour = \"grey50\"),\n        panel.spacing = unit(0, \"cm\"))+      # no space between facet panels\n  labs(title = \"Nested year labels, grey label border\")\n# plot with no box border on year\n#################################\nggplot(central_weekly,\n       aes(x = week, y = n)) +              # establish x and y for entire plot\n  geom_line(stat = \"identity\",              # make line, line height is count number\n            color = \"#69b3a2\") +            # line color\n  geom_point(size=1, color=\"#69b3a2\") +     # make points at the weekly data points\n  geom_area(fill = \"#69b3a2\",               # fill area below line\n            alpha = 0.4)+                   # fill transparency\n  scale_x_date(date_labels=\"%b\",            # date label format show month \n               date_breaks=\"month\",         # date labels on 1st of each month\n               expand=c(0,0)) +             # remove excess space\n  scale_y_continuous(\n    expand  = c(0,0))+                      # remove excess space below x-axis\n  facet_grid(~lubridate::year(week),        # facet on year (of Date class column)\n             space=\"free_x\",                \n             scales=\"free_x\",               # x-axes adapt to data range (not \"fixed\")\n             switch=\"x\") +                  # facet labels (year) on bottom\n  theme_bw() +\n  theme(strip.placement = \"outside\",                     # facet label placement\n          strip.background = element_blank(),            # no facet lable background\n          panel.grid.minor.x = element_blank(),          \n          panel.border = element_rect(colour=\"grey40\"),  # grey border to facet PANEL\n          panel.spacing=unit(0,\"cm\"))+                   # No space between facet panels\n  labs(title = \"Nested year labels - points, shaded, no label border\")"},{"path":"epidemic-curves.html","id":"dual-axis","chapter":"1 Epidemic curves","heading":"1.6 Dual-axis","text":"Although fierce discussions validity dual axes within data visualization community, many epi supervisors still want see epicurve similar chart percent overlaid second axis. discussed extensively [ggplot tips] page, one example using cowplot method shown :Two distinct plots made, combined cowplot package.plots must exact x-axis (set limits) else data labels alignEach uses theme_cowplot() one y-axis moved right side plotNow use cowplot overlay two plots. Attention paid x-axis alignment, side y-axis, use theme_cowplot().","code":"\n#load package\npacman::p_load(cowplot)\n\n# Make first plot of epicurve histogram\n#######################################\nplot_cases <- linelist %>% \n  \n  # plot cases per week\n  ggplot()+\n  \n  # create histogram  \n  geom_histogram(\n    \n    mapping = aes(x = date_onset),\n    \n    # bin breaks every week beginning monday before first case, going to monday after last case\n    breaks = weekly_breaks_all)+  # pre-defined vector of weekly dates (see top of ggplot section)\n        \n  # specify beginning and end of date axis to align with other plot\n  scale_x_date(\n    limits = c(min(weekly_breaks_all), max(weekly_breaks_all)))+  # min/max of the pre-defined weekly breaks of histogram\n  \n  # labels\n  labs(\n      y = \"Daily cases\",\n      x = \"Date of symptom onset\"\n    )+\n  theme_cowplot()\n\n\n# make second plot of percent died per week\n###########################################\nplot_deaths <- linelist %>%                        # begin with linelist\n  group_by(week = floor_date(date_onset, \"week\")) %>%  # create week column\n  \n  # summarise to get weekly percent of cases who died\n  summarise(n_cases = n(),\n            died = sum(outcome == \"Death\", na.rm=T),\n            pct_died = 100*died/n_cases) %>% \n  \n  # begin plot\n  ggplot()+\n  \n  # line of weekly percent who died\n  geom_line(                                # create line of percent died\n    mapping = aes(x = week, y = pct_died),  # specify y-height as pct_died column\n    stat = \"identity\",                      # set line height to the value in pct_death column, not the number of rows (which is default)\n    size = 2,\n    color = \"black\")+\n  \n  # Same date-axis limits as the other plot - perfect alignment\n  scale_x_date(\n    limits = c(min(weekly_breaks_all), max(weekly_breaks_all)))+  # min/max of the pre-defined weekly breaks of histogram\n  \n  \n  # y-axis adjustments\n  scale_y_continuous(                # adjust y-axis\n    breaks = seq(0,100, 10),         # set break intervals of percent axis\n    limits = c(0, 100),              # set extent of percent axis\n    position = \"right\")+             # move percent axis to the right\n  \n  # Y-axis label, no x-axis label\n  labs(x = \"\",\n       y = \"Percent deceased\")+      # percent axis label\n  \n  theme_cowplot()                   # add this to make the two plots merge together nicely\naligned_plots <- cowplot::align_plots(plot_cases, plot_deaths, align=\"hv\", axis=\"tblr\")\nggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])"},{"path":"epidemic-curves.html","id":"cumulative-incidence-1","chapter":"1 Epidemic curves","heading":"1.7 Cumulative Incidence","text":"Note: using incidence2, see section can produce cumulative incidence simple function. page address calculate cumulative incidence plot ggplot().beginning case linelist, create new column containing cumulative number cases per day outbreak using cumsum() base R:first 10 rows shown :cumulative column can plotted date_onset, using geom_line():can also overlaid onto epicurve, dual-axis using cowplot method described [ggplot tips] page:Now use cowplot overlay two plots. Attention paid x-axis alignment, side y-axis, use theme_cowplot().","code":"\ncumulative_case_counts <- linelist %>% \n  count(date_onset) %>%                # count of rows per day (returned in column \"n\")   \n  mutate(                         \n    cumulative_cases = cumsum(n)       # new column of the cumulative number of rows at each date\n    )\nplot_cumulative <- ggplot()+\n  geom_line(\n    data = cumulative_case_counts,\n    aes(x = date_onset, y = cumulative_cases),\n    size = 2,\n    color = \"blue\")\n\nplot_cumulative\n#load package\npacman::p_load(cowplot)\n\n# Make first plot of epicurve histogram\nplot_cases <- ggplot()+\n  geom_histogram(          \n    data = linelist,\n    aes(x = date_onset),\n    binwidth = 1)+\n  labs(\n    y = \"Daily cases\",\n    x = \"Date of symptom onset\"\n  )+\n  theme_cowplot()\n\n# make second plot of cumulative cases line\nplot_cumulative <- ggplot()+\n  geom_line(\n    data = cumulative_case_counts,\n    aes(x = date_onset, y = cumulative_cases),\n    size = 2,\n    color = \"blue\")+\n  scale_y_continuous(\n    position = \"right\")+\n  labs(x = \"\",\n       y = \"Cumulative cases\")+\n  theme_cowplot()+\n  theme(\n    axis.line.x = element_blank(),\n    axis.text.x = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks = element_blank())\naligned_plots <- cowplot::align_plots(plot_cases, plot_cumulative, align=\"hv\", axis=\"tblr\")\nggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])"},{"path":"epidemic-curves.html","id":"resources","chapter":"1 Epidemic curves","heading":"1.8 Resources","text":"","code":""},{"path":"time-series-and-outbreak-detection.html","id":"time-series-and-outbreak-detection","chapter":"2 Time series and outbreak detection","heading":"2 Time series and outbreak detection","text":"","code":""},{"path":"time-series-and-outbreak-detection.html","id":"overview","chapter":"2 Time series and outbreak detection","heading":"2.1 Overview","text":"tab demonstrates use several packages time series analysis.\r\nprimarily relies packages tidyverts\r\nfamily, also use RECON trending\r\npackage fit models appropriate infectious disease epidemiology.Note example use dataset surveillance package\r\nCampylobacter Germany (see data chapter,\r\nhandbook details). However, wanted run code dataset\r\nmultiple countries strata, example code template \r\nr4epis github repo.Topics covered include:Time series dataDescriptive analysisFitting regressionsRelation two time seriesOutbreak detectionInterrupted time series","code":""},{"path":"time-series-and-outbreak-detection.html","id":"preparation-1","chapter":"2 Time series and outbreak detection","heading":"2.2 Preparation","text":"","code":""},{"path":"time-series-and-outbreak-detection.html","id":"packages-1","chapter":"2 Time series and outbreak detection","heading":"Packages","text":"code chunk shows loading packages required analyses. handbook emphasize p_load() pacman, installs package necessary loads use. can also load packages library() base R. See page R basics information R packages.","code":"\npacman::p_load(rio,          # File import\n               here,         # File locator\n               tidyverse,    # data management + ggplot2 graphics\n               tsibble,      # handle time series datasets\n               slider,       # for calculating moving averages\n               imputeTS,     # for filling in missing values\n               feasts,       # for time series decomposition and autocorrelation\n               forecast,     # fit sin and cosin terms to data (note: must load after feasts)\n               trending,     # fit and assess models \n               tmaptools,    # for getting geocoordinates (lon/lat) based on place names\n               ecmwfr,       # for interacting with copernicus sateliate CDS API\n               stars,        # for reading in .nc (climate data) files\n               units,        # for defining units of measurement (climate data)\n               yardstick,    # for looking at model accuracy\n               surveillance  # for aberration detection\n               )"},{"path":"time-series-and-outbreak-detection.html","id":"load-data","chapter":"2 Time series and outbreak detection","heading":"Load data","text":"can download data used handbook via instructions [Download handbook data] page.example dataset used section weekly counts campylobacter cases reported Germany 2001 2011. \r\ncan click download data file (.xlsx).dataset reduced version dataset available surveillance package.\r\n(details load surveillance package see ?campyDE)Import data import() function rio package (handles many file types like .xlsx, .csv, .rds - see [Import export] page details).first 10 rows counts displayed .","code":"\n# import the counts into R\ncounts <- rio::import(\"campylobacter_germany.xlsx\")"},{"path":"time-series-and-outbreak-detection.html","id":"clean-data","chapter":"2 Time series and outbreak detection","heading":"Clean data","text":"code makes sure date column appropriate format.\r\ntab using tsibble package yearweek\r\nfunction used create calendar week variable. several \r\nways (see Working dates\r\npage details), however time series best keep within one framework (tsibble).","code":"\n## ensure the date column is in the appropriate format\ncounts$date <- as.Date(counts$date)\n\n## create a calendar week variable \n## fitting ISO definitons of weeks starting on a monday\ncounts <- counts %>% \n     mutate(epiweek = yearweek(date, week_start = 1))"},{"path":"time-series-and-outbreak-detection.html","id":"download-climate-data","chapter":"2 Time series and outbreak detection","heading":"Download climate data","text":"relation two time series section page, comparing\r\ncampylobacter case counts climate data.Climate data anywhere world can downloaded EU’s Copernicus\r\nSatellite. exact measurements, based model (similar \r\ninterpolation), however benefit global hourly coverage well forecasts.can download climate data files [Download handbook data] page.purposes demonstration , show R code use ecmwfr package pull data Copernicus\r\nclimate data store. need create free account order \r\nwork. package website useful walkthrough\r\n. example code go , \r\nappropriate API keys. replace X’s account\r\nIDs. need download one year data time otherwise server times-.sure coordinates location want download data\r\n, can use tmaptools package pull coordinates open street\r\nmaps. alternative option photon\r\npackage, however released CRAN yet; nice thing \r\nphoton provides contextual data several\r\nmatches search.","code":"\n## retrieve location coordinates\ncoords <- geocode_OSM(\"Germany\", geometry = \"point\")\n\n## pull together long/lats in format for ERA-5 querying (bounding box) \n## (as just want a single point can repeat coords)\nrequest_coords <- str_glue_data(coords$coords, \"{y}/{x}/{y}/{x}\")\n\n\n## Pulling data modelled from copernicus satellite (ERA-5 reanalysis)\n## https://cds.climate.copernicus.eu/cdsapp#!/software/app-era5-explorer?tab=app\n## https://github.com/bluegreen-labs/ecmwfr\n\n## set up key for weather data \nwf_set_key(user = \"XXXXX\",\n           key = \"XXXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXX\",\n           service = \"cds\") \n\n## run for each year of interest (otherwise server times out)\nfor (i in 2002:2011) {\n  \n  ## pull together a query \n  ## see here for how to do: https://bluegreen-labs.github.io/ecmwfr/articles/cds_vignette.html#the-request-syntax\n  ## change request to a list using addin button above (python to list)\n  ## Target is the name of the output file!!\n  request <- request <- list(\n    product_type = \"reanalysis\",\n    format = \"netcdf\",\n    variable = c(\"2m_temperature\", \"total_precipitation\"),\n    year = c(i),\n    month = c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"),\n    day = c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\",\n            \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\",\n            \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\"),\n    time = c(\"00:00\", \"01:00\", \"02:00\", \"03:00\", \"04:00\", \"05:00\", \"06:00\", \"07:00\",\n             \"08:00\", \"09:00\", \"10:00\", \"11:00\", \"12:00\", \"13:00\", \"14:00\", \"15:00\",\n             \"16:00\", \"17:00\", \"18:00\", \"19:00\", \"20:00\", \"21:00\", \"22:00\", \"23:00\"),\n    area = request_coords,\n    dataset_short_name = \"reanalysis-era5-single-levels\",\n    target = paste0(\"germany_weather\", i, \".nc\")\n  )\n  \n  ## download the file and store it in the current working directory\n  file <- wf_request(user     = \"XXXXX\",  # user ID (for authentication)\n                     request  = request,  # the request\n                     transfer = TRUE,     # download the file\n                     path     = here::here(\"data\", \"Weather\")) ## path to save the data\n  }"},{"path":"time-series-and-outbreak-detection.html","id":"load-climate-data","chapter":"2 Time series and outbreak detection","heading":"Load climate data","text":"Whether downloaded climate data via handbook, used code , now 10 years “.nc” climate data files stored folder computer.Use code import files R stars package.files imported object data, convert data frame.","code":"\n## define path to weather folder \nfile_paths <- list.files(\n  here::here(\"data\", \"time_series\", \"weather\"), # replace with your own file path \n  full.names = TRUE)\n\n## only keep those with the current name of interest \nfile_paths <- file_paths[str_detect(file_paths, \"germany\")]\n\n## read in all the files as a stars object \ndata <- stars::read_stars(file_paths)## t2m, tp, \r\n## t2m, tp, \r\n## t2m, tp, \r\n## t2m, tp, \r\n## t2m, tp, \r\n## t2m, tp, \r\n## t2m, tp, \r\n## t2m, tp, \r\n## t2m, tp, \r\n## t2m, tp,\n## change to a data frame \ntemp_data <- as_tibble(data) %>% \n  ## add in variables and correct units\n  mutate(\n    ## create an calendar week variable \n    epiweek = tsibble::yearweek(time), \n    ## create a date variable (start of calendar week)\n    date = as.Date(epiweek),\n    ## change temperature from kelvin to celsius\n    t2m = set_units(t2m, celsius), \n    ## change precipitation from metres to millimetres \n    tp  = set_units(tp, mm)) %>% \n  ## group by week (keep the date too though)\n  group_by(epiweek, date) %>% \n  ## get the average per week\n  summarise(t2m = as.numeric(mean(t2m)), \n            tp = as.numeric(mean(tp)))## `summarise()` has grouped output by 'epiweek'. You can override using the `.groups` argument."},{"path":"time-series-and-outbreak-detection.html","id":"time-series-data","chapter":"2 Time series and outbreak detection","heading":"2.3 Time series data","text":"number different packages structuring handling time series\r\ndata. said, focus tidyverts family packages \r\nuse tsibble package define time series object. data set\r\ndefined time series object means much easier structure analysis.use tsibble() function specify “index”, .e. variable\r\nspecifying time unit interest. case epiweek variable.data set weekly counts province, example, also\r\nable specify grouping variable using key = argument.\r\nallow us analysis group.Looking class(counts) tells top tidy data frame\r\n(“tbl_df”, “tbl”, “data.frame”), additional properties time series\r\ndata frame (“tbl_ts”).can take quick look data using ggplot2. see plot \r\nclear seasonal pattern, missings. However, \r\nseems issue reporting beginning year; cases drop\r\nlast week year increase first week next year.DANGER: datasets aren’t clean example.\r\nneed check duplicates missings . ","code":"\n## define time series object \ncounts <- tsibble(counts, index = epiweek)\n## plot a line graph of cases by week\nggplot(counts, aes(x = epiweek, y = case)) + \n     geom_line()"},{"path":"time-series-and-outbreak-detection.html","id":"duplicates","chapter":"2 Time series and outbreak detection","heading":"Duplicates","text":"tsibble allow duplicate observations. row need \r\nunique, unique within group (key variable).\r\npackage functions help identify duplicates. include\r\nare_duplicated() gives TRUE/FALSE vector whether row \r\nduplicate, duplicates() gives data frame duplicated rows.See page De-duplication\r\ndetails select rows want.","code":"\n## get a vector of TRUE/FALSE whether rows are duplicates\nare_duplicated(counts, index = epiweek) \n\n## get a data frame of any duplicated rows \nduplicates(counts, index = epiweek) "},{"path":"time-series-and-outbreak-detection.html","id":"missings","chapter":"2 Time series and outbreak detection","heading":"Missings","text":"saw brief inspection missings, also\r\nsaw seems problem reporting delay around new year.\r\nOne way address problem set values missing \r\nimpute values. simplest form time series imputation draw\r\nstraight line last non-missing next non-missing value.\r\nuse imputeTS package function na_interpolation().See Missing data page options imputation.Another alternative calculate moving average, try smooth\r\napparent reporting issues (see next section, page Moving averages).","code":"\n## create a variable with missings instead of weeks with reporting issues\ncounts <- counts %>% \n     mutate(case_miss = if_else(\n          ## if epiweek contains 52, 53, 1 or 2\n          str_detect(epiweek, \"W51|W52|W53|W01|W02\"), \n          ## then set to missing \n          NA_real_, \n          ## otherwise keep the value in case\n          case\n     ))\n\n## alternatively interpolate missings by linear trend \n## between two nearest adjacent points\ncounts <- counts %>% \n  mutate(case_int = na_interpolation(case_miss)\n         )\n\n## to check what values have been imputed compared to the original\nggplot_na_imputations(counts$case_miss, counts$case_int) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()"},{"path":"time-series-and-outbreak-detection.html","id":"descriptive-analysis","chapter":"2 Time series and outbreak detection","heading":"2.4 Descriptive analysis","text":"","code":""},{"path":"time-series-and-outbreak-detection.html","id":"timeseries_moving","chapter":"2 Time series and outbreak detection","heading":"Moving averages","text":"data noisy (counts jumping ) can helpful \r\ncalculate moving average. example , week calculate \r\naverage number cases four previous weeks. smooths data, \r\nmake interpretable. case really add much, \r\nstick interpolated data analysis.\r\nSee Moving averages page detail.","code":"\n## create a moving average variable (deals with missings)\ncounts <- counts %>% \n     ## create the ma_4w variable \n     ## slide over each row of the case variable\n     mutate(ma_4wk = slider::slide_dbl(case, \n                               ## for each row calculate the name\n                               ~ mean(.x, na.rm = TRUE),\n                               ## use the four previous weeks\n                               .before = 4))\n\n## make a quick visualisation of the difference \nggplot(counts, aes(x = epiweek)) + \n     geom_line(aes(y = case)) + \n     geom_line(aes(y = ma_4wk), colour = \"red\")"},{"path":"time-series-and-outbreak-detection.html","id":"periodicity","chapter":"2 Time series and outbreak detection","heading":"Periodicity","text":"define custom function create periodogram. See [Writing functions] page information write functions R.First, function defined. arguments include dataset column counts, start_week = first week dataset, number indicate many periods per year (e.g. 52, 12), lastly output style (see details code ).NOTE: possible use weeks add sin cosine terms, however use function generate terms (see regression section ) ","code":"\n## Function arguments\n#####################\n## x is a dataset\n## counts is variable with count data or rates within x \n## start_week is the first week in your dataset\n## period is how many units in a year \n## output is whether you want return spectral periodogram or the peak weeks\n  ## \"periodogram\" or \"weeks\"\n\n# Define function\nperiodogram <- function(x, \n                        counts, \n                        start_week = c(2002, 1), \n                        period = 52, \n                        output = \"weeks\") {\n  \n\n    ## make sure is not a tsibble, filter to project and only keep columns of interest\n    prepare_data <- dplyr::as_tibble(x)\n    \n    # prepare_data <- prepare_data[prepare_data[[strata]] == j, ]\n    prepare_data <- dplyr::select(prepare_data, {{counts}})\n    \n    ## create an intermediate \"zoo\" time series to be able to use with spec.pgram\n    zoo_cases <- zoo::zooreg(prepare_data, \n                             start = start_week, frequency = period)\n    \n    ## get a spectral periodogram not using fast fourier transform \n    periodo <- spec.pgram(zoo_cases, fast = FALSE, plot = FALSE)\n    \n    ## return the peak weeks \n    periodo_weeks <- 1 / periodo$freq[order(-periodo$spec)] * period\n    \n    if (output == \"weeks\") {\n      periodo_weeks\n    } else {\n      periodo\n    }\n    \n}\n\n## get spectral periodogram for extracting weeks with the highest frequencies \n## (checking of seasonality) \nperiodo <- periodogram(counts, \n                       case_int, \n                       start_week = c(2002, 1),\n                       output = \"periodogram\")\n\n## pull spectrum and frequence in to a dataframe for plotting\nperiodo <- data.frame(periodo$freq, periodo$spec)\n\n## plot a periodogram showing the most frequently occuring periodicity \nggplot(data = periodo, \n                aes(x = 1/(periodo.freq/52),  y = log(periodo.spec))) + \n  geom_line() + \n  labs(x = \"Period (Weeks)\", y = \"Log(density)\")\n## get a vector weeks in ascending order \npeak_weeks <- periodogram(counts, \n                          case_int, \n                          start_week = c(2002, 1), \n                          output = \"weeks\")"},{"path":"time-series-and-outbreak-detection.html","id":"decomposition","chapter":"2 Time series and outbreak detection","heading":"Decomposition","text":"Classical decomposition used break time series several parts, \r\ntaken together make pattern see.\r\ndifferent parts :trend-cycle (long-term direction data)seasonality (repeating patterns)random (left removing trend season)","code":"\n## decompose the counts dataset \ncounts %>% \n  # using an additive classical decomposition model\n  model(classical_decomposition(case_int, type = \"additive\")) %>% \n  ## extract the important information from the model\n  components() %>% \n  ## generate a plot \n  autoplot()"},{"path":"time-series-and-outbreak-detection.html","id":"autocorrelation","chapter":"2 Time series and outbreak detection","heading":"Autocorrelation","text":"Autocorrelation tells relation counts week\r\nweeks (called lags).Using ACF() function, can produce plot shows us number lines\r\nrelation different lags. lag 0 (x = 0), line \r\nalways 1 shows relation observation (shown ).\r\nfirst line shown (x = 1) shows relation observation\r\nobservation (lag 1), second shows relation \r\nobservation observation last (lag 2) lag \r\n52 shows relation observation observation 1\r\nyear (52 weeks ).Using PACF() function (partial autocorrelation) shows type relation\r\nadjusted weeks . less informative determining\r\nperiodicity.can formally test null hypothesis independence time series (.e. \r\nautocorrelated) using Ljung-Box test (stats package).\r\nsignificant p-value suggests autocorrelation data.","code":"\n## using the counts dataset\ncounts %>% \n  ## calculate autocorrelation using a full years worth of lags\n  ACF(case_int, lag_max = 52) %>% \n  ## show a plot\n  autoplot()\n## using the counts data set \ncounts %>% \n  ## calculate the partial autocorrelation using a full years worth of lags\n  PACF(case_int, lag_max = 52) %>% \n  ## show a plot\n  autoplot()\n## test for independance \nBox.test(counts$case_int, type = \"Ljung-Box\")## \r\n##  Box-Ljung test\r\n## \r\n## data:  counts$case_int\r\n## X-squared = 462.65, df = 1, p-value < 2.2e-16"},{"path":"time-series-and-outbreak-detection.html","id":"fitting-regressions","chapter":"2 Time series and outbreak detection","heading":"2.5 Fitting regressions","text":"possible fit large number different regressions time series,\r\nhowever, demonstrate fit negative binomial regression - \r\noften appropriate counts data infectious diseases.","code":""},{"path":"time-series-and-outbreak-detection.html","id":"fourier-terms","chapter":"2 Time series and outbreak detection","heading":"Fourier terms","text":"Fourier terms equivalent sin cosin curves. difference \r\nfit based finding appropriate combination curves explain\r\ndata.fitting one fourier term, equivalent fitting sin\r\ncosin frequently occurring lag seen periodogram (\r\ncase 52 weeks). use fourier() function forecast package.code assign using $, fourier() returns two columns (one\r\nsin one cosin) added dataset list, called\r\n“fourier” - list can used normal variable regression.","code":"\n## add in fourier terms using the epiweek and case_int variabless\ncounts$fourier <- select(counts, epiweek, case_int) %>% \n  fourier(K = 1)"},{"path":"time-series-and-outbreak-detection.html","id":"negative-binomial","chapter":"2 Time series and outbreak detection","heading":"Negative binomial","text":"possible fit regressions using base stats MASS\r\nfunctions (e.g. lm(), glm() glm.nb()). However using \r\ntrending package, allows calculating appropriate confidence\r\nprediction intervals (otherwise available).\r\nsyntax , specify outcome variable tilde (~)\r\nadd various exposure variables interest separated plus (+).difference first define model fit() \r\ndata. useful allows comparing multiple different models\r\nsyntax.TIP: wanted use rates, rather \r\ncounts include population variable logarithmic offset term, adding\r\noffset(log(population). need set population 1, \r\nusing predict() order produce rate. TIP: fitting complex models \r\nARIMA prophet, see fable package.","code":"\n## define the model you want to fit (negative binomial) \nmodel <- glm_nb_model(\n  ## set number of cases as outcome of interest\n  case_int ~\n    ## use epiweek to account for the trend\n    epiweek +\n    ## use the fourier terms to account for seasonality\n    fourier)\n\n## fit your model using the counts dataset\nfitted_model <- trending::fit(model, counts)\n\n## calculate confidence intervals and prediction intervals \nobserved <- predict(fitted_model)\n\n## plot your regression \nggplot(data = observed, aes(x = epiweek)) + \n  ## add in a line for the model estimate\n  geom_line(aes(y = estimate),\n            col = \"Red\") + \n  ## add in a band for the prediction intervals \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## add in a line for your observed case counts\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()"},{"path":"time-series-and-outbreak-detection.html","id":"residuals","chapter":"2 Time series and outbreak detection","heading":"Residuals","text":"see well model fits observed data need look residuals.\r\nresiduals difference observed counts counts\r\nestimated model. calculate simply using case_int - estimate,\r\nresiduals() function extracts directly regression us.see , explaining variation\r\nmodel. might fit fourier terms,\r\naddress amplitude. However example leave .\r\nplots show model worse peaks troughs (counts \r\nhighest lowest) might likely underestimate\r\nobserved counts.","code":"\n## calculate the residuals \nobserved <- observed %>% \n  mutate(resid = residuals(fitted_model$fitted_model, type = \"response\"))\n\n## are the residuals fairly constant over time (if not: outbreaks? change in practice?)\nobserved %>%\n  ggplot(aes(x = epiweek, y = resid)) +\n  geom_line() +\n  geom_point() + \n  labs(x = \"epiweek\", y = \"Residuals\")\n## is there autocorelation in the residuals (is there a pattern to the error?)  \nobserved %>% \n  as_tsibble(index = epiweek) %>% \n  ACF(resid, lag_max = 52) %>% \n  autoplot()\n## are residuals normally distributed (are under or over estimating?)  \nobserved %>%\n  ggplot(aes(x = resid)) +\n  geom_histogram(binwidth = 100) +\n  geom_rug() +\n  labs(y = \"count\") \n## compare observed counts to their residuals \n  ## should also be no pattern \nobserved %>%\n  ggplot(aes(x = estimate, y = resid)) +\n  geom_point() +\n  labs(x = \"Fitted\", y = \"Residuals\")\n## formally test autocorrelation of the residuals\n## H0 is that residuals are from a white-noise series (i.e. random)\n## test for independence \n## if p value significant then non-random\nBox.test(observed$resid, type = \"Ljung-Box\")## \r\n##  Box-Ljung test\r\n## \r\n## data:  observed$resid\r\n## X-squared = 346.64, df = 1, p-value < 2.2e-16"},{"path":"time-series-and-outbreak-detection.html","id":"relation-of-two-time-series","chapter":"2 Time series and outbreak detection","heading":"2.6 Relation of two time series","text":"look using weather data (specifically temperature) explain\r\ncampylobacter case counts.","code":""},{"path":"time-series-and-outbreak-detection.html","id":"merging-datasets","chapter":"2 Time series and outbreak detection","heading":"Merging datasets","text":"can join datasets using week variable. merging see \r\nhandbook section joining.","code":"\n## left join so that we only have the rows already existing in counts\n## drop the date variable from temp_data (otherwise is duplicated)\ncounts <- left_join(counts, \n                    select(temp_data, -date),\n                    by = \"epiweek\")"},{"path":"time-series-and-outbreak-detection.html","id":"descriptive-analysis-1","chapter":"2 Time series and outbreak detection","heading":"Descriptive analysis","text":"First plot data see obvious relation.\r\nplot shows clear relation seasonality two\r\nvariables, temperature might peak weeks case number.\r\npivoting data, see handbook section pivoting data.","code":"\ncounts %>% \n  ## keep the variables we are interested \n  select(epiweek, case_int, t2m) %>% \n  ## change your data in to long format\n  pivot_longer(\n    ## use epiweek as your key\n    !epiweek,\n    ## move column names to the new \"measure\" column\n    names_to = \"measure\", \n    ## move cell values to the new \"values\" column\n    values_to = \"value\") %>% \n  ## create a plot with the dataset above\n  ## plot epiweek on the x axis and values (counts/celsius) on the y \n  ggplot(aes(x = epiweek, y = value)) + \n    ## create a separate plot for temperate and case counts \n    ## let them set their own y-axes\n    facet_grid(measure ~ ., scales = \"free_y\") +\n    ## plot both as a line\n    geom_line()"},{"path":"time-series-and-outbreak-detection.html","id":"lags-and-cross-correlation","chapter":"2 Time series and outbreak detection","heading":"Lags and cross-correlation","text":"formally test weeks highly related cases temperature.\r\ncan use cross-correlation function (CCF()) feasts package.\r\nalso visualise (rather using arrange) using autoplot() function.see lag 4 weeks highly correlated,\r\nmake lagged temperature variable include regression.","code":"\ncounts %>% \n  ## calculate cross-correlation between interpolated counts and temperature\n  CCF(case_int, t2m,\n      ## set the maximum lag to be 52 weeks\n      lag_max = 52, \n      ## return the correlation coefficient \n      type = \"correlation\") %>% \n  ## arange in decending order of the correlation coefficient \n  ## show the most associated lags\n  arrange(-ccf) %>% \n  ## only show the top ten \n  slice_head(n = 10)## Warning: Current temporal ordering may yield unexpected results.\r\n## i Suggest to sort by ``, `lag` first.## # A tsibble: 10 x 2 [1W]\r\n##      lag   ccf\r\n##    <lag> <dbl>\r\n##  1    4W 0.749\r\n##  2    5W 0.745\r\n##  3    3W 0.735\r\n##  4    6W 0.729\r\n##  5    2W 0.727\r\n##  6    7W 0.704\r\n##  7    1W 0.695\r\n##  8    8W 0.671\r\n##  9    0W 0.649\r\n## 10  -47W 0.638\ncounts <- counts %>% \n  ## create a new variable for temperature lagged by four weeks\n  mutate(t2m_lag4 = lag(t2m, n = 4))"},{"path":"time-series-and-outbreak-detection.html","id":"negative-binomial-with-two-variables","chapter":"2 Time series and outbreak detection","heading":"Negative binomial with two variables","text":"fit negative binomial regression done previously. time add \r\ntemperature variable lagged four weeks.investigate individual terms, can pull original negative binomial\r\nregression trending format using get_model() pass \r\nbroom package tidy() function retrieve exponentiated estimates associated\r\nconfidence intervals.shows us lagged temperature, controlling trend seasonality,\r\nsimilar case counts (estimate ~ 1) significantly associated.\r\nsuggests might good variable use predicting future case\r\nnumbers (climate forecasts readily available).quick visual inspection model shows might better job \r\nestimating observed case counts.","code":"\n## define the model you want to fit (negative binomial) \nmodel <- glm_nb_model(\n  ## set number of cases as outcome of interest\n  case_int ~\n    ## use epiweek to account for the trend\n    epiweek +\n    ## use the furier terms to account for seasonality\n    fourier + \n    ## use the temperature lagged by four weeks \n    t2m_lag4\n    )\n\n## fit your model using the counts dataset\nfitted_model <- trending::fit(model, counts)\n\n## calculate confidence intervals and prediction intervals \nobserved <- predict(fitted_model)\nfitted_model %>% \n  ## extract original negative binomial regression\n  get_model() %>% \n  ## get a tidy dataframe of results\n  tidy(exponentiate = TRUE, \n       conf.int = TRUE)## # A tibble: 5 x 7\r\n##   term           estimate  std.error statistic  p.value   conf.low  conf.high\r\n##   <chr>             <dbl>      <dbl>     <dbl>    <dbl>      <dbl>      <dbl>\r\n## 1 (Intercept)   5.83      0.108          53.8  0         5.61       6.04     \r\n## 2 epiweek       0.0000846 0.00000774     10.9  8.13e-28  0.0000695  0.0000998\r\n## 3 fourierS1-52 -0.285     0.0214        -13.3  1.84e-40 -0.327     -0.243    \r\n## 4 fourierC1-52 -0.195     0.0200         -9.78 1.35e-22 -0.234     -0.157    \r\n## 5 t2m_lag4      0.00667   0.00269         2.48 1.30e- 2  0.00139    0.0119\n## plot your regression \nggplot(data = observed, aes(x = epiweek)) + \n  ## add in a line for the model estimate\n  geom_line(aes(y = estimate),\n            col = \"Red\") + \n  ## add in a band for the prediction intervals \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## add in a line for your observed case counts\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()"},{"path":"time-series-and-outbreak-detection.html","id":"residuals-1","chapter":"2 Time series and outbreak detection","heading":"Residuals","text":"investigate residuals see well model fits observed data.\r\nresults interpretation similar previous regression,\r\nmay feasible stick simpler model without temperature.","code":"\n## calculate the residuals \nobserved <- observed %>% \n  mutate(resid = case_int - estimate)\n\n## are the residuals fairly constant over time (if not: outbreaks? change in practice?)\nobserved %>%\n  ggplot(aes(x = epiweek, y = resid)) +\n  geom_line() +\n  geom_point() + \n  labs(x = \"epiweek\", y = \"Residuals\")## Warning: Removed 4 row(s) containing missing values (geom_path).## Warning: Removed 4 rows containing missing values (geom_point).\n## is there autocorelation in the residuals (is there a pattern to the error?)  \nobserved %>% \n  as_tsibble(index = epiweek) %>% \n  ACF(resid, lag_max = 52) %>% \n  autoplot()\n## are residuals normally distributed (are under or over estimating?)  \nobserved %>%\n  ggplot(aes(x = resid)) +\n  geom_histogram(binwidth = 100) +\n  geom_rug() +\n  labs(y = \"count\") ## Warning: Removed 4 rows containing non-finite values (stat_bin).\n## compare observed counts to their residuals \n  ## should also be no pattern \nobserved %>%\n  ggplot(aes(x = estimate, y = resid)) +\n  geom_point() +\n  labs(x = \"Fitted\", y = \"Residuals\")## Warning: Removed 4 rows containing missing values (geom_point).\n## formally test autocorrelation of the residuals\n## H0 is that residuals are from a white-noise series (i.e. random)\n## test for independence \n## if p value significant then non-random\nBox.test(observed$resid, type = \"Ljung-Box\")## \r\n##  Box-Ljung test\r\n## \r\n## data:  observed$resid\r\n## X-squared = 339.52, df = 1, p-value < 2.2e-16"},{"path":"time-series-and-outbreak-detection.html","id":"outbreak-detection","chapter":"2 Time series and outbreak detection","heading":"2.7 Outbreak detection","text":"demonstrate two (similar) methods detecting outbreaks .\r\nfirst builds sections .\r\nuse trending package fit regressions previous years, \r\npredict expect see following year. observed counts \r\nexpect, suggest outbreak.\r\nsecond method based similar principles uses surveillance package,\r\nnumber different algorithms aberration detection.CAUTION: Normally, interested current year (know counts present week). example pretending week 52 2011.","code":""},{"path":"time-series-and-outbreak-detection.html","id":"trending-package","chapter":"2 Time series and outbreak detection","heading":"trending package","text":"method define baseline (usually 5 years data).\r\nfit regression baseline data, use predict estimates\r\nnext year.","code":""},{"path":"time-series-and-outbreak-detection.html","id":"cut-off-date","chapter":"2 Time series and outbreak detection","heading":"Cut-off date","text":"easier define dates one place use throughout \r\nrest code.define start date (observations started) cut-date\r\n(end baseline period - period want predict starts).\r\n~also define many weeks year interest (one going \r\npredicting)~.\r\nalso define many weeks baseline cut-end date\r\ninterested predicting .NOTE: example pretend currently end September 2011 (“2011 W39”).","code":"\n## define start date (when observations began)\nstart_date <- min(counts$epiweek)\n\n## define a cut-off week (end of baseline, start of prediction period)\ncut_off <- yearweek(\"2010-12-31\")\n\n## define the last date interested in (i.e. end of prediction)\nend_date <- yearweek(\"2011-12-31\")\n\n## find how many weeks in period (year) of interest\nnum_weeks <- as.numeric(end_date - cut_off)"},{"path":"time-series-and-outbreak-detection.html","id":"add-rows","chapter":"2 Time series and outbreak detection","heading":"Add rows","text":"able forecast tidyverse format, need right number\r\nrows dataset, .e. one row week end_datedefined .\r\ncode allows add rows grouping variable - example\r\nmultiple countries one dataset, group country \r\nadd rows appropriately .\r\ngroup_by_key() function tsibble allows us grouping\r\npass grouped data dplyr functions, group_modify() \r\nadd_row(). specify sequence weeks one maximum week\r\ncurrently available data end week.","code":"\n## add in missing weeks till end of year \ncounts <- counts %>%\n  ## group by the region\n  group_by_key() %>%\n  ## for each group add rows from the highest epiweek to the end of year\n  group_modify(~add_row(.,\n                        epiweek = seq(max(.$epiweek) + 1, \n                                      end_date,\n                                      by = 1)))"},{"path":"time-series-and-outbreak-detection.html","id":"fourier-terms-1","chapter":"2 Time series and outbreak detection","heading":"Fourier terms","text":"need redefine fourier terms - want fit baseline\r\ndate predict (extrapolate) terms next year.\r\nneed combine two output lists fourier() function together;\r\nfirst one baseline data, second one predicts \r\nyear interest (defining h argument).N.b. bind rows use rbind() (rather tidyverse bind_rows) \r\nfourier columns list (named individually).","code":"\n## define fourier terms (sincos) \ncounts <- counts %>% \n  mutate(\n    ## combine fourier terms for weeks prior to  and after 2010 cut-off date\n    ## (nb. 2011 fourier terms are predicted)\n    fourier = rbind(\n      ## get fourier terms for previous years\n      fourier(\n        ## only keep the rows before 2011\n        filter(counts, \n               epiweek <= cut_off), \n        ## include one set of sin cos terms \n        K = 1\n        ), \n      ## predict the fourier terms for 2011 (using baseline data)\n      fourier(\n        ## only keep the rows before 2011\n        filter(counts, \n               epiweek <= cut_off),\n        ## include one set of sin cos terms \n        K = 1, \n        ## predict 52 weeks ahead\n        h = num_weeks\n        )\n      )\n    )"},{"path":"time-series-and-outbreak-detection.html","id":"split-data-and-fit-regression","chapter":"2 Time series and outbreak detection","heading":"Split data and fit regression","text":"now split dataset baseline period prediction\r\nperiod. done using dplyr group_split() function group_by(),\r\ncreate list two data frames, one cut-one\r\n.use purrr package pluck() function pull datasets \r\nlist (equivalent using square brackets, e.g. dat[[1]]), can fit\r\nmodel baseline data, use predict() function data\r\ninterest cut-.See page Iteration learn purrr.previously, can visualise model ggplot. highlight alerts \r\nred dots observed counts 95% prediction interval.\r\ntime also add vertical line label forecast starts.","code":"\n# split data for fitting and prediction\ndat <- counts %>% \n  group_by(epiweek <= cut_off) %>%\n  group_split()\n\n## define the model you want to fit (negative binomial) \nmodel <- glm_nb_model(\n  ## set number of cases as outcome of interest\n  case_int ~\n    ## use epiweek to account for the trend\n    epiweek +\n    ## use the furier terms to account for seasonality\n    fourier\n)\n\n# define which data to use for fitting and which for predicting\nfitting_data <- pluck(dat, 2)\npred_data <- pluck(dat, 1) %>% \n  select(case_int, epiweek, fourier)\n\n# fit model \nfitted_model <- trending::fit(model, fitting_data)\n\n# get confint and estimates for fitted data\nobserved <- fitted_model %>% \n  predict()\n\n# forecast with data want to predict with \nforecasts <- fitted_model %>% \n  predict(pred_data)\n\n## combine baseline and predicted datasets\nobserved <- bind_rows(observed, forecasts)\n## plot your regression \nggplot(data = observed, aes(x = epiweek)) + \n  ## add in a line for the model estimate\n  geom_line(aes(y = estimate),\n            col = \"grey\") + \n  ## add in a band for the prediction intervals \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## add in a line for your observed case counts\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## plot in points for the observed counts above expected\n  geom_point(\n    data = filter(observed, case_int > upper_pi), \n    aes(y = case_int), \n    colour = \"red\", \n    size = 2) + \n  ## add vertical line and label to show where forecasting started\n  geom_vline(\n           xintercept = as.Date(cut_off), \n           linetype = \"dashed\") + \n  annotate(geom = \"text\", \n           label = \"Forecast\", \n           x = cut_off, \n           y = max(observed$upper_pi), \n           angle = 90, \n           vjust = 1\n           ) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()## Warning: Removed 13 row(s) containing missing values (geom_path)."},{"path":"time-series-and-outbreak-detection.html","id":"prediction-validation","chapter":"2 Time series and outbreak detection","heading":"Prediction validation","text":"Beyond inspecting residuals, important investigate good model \r\npredicting cases future. gives idea reliable \r\nthreshold alerts .traditional way validating see well can predict latest\r\nyear present one (don’t yet know counts “current year”).\r\nexample data set use data 2002 2009 predict 2010,\r\nsee accurate predictions . refit model include\r\n2010 data use predict 2011 counts.can seen figure Hyndman et al “Forecasting principles\r\npractice”.downside using data available , \r\nfinal model using prediction.alternative use method called cross-validation. scenario \r\nroll data available fit multiple models predict one year ahead.\r\nuse data model, seen figure \r\nHyndman et al text.\r\nexample, first model uses 2002 predict 2003, second uses 2002 \r\n2003 predict 2004, .\r\nuse purrr package map() function loop dataset.\r\nput estimates one data set merge original case counts,\r\nuse yardstick package compute measures accuracy.\r\ncompute four measures including: Root mean squared error (RMSE), Mean absolute error\r\n(MAE), Mean absolute scaled error (MASE), Mean absolute percent error (MAPE).","code":"\n## Cross validation: predicting week(s) ahead based on sliding window\n\n## expand your data by rolling over in 52 week windows (before + after) \n## to predict 52 week ahead\n## (creates longer and longer chains of observations - keeps older data)\n\n## define window want to roll over\nroll_window <- 52\n\n## define weeks ahead want to predict \nweeks_ahead <- 52\n\n## create a data set of repeating, increasingly long data\n## label each data set with a unique id\n## only use cases before year of interest (i.e. 2011)\ncase_roll <- counts %>% \n  filter(epiweek < cut_off) %>% \n  ## only keep the week and case counts variables\n  select(epiweek, case_int) %>% \n    ## drop the last x observations \n    ## depending on how many weeks ahead forecasting \n    ## (otherwise will be an actual forecast to \"unknown\")\n    slice(1:(n() - weeks_ahead)) %>%\n    as_tsibble(index = epiweek) %>% \n    ## roll over each week in x after windows to create grouping ID \n    ## depending on what rolling window specify\n    stretch_tsibble(.init = roll_window, .step = 1) %>% \n  ## drop the first couple - as have no \"before\" cases\n  filter(.id > roll_window)\n\n\n## for each of the unique data sets run the code below\nforecasts <- purrr::map(unique(case_roll$.id), \n                        function(i) {\n  \n  ## only keep the current fold being fit \n  mini_data <- filter(case_roll, .id == i) %>% \n    as_tibble()\n  \n  ## create an empty data set for forecasting on \n  forecast_data <- tibble(\n    epiweek = seq(max(mini_data$epiweek) + 1,\n                  max(mini_data$epiweek) + weeks_ahead,\n                  by = 1),\n    case_int = rep.int(NA, weeks_ahead),\n    .id = rep.int(i, weeks_ahead)\n  )\n  \n  ## add the forecast data to the original \n  mini_data <- bind_rows(mini_data, forecast_data)\n  \n  ## define the cut off based on latest non missing count data \n  cv_cut_off <- mini_data %>% \n    ## only keep non-missing rows\n    drop_na(case_int) %>% \n    ## get the latest week\n    summarise(max(epiweek)) %>% \n    ## extract so is not in a dataframe\n    pull()\n  \n  ## make mini_data back in to a tsibble\n  mini_data <- tsibble(mini_data, index = epiweek)\n  \n  ## define fourier terms (sincos) \n  mini_data <- mini_data %>% \n    mutate(\n    ## combine fourier terms for weeks prior to  and after cut-off date\n    fourier = rbind(\n      ## get fourier terms for previous years\n      forecast::fourier(\n        ## only keep the rows before cut-off\n        filter(mini_data, \n               epiweek <= cv_cut_off), \n        ## include one set of sin cos terms \n        K = 1\n        ), \n      ## predict the fourier terms for following year (using baseline data)\n      fourier(\n        ## only keep the rows before cut-off\n        filter(mini_data, \n               epiweek <= cv_cut_off),\n        ## include one set of sin cos terms \n        K = 1, \n        ## predict 52 weeks ahead\n        h = weeks_ahead\n        )\n      )\n    )\n  \n  \n  # split data for fitting and prediction\n  dat <- mini_data %>% \n    group_by(epiweek <= cv_cut_off) %>%\n    group_split()\n\n  ## define the model you want to fit (negative binomial) \n  model <- glm_nb_model(\n    ## set number of cases as outcome of interest\n    case_int ~\n      ## use epiweek to account for the trend\n      epiweek +\n      ## use the furier terms to account for seasonality\n      fourier\n  )\n\n  # define which data to use for fitting and which for predicting\n  fitting_data <- pluck(dat, 2)\n  pred_data <- pluck(dat, 1)\n  \n  # fit model \n  fitted_model <- trending::fit(model, fitting_data)\n  \n  # forecast with data want to predict with \n  forecasts <- fitted_model %>% \n    predict(pred_data) %>% \n    ## only keep the week and the forecast estimate\n    select(epiweek, estimate)\n    \n  }\n  )\n\n## make the list in to a data frame with all the forecasts\nforecasts <- bind_rows(forecasts)\n\n## join the forecasts with the observed\nforecasts <- left_join(forecasts, \n                       select(counts, epiweek, case_int),\n                       by = \"epiweek\")\n\n## using {yardstick} compute metrics\n  ## RMSE: Root mean squared error\n  ## MAE:  Mean absolute error  \n  ## MASE: Mean absolute scaled error\n  ## MAPE: Mean absolute percent error\nmodel_metrics <- bind_rows(\n  ## in your forcasted dataset compare the observed to the predicted\n  rmse(forecasts, case_int, estimate), \n  mae( forecasts, case_int, estimate),\n  mase(forecasts, case_int, estimate),\n  mape(forecasts, case_int, estimate),\n  ) %>% \n  ## only keep the metric type and its output\n  select(Metric  = .metric, \n         Measure = .estimate) %>% \n  ## make in to wide format so can bind rows after\n  pivot_wider(names_from = Metric, values_from = Measure)\n\n## return model metrics \nmodel_metrics## # A tibble: 1 x 4\r\n##    rmse   mae  mase  mape\r\n##   <dbl> <dbl> <dbl> <dbl>\r\n## 1  252.  199.  1.96  17.3"},{"path":"time-series-and-outbreak-detection.html","id":"surveillance-package","chapter":"2 Time series and outbreak detection","heading":"surveillance package","text":"section use surveillance package create alert thresholds\r\nbased outbreak detection algorithms. several different methods\r\navailable package, however focus two options .\r\ndetails, see papers application\r\ntheory\r\nalogirthms used.first option uses improved Farrington method. fits negative\r\nbinomial glm (including trend) -weights past outbreaks (outliers) \r\ncreate threshold level.second option use glrnb method. also fits negative binomial glm\r\nincludes trend fourier terms (favoured ). regression used\r\ncalculate “control mean” (~fitted values) - uses computed\r\ngeneralized likelihood ratio statistic assess shift mean\r\nweek. Note threshold week takes account previous\r\nweeks sustained shift alarm triggered.\r\n(Also note alarm algorithm reset)order work surveillance package, first need define \r\n“surveillance time series” object (using sts() function) fit within \r\nframework.","code":"\n## define surveillance time series object\n## nb. you can include a denominator with the population object (see ?sts)\ncounts_sts <- sts(observed = counts$case_int[!is.na(counts$case_int)],\n                  start = c(\n                    ## subset to only keep the year from start_date \n                    as.numeric(str_sub(start_date, 1, 4)), \n                    ## subset to only keep the week from start_date\n                    as.numeric(str_sub(start_date, 7, 8))), \n                  ## define the type of data (in this case weekly)\n                  freq = 52)\n\n## define the week range that you want to include (ie. prediction period)\n## nb. the sts object only counts observations without assigning a week or \n## year identifier to them - so we use our data to define the appropriate observations\nweekrange <- cut_off - start_date"},{"path":"time-series-and-outbreak-detection.html","id":"farrington-method","chapter":"2 Time series and outbreak detection","heading":"Farrington method","text":"define parameters Farrington method list.\r\nrun algorithm using farringtonFlexible() can extract \r\nthreshold alert using farringtonmethod@upperboundto include \r\ndataset. also possible extract TRUE/FALSE week triggered\r\nalert (threshold) using farringtonmethod@alarm.can visualise results ggplot done previously.","code":"\n## define control\nctrl <- list(\n  ## define what time period that want threshold for (i.e. 2011)\n  range = which(counts_sts@epoch > weekrange),\n  b = 9, ## how many years backwards for baseline\n  w = 2, ## rolling window size in weeks\n  weightsThreshold = 2.58, ## reweighting past outbreaks (improved noufaily method - original suggests 1)\n  ## pastWeeksNotIncluded = 3, ## use all weeks available (noufaily suggests drop 26)\n  trend = TRUE,\n  pThresholdTrend = 1, ## 0.05 normally, however 1 is advised in the improved method (i.e. always keep)\n  thresholdMethod = \"nbPlugin\",\n  populationOffset = TRUE\n  )\n\n## apply farrington flexible method\nfarringtonmethod <- farringtonFlexible(counts_sts, ctrl)\n\n## create a new variable in the original dataset called threshold\n## containing the upper bound from farrington \n## nb. this is only for the weeks in 2011 (so need to subset rows)\ncounts[which(counts$epiweek >= cut_off & \n               !is.na(counts$case_int)),\n              \"threshold\"] <- farringtonmethod@upperbound\nggplot(counts, aes(x = epiweek)) + \n  ## add in observed case counts as a line\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## add in upper bound of aberration algorithm\n  geom_line(aes(y = threshold, colour = \"Alert threshold\"), \n            linetype = \"dashed\", \n            size = 1.5) +\n  ## define colours\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Alert threshold\" = \"red\")) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic() + \n  ## remove title of legend \n  theme(legend.title = element_blank())"},{"path":"time-series-and-outbreak-detection.html","id":"glrnb-method","chapter":"2 Time series and outbreak detection","heading":"GLRNB method","text":"Similarly GLRNB method define parameters list,\r\nfit algorithm extract upper bounds.CAUTION: method uses “brute force” (similar bootstrapping) calculating thresholds, can take long time!See GLRNB vignette\r\ndetails.Visualise outputs previously.","code":"\n## define control options\nctrl <- list(\n  ## define what time period that want threshold for (i.e. 2011)\n  range = which(counts_sts@epoch > weekrange),\n  mu0 = list(S = 1,    ## number of fourier terms (harmonics) to include\n  trend = TRUE,   ## whether to include trend or not\n  refit = FALSE), ## whether to refit model after each alarm\n  ## cARL = threshold for GLR statistic (arbitrary)\n     ## 3 ~ middle ground for minimising false positives\n     ## 1 fits to the 99%PI of glm.nb - with changes after peaks (threshold lowered for alert)\n   c.ARL = 2,\n   # theta = log(1.5), ## equates to a 50% increase in cases in an outbreak\n   ret = \"cases\"     ## return threshold upperbound as case counts\n  )\n\n## apply the glrnb method\nglrnbmethod <- glrnb(counts_sts, control = ctrl, verbose = FALSE)\n\n## create a new variable in the original dataset called threshold\n## containing the upper bound from glrnb \n## nb. this is only for the weeks in 2011 (so need to subset rows)\ncounts[which(counts$epiweek >= cut_off & \n               !is.na(counts$case_int)),\n              \"threshold_glrnb\"] <- glrnbmethod@upperbound\nggplot(counts, aes(x = epiweek)) + \n  ## add in observed case counts as a line\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## add in upper bound of aberration algorithm\n  geom_line(aes(y = threshold_glrnb, colour = \"Alert threshold\"), \n            linetype = \"dashed\", \n            size = 1.5) +\n  ## define colours\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Alert threshold\" = \"red\")) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic() + \n  ## remove title of legend \n  theme(legend.title = element_blank())"},{"path":"time-series-and-outbreak-detection.html","id":"interrupted-timeseries","chapter":"2 Time series and outbreak detection","heading":"2.8 Interrupted timeseries","text":"Interrupted timeseries (also called segmented regression intervention analysis),\r\noften used assessing impact vaccines incidence disease.\r\ncan used assessing impact wide range interventions introductions.\r\nexample changes hospital procedures introduction new disease\r\nstrain population.\r\nexample pretend new strain Campylobacter introduced\r\nGermany end 2008, see affects number cases.\r\nuse negative binomial regression . regression time \r\nsplit two parts, one intervention (introduction new strain )\r\none (pre post-periods). allows us calculate incidence rate ratio comparing \r\ntwo time periods. Explaining equation might make clearer (just\r\nignore!).negative binomial regression can defined follows:\\[\\log(Y_t)= β_0 + β_1 \\times t+ β_2 \\times δ(t-t_0) + β_3\\times(t-t_0 )^+ + log(pop_t) + e_t\\]:\r\n\\(Y_t\\)number cases observed time \\(t\\)\\(pop_t\\) population size 100,000s time \\(t\\) (used )\\(t_0\\) last year pre-period (including transition time )\\(δ(x\\) indicator function (0 x≤0 1 x>0)\\((x)^+\\) cut operator (x x>0 0 otherwise)\\(e_t\\) denotes residual\r\nAdditional terms trend season can added needed.\\(β_2 \\times δ(t-t_0) + β_3\\times(t-t_0 )^+\\) generalised linear\r\npart post-period zero pre-period.\r\nmeans \\(β_2\\) \\(β_3\\) estimates effects intervention.need re-calculate fourier terms without forecasting , use\r\ndata available us (.e. retrospectively). Additionally need calculate\r\nextra terms needed regression.use terms fit negative binomial regression, produce \r\ntable percentage change. example shows \r\nsignificant change.previously can visualise outputs regression.","code":"\n## add in fourier terms using the epiweek and case_int variabless\ncounts$fourier <- select(counts, epiweek, case_int) %>% \n  as_tsibble(index = epiweek) %>% \n  fourier(K = 1)\n\n## define intervention week \nintervention_week <- yearweek(\"2008-12-31\")\n\n## define variables for regression \ncounts <- counts %>% \n  mutate(\n    ## corresponds to t in the formula\n      ## count of weeks (could probably also just use straight epiweeks var)\n    # linear = row_number(epiweek), \n    ## corresponds to delta(t-t0) in the formula\n      ## pre or post intervention period\n    intervention = as.numeric(epiweek >= intervention_week), \n    ## corresponds to (t-t0)^+ in the formula\n      ## count of weeks post intervention\n      ## (choose the larger number between 0 and whatever comes from calculation)\n    time_post = pmax(0, epiweek - intervention_week + 1))\n## define the model you want to fit (negative binomial) \nmodel <- glm_nb_model(\n  ## set number of cases as outcome of interest\n  case_int ~\n    ## use epiweek to account for the trend\n    epiweek +\n    ## use the furier terms to account for seasonality\n    fourier + \n    ## add in whether in the pre- or post-period \n    intervention + \n    ## add in the time post intervention \n    time_post\n    )\n\n## fit your model using the counts dataset\nfitted_model <- trending::fit(model, counts)\n\n## calculate confidence intervals and prediction intervals \nobserved <- predict(fitted_model)\n\n\n\n## show estimates and percentage change in a table\nfitted_model %>% \n  ## extract original negative binomial regression\n  get_model() %>% \n  ## get a tidy dataframe of results\n  tidy(exponentiate = TRUE, \n       conf.int = TRUE) %>% \n  ## only keep the intervention value \n  filter(term == \"intervention\") %>% \n  ## change the IRR to percentage change for estimate and CIs \n  mutate(\n    ## for each of the columns of interest - create a new column\n    across(\n      all_of(c(\"estimate\", \"conf.low\", \"conf.high\")), \n      ## apply the formula to calculate percentage change\n            .f = function(i) 100 * (i - 1), \n      ## add a suffix to new column names with \"_perc\"\n      .names = \"{.col}_perc\")\n    ) %>% \n  ## only keep (and rename) certain columns \n  select(\"IRR\" = estimate, \n         \"95%CI low\" = conf.low, \n         \"95%CI high\" = conf.high,\n         \"Percentage change\" = estimate_perc, \n         \"95%CI low (perc)\" = conf.low_perc, \n         \"95%CI high (perc)\" = conf.high_perc,\n         \"p-value\" = p.value)## # A tibble: 1 x 7\r\n##       IRR `95%CI low` `95%CI high` `Percentage change` `95%CI low (perc)` `95%CI high (perc)` `p-value`\r\n##     <dbl>       <dbl>        <dbl>               <dbl>              <dbl>               <dbl>     <dbl>\r\n## 1 -0.0661      -0.135      0.00305               -107.              -113.               -99.7    0.0645\nggplot(observed, aes(x = epiweek)) + \n  ## add in observed case counts as a line\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## add in a line for the model estimate\n  geom_line(aes(y = estimate, col = \"Estimate\")) + \n  ## add in a band for the prediction intervals \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## add vertical line and label to show where forecasting started\n  geom_vline(\n           xintercept = as.Date(intervention_week), \n           linetype = \"dashed\") + \n  annotate(geom = \"text\", \n           label = \"Intervention\", \n           x = intervention_week, \n           y = max(observed$upper_pi), \n           angle = 90, \n           vjust = 1\n           ) + \n  ## define colours\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Estimate\" = \"red\")) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()## Warning: Removed 13 row(s) containing missing values (geom_path)."},{"path":"time-series-and-outbreak-detection.html","id":"resources-1","chapter":"2 Time series and outbreak detection","heading":"2.9 Resources","text":"forecasting: principles practice textbookEPIET timeseries analysis case studiesPenn State course\r\nSurveillance package manuscript","code":""}]
