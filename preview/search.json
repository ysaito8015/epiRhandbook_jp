[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"","code":""},{"path":"index.html","id":"about-this-handbook","chapter":"Welcome","heading":"About this handbook","text":"free open-access R reference guide intended applied epidemiologists.book strives :Serve quick reference guide - textbookAddress common epidemiological problems via task-centered examplesBe accessible settings limited technical support low internet-connectivity (downloadable version)Contain clear simple language, step--step instructions many commentsBe living document, growing adapting new best practicesWhat gaps book address?Many epidemiologists formal training R data science, transitioning R SAS, STATA, statistical software.R universe changes frequently - place best practice code catered toward common epidemiologist user.Epidemiologists often must read dozens online forum pages answers, epidemiology-oriented.epidemiologists work low internet-connectivity environments limited technical support.different R books?handbook written epidemiologists, epidemiologists. Examples taken lived experience local, national, academic, emergency settings. also offered download-able format bring settings unreliable internet. addition core R concepts tools, book covers:epidemic curvestransmission chains performing epidemic modelingage pyramidsage sex standardizationprobabilistic matching datasets name similarity, age, sex, etc.outbreak detection methodssurvey analysiscausal diagramssurvival analysisGIS basics - including catchment area calculationphylogenetic treesmissing data imputationroutinized reports Rmarkdown","code":""},{"path":"index.html","id":"how-to-read-this-handbook","chapter":"Welcome","heading":"How to read this handbook","text":"Search via search box Table ContentsClick “clipboard” “copy” icon copy codeSee “Resources” section page links trainingClick download offline versionIf use handbook suggestions, let us know SURVEY LINK!","code":""},{"path":"index.html","id":"edit-or-contribute","chapter":"Welcome","heading":"Edit or contribute","text":"suggestions want contribute content, please post issue github repository.","code":""},{"path":"index.html","id":"acknowledgements","chapter":"Welcome","heading":"Acknowledgements","text":"","code":""},{"path":"index.html","id":"contributors","chapter":"Welcome","heading":"Contributors","text":"handbook collaborative team production; conceived, written, edited epidemiologists public health practitioners around world. team members:Editor--Chief:Editorial core team: …(list)…Authors: …(list)…Reviewers: …(list)…Advisers …(list)…","code":""},{"path":"index.html","id":"funding-and-programmatic-support","chapter":"Welcome","heading":"Funding and programmatic support","text":"Training Programs Epidemiology Public Health Interventions Network (TEPHINET)EPIET Alumni Network (EAN)","code":""},{"path":"index.html","id":"data-sources","chapter":"Welcome","heading":"Data sources","text":"linelist used much handbook adapted simulated Ebola outbreak linelist outbreaks package","code":""},{"path":"index.html","id":"inspiration","chapter":"Welcome","heading":"Inspiration","text":"“R4Epis” project (collaboration MSF RECON)R Epidemics Consortium (RECON)R Data Science book (R4DS)bookdown: Authoring Books Technical Documents R Markdown\r\nspecific tutorials vignettes credited relevant pages","code":""},{"path":"index.html","id":"image-credits","chapter":"Welcome","heading":"Image credits","text":"Logo: CDC Public Health Image library, R Graph Gallery2013 Yemen looking mosquito breeding sitesEbola virusSurvey RajasthanNetwork","code":""},{"path":"index.html","id":"license-and-terms-of-use","chapter":"Welcome","heading":"License and Terms of Use","text":"Creative Commons license TBD…","code":""},{"path":"cleaning-data.html","id":"cleaning-data","chapter":"1 Cleaning data","heading":"1 Cleaning data","text":"","code":""},{"path":"cleaning-data.html","id":"overview","chapter":"1 Cleaning data","heading":"1.1 Overview","text":"page demonstrates common steps necessary clean dataset, starting importing raw data demonstrating “pipe chain” cleaning steps.page uses simulated Ebola case linelist, referenced throughout handbook.functions described page:%>% - pipe pass dataset one function nextmutate() - create, transform, re-define columnsselect() - select re-name columnsrename() - rename columnsacross() - transform multiple columns one timefilter() - keep certain rowsadd_row() - add row manuallyclean_names() - standardize syntax column namesas.characer(), .numeric(), .Date(), etc. - convert class columnrecode() - re-code values columncase_when() - re-code values column using complex logical criteriareplace_na(), na_if(), coalesce() - special functions re-codingclean_data() - re-code/clean using data dictionaryage_categories() cut() - create categorical groups numeric columndistinct() - de-duplicate rows","code":""},{"path":"cleaning-data.html","id":"cleaning-pipeline","chapter":"1 Cleaning data","heading":"1.2 Cleaning pipeline","text":"epidemiological analysis data processing, cleaning steps often performed linked together, sequentially. R often manifests cleaning “pipeline”, raw dataset passed “piped” one cleaning step another.chain utilizes dplyr verbs magrittr pipe operator (see handbook page dplyr tidyverse coding style (LINK ). pipe begins “raw” data (linelist_raw) ends “clean” dataset (linelist).cleaning pipeline order steps important. Cleaning steps might include:Importing dataColumn names cleaned changedRows filtered, added, de-duplicatedColumns selected, added, transformed, re-orderedValues re-coded, cleaned, grouped","code":""},{"path":"cleaning-data.html","id":"load-packages","chapter":"1 Cleaning data","heading":"1.3 Load packages","text":"packages used page clean data:","code":"\npacman::p_load(\n  rio,        # importing data  \n  here,       # relative file pathways  \n  janitor,    # data cleaning\n  lubridate,  # working with dates\n  epikit,     # age_categories() function\n  tidyverse   # data manipulation and visualization\n)"},{"path":"cleaning-data.html","id":"import-data","chapter":"1 Cleaning data","heading":"1.4 Import data","text":"import raw .xlsx dataset using import() function package rio, save dataframe linelist_raw. dataset large takes long time import, can useful import command separate pipe chain “raw” saved distinct file. also allows easy comparison original cleaned versions.See page importing data details. (LINK IMPORT PAGE)can view first 50 rows original “raw” dataset :","code":"\nlinelist_raw <- import(\"linelist_raw.xlsx\")"},{"path":"cleaning-data.html","id":"skip-import-of-rows","chapter":"1 Cleaning data","heading":"1.4.1 Skip import of rows","text":"Sometimes, may want avoid importing row data (e.g. column names, row 1).\r\ncan argument skip = using import() rio package .xlsx .csv file. Provide number rows want skip.Unfortunately skip = accepts one integer value, range (e.g. “2:10”). skip import specific rows consecutive top, consider importing multiple times using bind_rows() dplyr. See example skipping row 2.","code":"\nlinelist_raw <- import(\"linelist_raw.xlsx\", skip = 1)  # does not import header row"},{"path":"cleaning-data.html","id":"remove-a-second-header-row","chapter":"1 Cleaning data","heading":"1.4.2 Remove a second header row","text":"data may second row data, example may “data dictionary” row looks like :situation can problematic can result columns imported class “character”, even numbers another class. solve , likely need import data twice.Import data order store correct column namesImport data , skipping first two rows (header second rows)Bind correct names onto reduced dataframeThe exact arguments used bind correct column names depends type data file (.csv, .tsv, .xlsx, etc.). using rio’s import() function, understand function rio uses import data, give appropriate argument skip lines /designate column names. See handbook page importing data (LINK) details rio.Excel files:CSV files:Backup option - changing column names separate command","code":"\n# For excel files (remove 2nd row)\nlinelist_raw_names <- import(\"linelist_raw.xlsx\") %>% names()  # save true column names\n\n# import, skip row 2, assign to col_names =\nlinelist_raw <- import(\"linelist_raw.xlsx\", skip = 2, col_names = linelist_raw_names) \n# For csv files\nlinelist_raw_names <- import(\"linelist_raw.csv\") %>% names() # save true column names\n\n# note argument is 'col.names ='\nlinelist_raw <- import(\"linelist_raw.csv\", skip = 2, col.names = linelist_raw_names) \n# assign/overwrite headers using the base 'colnames()' function\ncolnames(linelist_raw) <- linelist_raw_names"},{"path":"cleaning-data.html","id":"create-a-data-dictionary","chapter":"1 Cleaning data","heading":"1.4.3 Create a data dictionary","text":"Bonus! second row data dictionary, can easily create proper data dictionary using gather() command tidyr package. tip adapted post.","code":"\ndict <- linelist_2headers %>%             # begin: linelist with dictionary as first row\n  head(1) %>%                             # keep only column names and first dictionary row                \n  pivot_longer(cols = everything(),       # pivot all columns to long format\n               names_to = \"Column\",       # assign new column names\n               values_to = \"Description\")"},{"path":"cleaning-data.html","id":"combine-two-header-rows","chapter":"1 Cleaning data","heading":"1.4.4 Combine two header rows","text":"cases, may want combine two header rows one. command define column names combination (pasting together) existing column names value underneath first row. Replace “df” name dataset.","code":"\nnames(df) <- paste(names(df), df[1, ], sep = \"_\")"},{"path":"cleaning-data.html","id":"column-names","chapter":"1 Cleaning data","heading":"1.5 Column names","text":"Column names used often must “clean” syntax. suggest following:Short namesNo spaces (replaced underscores (_),unusual characters (&, #, <, >, …)Similar style nomenclature (e.g. date columns named like date_onset, date_report, date_death…)columns names linelist_raw . can see :contain spacesDifferent naming patterns used dates (‘date onset’ vs. ‘infection date’)must merged header across two last columns .xlsx - resolve , import() used name first two columns (“merged_header”), assigned second column name “…28”, empty (28th column)Note: column name include spaces, surround name back-ticks, example: linelist$`infection date`. note keyboard, back-tick (`) different single quotation mark (’).","code":"\nnames(linelist_raw)##  [1] \"case_id\"         \"generation\"      \"infection date\"  \"date onset\"      \"hosp date\"       \"date_of_outcome\" \"outcome\"        \r\n##  [8] \"gender\"          \"hospital\"        \"lon\"             \"lat\"             \"infector\"        \"source\"          \"age\"            \r\n## [15] \"age_unit\"        \"row_num\"         \"wt_kg\"           \"ht_cm\"           \"ct_blood\"        \"fever\"           \"chills\"         \r\n## [22] \"cough\"           \"aches\"           \"vomit\"           \"temp\"            \"time_admission\"  \"merged_header\"   \"...28\""},{"path":"cleaning-data.html","id":"automatic-name-cleaning","chapter":"1 Cleaning data","heading":"1.5.1 Automatic name cleaning","text":"function clean_names() package janitor standardizes column names makes unique following:Converts names consist underscores, numbers, lettersAccented characters transliterated ASCII (e.g. german o umlaut becomes “o”, spanish “enye” becomes “n”)Capitalization preference can specified using case = argument (“snake” default, alternatives include “sentence”, “title”, “small_camel”…)can designate specific name replacements replace = argument (e.g. replace = c(onset = “date_of_onset”))online vignetteBelow, cleaning pipeline begins using clean_names() raw linelist.NOTE: last column name “…28” changed “x28”.","code":"\n# send the dataset through the function clean_names()\nlinelist <- linelist_raw %>% \n  janitor::clean_names()\n\n# see the new names\nnames(linelist)##  [1] \"case_id\"         \"generation\"      \"infection_date\"  \"date_onset\"      \"hosp_date\"       \"date_of_outcome\" \"outcome\"        \r\n##  [8] \"gender\"          \"hospital\"        \"lon\"             \"lat\"             \"infector\"        \"source\"          \"age\"            \r\n## [15] \"age_unit\"        \"row_num\"         \"wt_kg\"           \"ht_cm\"           \"ct_blood\"        \"fever\"           \"chills\"         \r\n## [22] \"cough\"           \"aches\"           \"vomit\"           \"temp\"            \"time_admission\"  \"merged_header\"   \"x28\""},{"path":"cleaning-data.html","id":"manual-name-cleaning","chapter":"1 Cleaning data","heading":"1.5.2 Manual name cleaning","text":"Re-naming columns manually often necessary. , re-naming performed using rename() function dplyr package, part pipe chain. rename() uses style “NEW = OLD”, new column name given old column name., re-name command added cleaning pipeline:Now can see columns names changed:","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome)##  [1] \"case_id\"              \"generation\"           \"date_infection\"       \"date_onset\"           \"date_hospitalisation\"\r\n##  [6] \"date_outcome\"         \"outcome\"              \"gender\"               \"hospital\"             \"lon\"                 \r\n## [11] \"lat\"                  \"infector\"             \"source\"               \"age\"                  \"age_unit\"            \r\n## [16] \"row_num\"              \"wt_kg\"                \"ht_cm\"                \"ct_blood\"             \"fever\"               \r\n## [21] \"chills\"               \"cough\"                \"aches\"                \"vomit\"                \"temp\"                \r\n## [26] \"time_admission\"       \"merged_header\"        \"x28\""},{"path":"cleaning-data.html","id":"rename-by-column-position","chapter":"1 Cleaning data","heading":"Rename by column position","text":"can also rename column position, instead column name, example:","code":"\nrename(newNameForFirstColumn  = 1,\n       newNameForSecondColumn = 2)"},{"path":"cleaning-data.html","id":"rename-via-select","chapter":"1 Cleaning data","heading":"Rename via select()","text":"can also rename columns within dplyr select() function, used retain certain columns (covered later page). approach also uses format new_name = old_name. example:","code":"\nlinelist_raw %>% \n  select(# NEW name             # OLD name\n         date_infection       = `infection date`,    # rename and KEEP ONLY these columns\n         date_hospitalisation = `hosp date`)"},{"path":"cleaning-data.html","id":"other-name-challenges","chapter":"1 Cleaning data","heading":"1.5.3 Other name challenges","text":"","code":""},{"path":"cleaning-data.html","id":"empty-excel-column-names","chapter":"1 Cleaning data","heading":"Empty Excel column names","text":"importing Excel sheet missing column name, depending import function used, R likely create column name value like “…1” “…2”. can clean names manually referencing position number (see example ), name (linelist_raw$...1).","code":""},{"path":"cleaning-data.html","id":"merged-excel-column-names","chapter":"1 Cleaning data","heading":"Merged Excel column names","text":"Merged cells Excel file common occurrence receiving data field level. Merged cells can nice human reading data, cause many problems machine reading data. R accommodate merged cells.Remind people data entry human-readable data machine-readable data. Strive train users principles tidy data. possible, try change procedures data arrive tidy format without merged cells.variable must column.observation must row.value must cell.using rio’s import() function, value merged cell assigned first cell subsequent cells empty.One solution deal merged cells import data function readWorkbook() package openxlsx. Set argument fillMergedCells = TRUE. gives value merged cell cells within merge range.DANGER: column names merged, end duplicate column names, need fix manually - R work well duplicate column names! can re-name referencing position (e.g. column 5), explained section manual column name cleaning..","code":"\nlinelist_raw <- openxlsx::readWorkbook(\"linelist_raw.xlsx\", fillMergedCells = TRUE)"},{"path":"cleaning-data.html","id":"select-or-re-order-columns","chapter":"1 Cleaning data","heading":"1.6 Select or re-order columns","text":"Often first step cleaning data selecting columns want work , set order dataframe. dplyr chain verbs, done select().CAUTION: examples , linelist modified select() -written. New column names displayed purpose example.column names linelist:","code":"\nnames(linelist)##  [1] \"case_id\"              \"generation\"           \"date_infection\"       \"date_onset\"           \"date_hospitalisation\"\r\n##  [6] \"date_outcome\"         \"outcome\"              \"gender\"               \"hospital\"             \"lon\"                 \r\n## [11] \"lat\"                  \"infector\"             \"source\"               \"age\"                  \"age_unit\"            \r\n## [16] \"row_num\"              \"wt_kg\"                \"ht_cm\"                \"ct_blood\"             \"fever\"               \r\n## [21] \"chills\"               \"cough\"                \"aches\"                \"vomit\"                \"temp\"                \r\n## [26] \"time_admission\"       \"merged_header\"        \"x28\""},{"path":"cleaning-data.html","id":"keep-columns","chapter":"1 Cleaning data","heading":"1.6.1 Keep columns","text":"Select columns want remainPut names select() command, quotation marks. appear order provide.","code":"\n# linelist dataset is piped through select() command, and names() prints just the column names\nlinelist %>% \n  select(case_id, date_onset, date_hospitalisation, fever) %>% \n  names()  # display the column names## [1] \"case_id\"              \"date_onset\"           \"date_hospitalisation\" \"fever\""},{"path":"cleaning-data.html","id":"helper-functions","chapter":"1 Cleaning data","heading":"1.6.2 Helper functions","text":"Helper functions operators exist make easy specify columns.example, want re-order columns, everything() useful signify columns yet mentions. command pulls columns date_onset date_hospitalisation beginning:well everything() helpers functions work within select():everything() - columns mentionedlast_col() - last columnwhere() - applies function columns selects TRUEstarts_with() - matches specified prefix. Example: select(starts_with(\"date\"))ends_with() - matches specified suffix. Example: select(ends_with(\"_end\"))contains() - columns containing character string. Example: select(contains(\"time\"))matches() - apply regular expression (regex). Example: select(contains(\"[pt]al\"))num_range() -any_of() - matches column named. Useful name might exist. Example: select(any_of(date_onset, date_death, cardiac_arrest))addition, use normal operators c() list several columns, : consecutive columns, ! opposite, & , | .Use () specify logical criteria columns. providing function inside (), include empty parentheses. selects columns class Numeric.Use contains() select columns column name contains string. ends_with() starts_with() provide nuance.function matches() works similarly contains() can provided regular expression (LINK), multiple strings separated bars within parentheses:CAUTION: column name specifically provide exist data, can return error stop code. Consider using any_of() cite columns may may exist, especially useful negative (remove) selections.","code":"\n# move case_id, date_onset, date_hospitalisation, and gender to beginning\nlinelist %>% \n  select(date_onset, date_hospitalisation, everything()) %>% \n  names()##  [1] \"date_onset\"           \"date_hospitalisation\" \"case_id\"              \"generation\"           \"date_infection\"      \r\n##  [6] \"date_outcome\"         \"outcome\"              \"gender\"               \"hospital\"             \"lon\"                 \r\n## [11] \"lat\"                  \"infector\"             \"source\"               \"age\"                  \"age_unit\"            \r\n## [16] \"row_num\"              \"wt_kg\"                \"ht_cm\"                \"ct_blood\"             \"fever\"               \r\n## [21] \"chills\"               \"cough\"                \"aches\"                \"vomit\"                \"temp\"                \r\n## [26] \"time_admission\"       \"merged_header\"        \"x28\"\n# select columns that are class Numeric\nlinelist %>% \n  select(where(is.numeric)) %>% \n  names()## [1] \"generation\" \"lon\"        \"lat\"        \"row_num\"    \"wt_kg\"      \"ht_cm\"      \"ct_blood\"   \"temp\"\n# select columns containing certain characters\nlinelist %>% \n  select(contains(\"date\")) %>% \n  names()## [1] \"date_infection\"       \"date_onset\"           \"date_hospitalisation\" \"date_outcome\"\n# searched for multiple character matches\nlinelist %>% \n  select(matches(\"onset|hosp|fev\")) %>%   # note the OR symbol \"|\"\n  names()## [1] \"date_onset\"           \"date_hospitalisation\" \"hospital\"             \"fever\"\nlinelist %>% \n  select(any_of(c(\"village_origin\", \"village_detection\", \"village_residence\", \"village_travel\"))) %>% \n  names()## character(0)"},{"path":"cleaning-data.html","id":"remove-columns","chapter":"1 Cleaning data","heading":"1.6.3 Remove columns","text":"Indicate columns remove placing minus symbol “-” front column name (e.g. select(-outcome)), vector column names (). columns retained.","code":"\nlinelist %>% \n  select(-c(date_onset, fever:vomit)) %>% # remove onset and all symptom columns\n  names()##  [1] \"case_id\"              \"generation\"           \"date_infection\"       \"date_hospitalisation\" \"date_outcome\"        \r\n##  [6] \"outcome\"              \"gender\"               \"hospital\"             \"lon\"                  \"lat\"                 \r\n## [11] \"infector\"             \"source\"               \"age\"                  \"age_unit\"             \"row_num\"             \r\n## [16] \"wt_kg\"                \"ht_cm\"                \"ct_blood\"             \"temp\"                 \"time_admission\"      \r\n## [21] \"merged_header\"        \"x28\""},{"path":"cleaning-data.html","id":"standalone","chapter":"1 Cleaning data","heading":"1.6.4 Standalone","text":"select() can also used independent command (pipe chain). case, first argument original dataframe operated upon.Add pipe chainIn linelist, columns need: row_num, merged_header, x28. Remove adding select() command cleaning pipe chain:","code":"\n# Create a new linelist with id and age-related columns\nlinelist_age <- select(linelist, case_id, contains(\"age\"))\n\n# display the column names\nnames(linelist_age)## [1] \"case_id\"  \"age\"      \"age_unit\"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    #####################################################\n\n    # remove column\n    select(-c(row_num, merged_header, x28))"},{"path":"cleaning-data.html","id":"deduplication","chapter":"1 Cleaning data","heading":"1.7 Deduplication","text":"See handbook page de-duplications (LINK). simple de-duplication addressed .package dplyr offers distinct() function reduce dataframe unique rows - removing rows 100% duplicates.\r\njust add simple command distinct() pipe chain:begin 6609 rows linelist.de-duplication 6479 rows., distinct() command added cleaning pipe chain:","code":"\nlinelist <- linelist %>% \n  distinct()\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    #####################################################\n    \n    # de-duplicate\n    distinct()"},{"path":"cleaning-data.html","id":"column-creation-and-transformation","chapter":"1 Cleaning data","heading":"1.8 Column creation and transformation","text":"verb mutate() used add new column, modify existing one. example creating new columns mutate(). syntax : mutate(new_column_name = value transformation)","code":""},{"path":"cleaning-data.html","id":"new-columns","chapter":"1 Cleaning data","heading":"1.8.1 New columns","text":"basic mutate() command create new column might look like . creates new column new_col value every row 10.can also reference values columns, perform calculations. example Body Mass Index (BMI) calculated height weight using formula BMI = kg/m^2.creating multiple new columns, separate comma new line. , examples ways new columns, including pasting together values columns using str_glue() stringr package:Scroll right see new columns (first 50 rows shown):TIP: verb transmute() adds new columns just like mutate() also drops/removes columns mention.","code":"\nlinelist <- linelist %>% \n  mutate(new_col = 10)\nlinelist <- linelist %>% \n  mutate(bmi = wt_kg / (ht_cm/100)^2)\nlinelist <- linelist %>%                       \n  mutate(new_var_dup    = case_id,             # new column = duplicate/copy another existing column\n         new_var_static = 7,                   # new column = all values the same\n         new_var_static = new_var_static + 5,  # you can overwrite a column, and it can be a calculation using other variables\n         new_var_paste  = stringr::str_glue(\"{hospital} on ({date_hospitalisation})\") # new column = pasting together values from other columns\n         ) "},{"path":"cleaning-data.html","id":"add-or-transform-columns-using-base-r","chapter":"1 Cleaning data","heading":"1.8.2 Add or transform columns using base R","text":"define new column (re-define column) using base R, just use assignment operator .\r\nRemember using base R must specify dataframe writing column name (e.g. dataframe$column). two dummy examples:","code":"\nlinelist$old_var <- linelist$old_var + 7\nlinelist$new_var <- linelist$old_var + linelist$age"},{"path":"cleaning-data.html","id":"add-to-pipe-chain","chapter":"1 Cleaning data","heading":"1.8.2.1 Add to pipe chain","text":", new column added pipe chain.","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################\n    # add new column\n    mutate(bmi = wt_kg / (ht_cm/100)^2)    "},{"path":"cleaning-data.html","id":"convert-column-class","chapter":"1 Cleaning data","heading":"1.8.3 Convert column class","text":"Often need set correct class column. ways set column class import commands, often often cumbersome. See section object classes learn converting class objects, including columns.First, run checks important columns see correct class:Currently, class “age” column character. perform quantitative analyses, need numbers recognized numeric!class “date_onset” column also character! perform analyses, dates must recognized dates!case, use mutate() define column , converted different class. basic example, converting ensuring column age class Numeric:Examples converting functions:Dates can especially difficult! date values must format conversion work correctly (e.g “MM/DD/YYYY”, “DD Mmm YYYY”). See page Working Dates (LINK) details. Especially converting class date, check data visually cross-table confirm value converted correctly. .Date(), format = argument often source errors.","code":"\nclass(linelist$age)## [1] \"character\"\nclass(linelist$date_onset)## [1] \"character\"\nlinelist <- linelist %>% \n  mutate(age = as.numeric(age))\n# Examples of modifying class\nlinelist <- linelist %>% \n  mutate(date_var      = as.Date(date_var, format = \"MM/DD/YYYY\"),  # See page on Dates for details  \n         numeric_var   = as.numeric(numeric_var),\n         character_var = as.character(character_var),\n         factor_var    = factor(factor_var, levels = c(...), labels = c(...))  # See page on Factors for details  \n         )"},{"path":"cleaning-data.html","id":"re-code-values","chapter":"1 Cleaning data","heading":"1.9 Re-code values","text":"scenarios need re-code (change) values:edit one specific value (e.g. one date incorrect year format)reconcile values spelled sameto create new column groupings categorical valuesto create new column grouping numeric values (e.g. age categories)","code":""},{"path":"cleaning-data.html","id":"re-code-specific-values","chapter":"1 Cleaning data","heading":"Re-code specific values","text":"change values manually can use recode() function within mutate() function.Imagine nonsensical date data: fix date source data, , write change cleaning pipeline via mutate() recode().mutate() line can read : “mutate column date_onset equal column date_onset re-coded OLD VALUE changed NEW VALUE”. Note pattern (OLD = NEW) recode() opposite R patterns (new = old). R development community working revising .another example re-coding multiple values within one column.linelist values column “hospital” must cleaned. several different spellings many missing values.recode() command re-defines column “hospital” current column “hospital”, specified recode changes. Don’t forget commas !Now see spellings hospital column corrected consolidated:TIP: number spaces equals sign matter. Make code easier read aligning = rows. Also, consider adding hashed comment row clarify future readers side OLD side NEW. TIP: Sometimes blank character value exists dataset (recognized R’s value missing - NA). can reference value two quotation marks space inbetween (\"\").","code":"\n# fix incorrect values                   # old value       # new value\nlinelist <- linelist %>% \n  mutate(date_onset = recode(date_onset, \"2014-14-15\" = \"2014-04-15\"))\ntable(linelist$hospital, useNA = \"always\")## \r\n##                      Central Hopital                     Central Hospital                           Hospital A \r\n##                                   11                                  443                                  289 \r\n##                           Hospital B                     Military Hopital                    Military Hospital \r\n##                                  289                                   30                                  786 \r\n##                     Mitylira Hopital                    Mitylira Hospital                                Other \r\n##                                    1                                   79                                  885 \r\n##                         Port Hopital                        Port Hospital St. Mark's Maternity Hospital (SMMH) \r\n##                                   47                                 1725                                  411 \r\n##   St. Marks Maternity Hopital (SMMH)                                 <NA> \r\n##                                   11                                 1472\nlinelist <- linelist %>% \n  mutate(hospital = recode(hospital,\n                      #    reference: OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      ))\ntable(linelist$hospital, useNA = \"always\")## \r\n##                     Central Hospital                           Hospital A                           Hospital B \r\n##                                  454                                  289                                  289 \r\n##                    Military Hospital                                Other                        Port Hospital \r\n##                                  896                                  885                                 1772 \r\n## St. Mark's Maternity Hospital (SMMH)                                 <NA> \r\n##                                  422                                 1472"},{"path":"cleaning-data.html","id":"re-code-missing-values","chapter":"1 Cleaning data","heading":"Re-code missing values","text":"dplyr offers two special function handling missing values:replace_na()change missing values (NA) specific value, “Missing”, use function replace_na() within mutate(). Note used manner recode - name variable must repeated within replace_na().na_if()convert specific value NA, use na_if(). command performs opposite operation replace_na(). example , values “Missing” column hospital converted NA.Note: na_if() used logic criteria (e.g. “values > 99”) - use replace() case_when() :","code":"\nlinelist <- linelist %>% \n  mutate(hospital = replace_na(hospital, \"Missing\"))\nlinelist <- linelist %>% \n  mutate(hospital = na_if(hospital, \"Missing\"))\n# Convert temperatures above 40 to NA \nlinelist <- linelist %>% \n  mutate(temp = replace(temp, temp > 40, NA))\n\n# Convert onset dates earlier than 2000 to missing\nlinelist <- linelist %>% \n  mutate(temp = replace(date_onset, date_onset > as.Date(\"2000-01-01\"), NA))"},{"path":"cleaning-data.html","id":"re-code-by-logic","chapter":"1 Cleaning data","heading":"1.9.1 Re-code by logic","text":"tabs demonstrate re-coding values column using logic conditions:Using replace(), ifelse() if_else() simple logicUsing case_when() complex logic","code":""},{"path":"cleaning-data.html","id":"re-code-with-simple-logic","chapter":"1 Cleaning data","heading":"Re-code with simple logic","text":"","code":""},{"path":"cleaning-data.html","id":"replace","chapter":"1 Cleaning data","heading":"replace()","text":"re-code simple logical criteria, can use replace() within mutate(). replace() function base R. Use logic condition specify rows change . general syntax :mutate(col_to_change = replace(col_to_change, criteria rows, new value)).One common situation changing one value one row, using unique row identifier. , gender changed “Female” row column case_id “2195”.equivalent command using base R syntax indexing brackets [ ] . reads “Change value dataframe linelist‘s column gender (rows linelist’s column case_id value ’2195’) ‘Female’”.","code":"# Example: change gender of one specific observation to \"Female\" \r\nmutate(gender = replace(gender, case_id == \"2195\", \"Female\")\nlinelist$gender[linelist$case_id == \"2195\"] <- \"Female\""},{"path":"cleaning-data.html","id":"ifelse-and-if_else","chapter":"1 Cleaning data","heading":"ifelse() and if_else()","text":"Another tool simple logical re-coding ifelse() partner if_else(). However, cases better use case_when() (clarity).commands simplified versions else programming statement (LINK). general syntax :ifelse(condition, value return condition evaluates TRUE, value return condition evaluates FALSE), column source_known defined (re-defined). value given row “known” row’s value column source missing. value source missing, value source_known “unknown”.if_else() special version dplyr handles dates. Note ‘true’ value date, ‘false’ value must also qualify date, hence using special character NA_real_ instead just NA.Avoid stringing together many ifelse commands… use case_when() instead! case_when() much easier read ’ll make fewer errors.Outside dataframe, want object used code switch value based criteria, consider using switch() base R. example … . See section using switch() page R interactive console.","code":"\nlinelist <- linelist %>% \n  mutate(source_known = ifelse(!is.na(source), \"known\", \"unknown\"))\nlinelist <- linelist %>% \n  mutate(date_death = if_else(outcome == \"Death\", date_outcome, NA_real_))"},{"path":"cleaning-data.html","id":"re-code-with-complex-logic","chapter":"1 Cleaning data","heading":"Re-code with complex logic","text":"Use dplyr’s case_when() need use complex logic statements re-code values. important differences recode() syntax logic order!case_when() commands Right-Hand Side (RHS) Left-Hand Side (LHS) separated “tilde” ~. logic criteria LHS pursuant value RHS. Statements separated commas. important note :Statements evaluated order written - top--bottom. Thus best write specific criteria first, general last.End TRUE LHS, signifies value meet previous criteraThe values RHS must class - numeric, character, logical, etc.\r\nassign NA, may need use special values NA_character, NA_real (numeric POSIX), .Date(NA)\r\nassign NA, may need use special values NA_character, NA_real (numeric POSIX), .Date(NA)utilize columns age age_unit create column age_years:","code":"\nlinelist <- linelist %>% \n  mutate(age_years = case_when(\n            age_unit == \"years\"  ~ age,       # if age is given in years\n            age_unit == \"months\" ~ age/12,    # if age is given in months\n            is.na(age_unit)      ~ age,       # if age unit is missing, assume years\n            TRUE                 ~ NA_real_)) # any other circumstance assign missing"},{"path":"cleaning-data.html","id":"re-code-with-a-cleaning-dictionary","chapter":"1 Cleaning data","heading":"1.9.2 Re-code with a cleaning dictionary","text":"Use package linelist clean linelist cleaning dictionary.Import cleaning dictionary 3 columns:\r\n“” column (incorrect value)\r\n“” column (correct value)\r\ncolumn specifying column changes applied (*.global apply columns)\r\n“” column (incorrect value)“” column (correct value)column specifying column changes applied (*.global apply columns)Store names columns want “protect” changes. must provided clean_data() numeric logical vector, see use names(.) command (dot means dataframe).Run clean_data() specifying cleaning dictionary, third column nameScroll see values changed - particularly gender (lowercase uppercase), symptoms columns transformed yes/1/0.CAUTION: clean_data() linelist package also clean values data unless columns protected - may encounter changes columns dashes “-” .Note column names cleaning dictionary must correspond names point cleaning script. clean_data() also implements column name cleaning function similar clean_names() janitor standardizes column names prior applying dictionary.See online reference details.","code":"\ncleaning_dict <- rio::import(\"cleaning_dict.csv\")\nprotected_cols <- c(\"case_id\", \"source\")\nlinelist <- linelist %>% \n  linelist::clean_data(\n    wordlists = cleaning_dict,\n    spelling_vars = \"col\",       #defaults to 3rd column in dict, if not specified\n    protect = names(.) %in% protected_cols\n  )"},{"path":"cleaning-data.html","id":"mutate-on-grouped-values","chapter":"1 Cleaning data","heading":"Mutate on grouped values","text":"dataframe already grouped (LINK grouping page), mutate() may behave differently dataframe grouped. summarizing functions, like mean(), median(), max(), etc. based grouped rows, rows.Read using mutate grouped dataframes: https://dplyr.tidyverse.org/reference/mutate.html","code":"\n# age normalized to mean of ALL rows\nlinelist %>% \n  select(case_id, age, hospital) %>% \n  mutate(age_norm = age / mean(age, na.rm=T))\n\n# age normalized to mean of hospital group\nlinelist %>% \n  select(case_id, age, hospital) %>% \n  group_by(hospital) %>% \n  mutate(age_norm = age / mean(age, na.rm=T))"},{"path":"cleaning-data.html","id":"other-transformations","chapter":"1 Cleaning data","heading":"1.10 Other transformations","text":"","code":""},{"path":"cleaning-data.html","id":"special-re-coding-tools","chapter":"1 Cleaning data","heading":"1.10.1 Special re-coding tools","text":"coalesce()dplyr function finds first non-missing value position. , provide columns row fill value first non-missing value columns provided.example, might use thiscoalesce()` create “location” variable hypothetical variables “patient_residence” “reporting_jurisdiction”, prioritize patient residence information, exists.cumsum(), cummean(), cummin(), cummax(), cumany(), cumall(),","code":"\nlinelist <- linelist %>% \n  mutate(location = coalesce(patient_residence, reporting_jurisdiction))"},{"path":"cleaning-data.html","id":"add-to-pipe-chain-1","chapter":"1 Cleaning data","heading":"Add to pipe chain","text":", new columns column transformations added pipe chain.","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################\n    \n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %>% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% \n    \n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %>% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %>% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age,\n          TRUE ~ NA_real_))"},{"path":"cleaning-data.html","id":"num_cats","chapter":"1 Cleaning data","heading":"1.11 Numeric categories","text":"describe special approaches creating numeric categories. Common examples include age categories, groups lab values, etc. discuss:age_categories(), epikit packagecut(), base Rcase_when()quantile breaksSometimes, numeric variables import class “character”. occurs non-numeric characters values, example entry “2 months” age, (depending R locale settings) comma used decimals place (e.g. “4,5” mean four one half years).example create age_cat column using age_years column.First, examine distribution data, make appropriate cut-points. See page Plotting Continuous Data (LINK).","code":"\n#check the class of the linelist variable age\nclass(linelist$age_years)## [1] \"numeric\"\n# examine the distribution\nhist(linelist$age_years)\nsummary(linelist$age_years, na.rm=T)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \r\n##    0.00    6.00   13.00   16.31   24.00   95.00     104"},{"path":"cleaning-data.html","id":"age_categories","chapter":"1 Cleaning data","heading":"1.11.1 age_categories()","text":"epikit package, can use age_categories() function easily categorize label numeric columns (note: function can applied non-age numeric variables ). output ordered factor.optional arguments demonstrated :lower = Default 0). lowest number want considered.upper = highest number want considered.= number years groups.separator = Default “-”. Character ages labels.ceiling = Default FALSE. TRUE, highest break value ceiling category “XX+” included. values highest break upper (defined) categorized NA.See function’s Help page details (enter ?age_categories R console).First, simple example:break values specify default included “higher” group - groups “open” lower/left side. shown , can add 1 break value achieve groups open top/right.","code":"\n# Simple example\n################\nlibrary(epikit)\n\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years,\n      breakers = c(0, 5, 10, 15, 20, 30, 40, 50, 60, 70)\n      ))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \r\n##   0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-69   70+  <NA> \r\n##  1159  1225  1045   839  1117   581   263   107    27    12   104\n# Include upper ends for the same categories\n############################################\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 6, 11, 16, 21, 31, 41, 51, 61, 71)))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \r\n##   0-5  6-10 11-15 16-20 21-30 31-40 41-50 51-60 61-70   71+  <NA> \r\n##  1412  1214   999   776  1053   553   245    88    24    11   104\n# With ceiling set to TRUE\n##########################\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 5, 10, 15, 20, 30, 40, 50, 60, 70),\n      ceiling = TRUE)) # 70 is ceiling, all above become NA\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \r\n##   0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-70  <NA> \r\n##  1159  1225  1045   839  1117   581   263   107    28   115"},{"path":"cleaning-data.html","id":"cut","chapter":"1 Cleaning data","heading":"1.11.2 cut()","text":"can also use base R function cut(), creates categories numeric column. differences age_categories() :need install/load another packageYou can specify whether groups open/closed right/leftYou must provide accurate labels yourselfIf want 0 included lowest group must specify thisThe basic syntax within cut() first provide numeric variable cut (age_years), breaks argument, numeric vector (c()) break points. Using cut(), resulting column ordered factor. used within mutate() (dplyr verb) necessary specify dataframe column name (e.g. linelist$age_years).Create new column age categories (age_cat) cutting numeric age_year column specified break points.Specify numeric vector break pointsDefault behavior cut() lower break values excluded category, upper break values included. opposite behavior age_categories() function.Include 0 lowest category adding include.lowest = TRUEAdd vector customized labels using labels = argumentCheck work cross-tabulation numeric category columns - aware missing valuesBelow detailed description behavior using cut() make age_cat column. Key points:Inclusion/exclusion behavior break pointsCustom category labelsHandling missing valuesCheck work!simple example cut() applied age_years make new variable age_cat :default, categorization occurs right/upper side “open” inclusive (left/lower side “closed” exclusive). default labels use notation “(, B]”, means group include (lower break value), includes B (upper break value). Reverse behavior providing right = TRUE argument.default, categorization occurs right/upper side “open” inclusive (left/lower side “closed” exclusive). default labels use notation “(, B]”, means group include (lower break value), includes B (upper break value). Reverse behavior providing right = TRUE argument.Thus, default “0” values excluded lowest group, categorized NA. “0” values infants coded age 0. change add argument include.lowest = TRUE. , “0” values included lowest group. automatically-generated label lowest category change “(0,B]” “[0,B]”, signifies 0 values included.Thus, default “0” values excluded lowest group, categorized NA. “0” values infants coded age 0. change add argument include.lowest = TRUE. , “0” values included lowest group. automatically-generated label lowest category change “(0,B]” “[0,B]”, signifies 0 values included.Check work!!! Verify age value assigned correct category cross-tabulating numeric category columns. Examine assignment boundary values (e.g. 15, neighboring categories 10-15 15-20).Check work!!! Verify age value assigned correct category cross-tabulating numeric category columns. Examine assignment boundary values (e.g. 15, neighboring categories 10-15 15-20).Reverse break inclusion behavior cut()Lower break values included category (upper break values excluded) argument right = included set TRUE. applied - note values shifted among categories.NOTE: include include.lowest = TRUE argument right = TRUE, extreme inclusion now apply highest break point value category, lowest.Add labelsAs manually written, careful ensure accurate! Check work using cross-tabulation, described .\r\ncode , manual labels added.Re-labeling NA values cut()cut() automatically label NA values, may want assign label “Missing”. requires extra steps cut() automatically classified new column age_cat class Factor (rigid class limited defined values).First, convert age_cut Factor Character class, flexibility add new character values (e.g. “Missing”). Otherwise encounter error. , use dplyr verb replace_na() replace NA values character value like “Missing”. steps can combined one step, shown .Note Missing added, order categories now wrong (alphabetical considering numbers characters).fix , re-convert age_cat factor, define order levels correctly.seems cumbersome, consider using age_categories() instead, described .Make breaks labelsFor fast way make breaks labels manually, use something like . See page using seq() rep() c() DOMake breaks quantile(). stats package comes base R.Read cut() Help page entering ?cut R console.","code":"\n# Create new variable, by cutting the numeric age variable\n# by default, upper break is excluded and lower break excluded from each category\nlinelist <- linelist %>% \n  mutate(\n    age_cat = cut(\n      age_years,\n      breaks = c(0, 5, 10, 15, 20,\n                 30, 50, 70, 100),\n      include.lowest = TRUE         # include 0 in lowest group\n      ))\n\n# tabulate the number of observations per group\ntable(linelist$age_cat, useNA = \"always\")## \r\n##    [0,5]   (5,10]  (10,15]  (15,20]  (20,30]  (30,50]  (50,70] (70,100]     <NA> \r\n##     1412     1214      999      776     1053      798      112       11      104\n# Cross tabulation of the numeric and category columns. \ntable(\"Numeric Values\" = linelist$age_years,   # names specified in table for clarity.\n      \"Categories\"     = linelist$age_cat,\n      useNA = \"always\")                        # don't forget to examine NA values##                    Categories\r\n## Numeric Values      [0,5] (5,10] (10,15] (15,20] (20,30] (30,50] (50,70] (70,100] <NA>\r\n##   0                   127      0       0       0       0       0       0        0    0\r\n##   0.166666666666667     1      0       0       0       0       0       0        0    0\r\n##   0.333333333333333     2      0       0       0       0       0       0        0    0\r\n##   0.5                   2      0       0       0       0       0       0        0    0\r\n##   0.666666666666667     8      0       0       0       0       0       0        0    0\r\n##   0.75                  6      0       0       0       0       0       0        0    0\r\n##   0.833333333333333     4      0       0       0       0       0       0        0    0\r\n##   0.916666666666667     2      0       0       0       0       0       0        0    0\r\n##   1                   264      0       0       0       0       0       0        0    0\r\n##   1.5                   2      0       0       0       0       0       0        0    0\r\n##   2                   247      0       0       0       0       0       0        0    0\r\n##   3                   248      0       0       0       0       0       0        0    0\r\n##   4                   246      0       0       0       0       0       0        0    0\r\n##   5                   253      0       0       0       0       0       0        0    0\r\n##   6                     0    274       0       0       0       0       0        0    0\r\n##   7                     0    220       0       0       0       0       0        0    0\r\n##   8                     0    240       0       0       0       0       0        0    0\r\n##   9                     0    238       0       0       0       0       0        0    0\r\n##   10                    0    242       0       0       0       0       0        0    0\r\n##   11                    0      0     229       0       0       0       0        0    0\r\n##   12                    0      0     233       0       0       0       0        0    0\r\n##   13                    0      0     181       0       0       0       0        0    0\r\n##   14                    0      0     160       0       0       0       0        0    0\r\n##   15                    0      0     196       0       0       0       0        0    0\r\n##   16                    0      0       0     186       0       0       0        0    0\r\n##   17                    0      0       0     150       0       0       0        0    0\r\n##   18                    0      0       0     157       0       0       0        0    0\r\n##   19                    0      0       0     150       0       0       0        0    0\r\n##   20                    0      0       0     133       0       0       0        0    0\r\n##   21                    0      0       0       0     134       0       0        0    0\r\n##   22                    0      0       0       0     126       0       0        0    0\r\n##   23                    0      0       0       0     118       0       0        0    0\r\n##   24                    0      0       0       0     118       0       0        0    0\r\n##   25                    0      0       0       0     119       0       0        0    0\r\n##   26                    0      0       0       0      93       0       0        0    0\r\n##   27                    0      0       0       0      88       0       0        0    0\r\n##   28                    0      0       0       0      96       0       0        0    0\r\n##   29                    0      0       0       0      92       0       0        0    0\r\n##   30                    0      0       0       0      69       0       0        0    0\r\n##   31                    0      0       0       0       0      66       0        0    0\r\n##   32                    0      0       0       0       0      67       0        0    0\r\n##   33                    0      0       0       0       0      84       0        0    0\r\n##   34                    0      0       0       0       0      59       0        0    0\r\n##   35                    0      0       0       0       0      59       0        0    0\r\n##   36                    0      0       0       0       0      43       0        0    0\r\n##   37                    0      0       0       0       0      38       0        0    0\r\n##   38                    0      0       0       0       0      53       0        0    0\r\n##   39                    0      0       0       0       0      43       0        0    0\r\n##   40                    0      0       0       0       0      41       0        0    0\r\n##   41                    0      0       0       0       0      42       0        0    0\r\n##   42                    0      0       0       0       0      31       0        0    0\r\n##   43                    0      0       0       0       0      20       0        0    0\r\n##   44                    0      0       0       0       0      32       0        0    0\r\n##   45                    0      0       0       0       0      19       0        0    0\r\n##   46                    0      0       0       0       0      19       0        0    0\r\n##   47                    0      0       0       0       0      18       0        0    0\r\n##   48                    0      0       0       0       0      25       0        0    0\r\n##   49                    0      0       0       0       0      16       0        0    0\r\n##   50                    0      0       0       0       0      23       0        0    0\r\n##   51                    0      0       0       0       0       0      18        0    0\r\n##   52                    0      0       0       0       0       0      13        0    0\r\n##   53                    0      0       0       0       0       0      11        0    0\r\n##   54                    0      0       0       0       0       0       5        0    0\r\n##   55                    0      0       0       0       0       0      10        0    0\r\n##   56                    0      0       0       0       0       0       7        0    0\r\n##   57                    0      0       0       0       0       0       6        0    0\r\n##   58                    0      0       0       0       0       0       8        0    0\r\n##   59                    0      0       0       0       0       0       6        0    0\r\n##   60                    0      0       0       0       0       0       4        0    0\r\n##   61                    0      0       0       0       0       0       3        0    0\r\n##   62                    0      0       0       0       0       0       1        0    0\r\n##   63                    0      0       0       0       0       0       6        0    0\r\n##   65                    0      0       0       0       0       0       4        0    0\r\n##   66                    0      0       0       0       0       0       3        0    0\r\n##   67                    0      0       0       0       0       0       3        0    0\r\n##   69                    0      0       0       0       0       0       3        0    0\r\n##   70                    0      0       0       0       0       0       1        0    0\r\n##   71                    0      0       0       0       0       0       0        3    0\r\n##   72                    0      0       0       0       0       0       0        2    0\r\n##   76                    0      0       0       0       0       0       0        1    0\r\n##   77                    0      0       0       0       0       0       0        2    0\r\n##   91                    0      0       0       0       0       0       0        1    0\r\n##   94                    0      0       0       0       0       0       0        1    0\r\n##   95                    0      0       0       0       0       0       0        1    0\r\n##   <NA>                  0      0       0       0       0       0       0        0  104\nlinelist <- linelist %>% \n  mutate(\n    age_cat = cut(\n      age_years,\n      breaks = c(0, 5, 10, 15, 20,\n                 30, 50, 70, 100),  # same breaks as above\n      right = FALSE,                # include each *lower* break point\n      include.lowest = TRUE         # include *highest* value *highest* group\n      ))                                                 \n\ntable(linelist$age_cat, useNA = \"always\")## \r\n##    [0,5)   [5,10)  [10,15)  [15,20)  [20,30)  [30,50)  [50,70) [70,100]     <NA> \r\n##     1159     1225     1045      839     1117      844      134       12      104\nlinelist <- linelist %>% \n  mutate(\n    age_cat = cut(\n      age_years,\n      breaks = c(0, 5, 10, 15, 20,\n                 30, 50, 70, 100),  # same breaks as above\n      right = FALSE,                # include each *lower* break point\n      include.lowest = TRUE,        # include *highest* value *highest* group\n      labels = c(\"0-4\", \"5-9\", \"10-14\",\n                 \"15-19\", \"20-29\", \"30-49\",\n                 \"50-69\", \"70-100\")\n      ))\n\ntable(linelist$age_cat, useNA = \"always\")## \r\n##    0-4    5-9  10-14  15-19  20-29  30-49  50-69 70-100   <NA> \r\n##   1159   1225   1045    839   1117    844    134     12    104\nlinelist <- linelist %>% \n  \n  # cut() creates age_cat, automatically of class Factor      \n  mutate(age_cat = cut(age_years,\n                          breaks = c(0, 5, 10, 15, 20, 30, 50, 70, 100),          \n                          right = FALSE,\n                          include.lowest = TRUE,        \n                          labels = c(\"0-4\", \"5-9\", \"10-14\", \"15-19\",\n                                     \"20-29\", \"30-49\", \"50-69\", \"70-100\")),\n         \n         # convert to class Character, and replace NA with \"Missing\"\n         age_cat = replace_na(as.character(age_cat), \"Missing\"))\n\n\ntable(linelist$age_cat, useNA = \"always\")## \r\n##     0-4   10-14   15-19   20-29   30-49     5-9   50-69  70-100 Missing    <NA> \r\n##    1159    1045     839    1117     844    1225     134      12     104       0\nlinelist <- linelist %>% \n  \n  # cut() creates age_cat, automatically of class Factor      \n  mutate(age_cat = cut(age_years,\n                          breaks = c(0, 5, 10, 15, 20, 30, 50, 70, 100),          \n                          right = FALSE,\n                          include.lowest = TRUE,        \n                          labels = c(\"0-4\", \"5-9\", \"10-14\", \"15-19\",\n                                     \"20-29\", \"30-49\", \"50-69\", \"70-100\")),\n         \n         # convert to class Character, and replace NA with \"Missing\"\n         age_cat = replace_na(as.character(age_cat), \"Missing\"),\n         \n         # re-classify age_cat as Factor, with correct level order and new \"Missing\" level\n         age_cat = factor(age_cat, levels = c(\"0-4\", \"5-9\", \"10-14\", \"15-19\", \"20-29\",\n                                              \"30-49\", \"50-69\", \"70-100\", \"Missing\")))    \n  \n\ntable(linelist$age_cat, useNA = \"always\")## \r\n##     0-4     5-9   10-14   15-19   20-29   30-49   50-69  70-100 Missing    <NA> \r\n##    1159    1225    1045     839    1117     844     134      12     104       0\n# Make break points from 0 to 90 by 5\nage_seq = seq(from = 0, to = 90, by = 5)\nage_seq\n\n# Make labels for the above categories, assuming default cut() settings\nage_labels = paste0(age_seq+1, \"-\", age_seq + 5)\nage_labels\n\n# check that both vectors are the same length\nlength(age_seq) == length(age_labels)\nage_quantiles <- quantile(linelist$age_years, c(0, .25, .50, .75, .90, .95), na.rm=T)\nage_quantiles##  0% 25% 50% 75% 90% 95% \r\n##   0   6  13  24  35  42\n# to return only the numbers use unname()\nage_quantiles <- unname(age_quantiles)\nage_quantiles## [1]  0  6 13 24 35 42"},{"path":"cleaning-data.html","id":"case_when","chapter":"1 Cleaning data","heading":"1.11.3 case_when()","text":"dplyr function case_when() can also used create numeric categories.Allows explicit setting break point inclusion/exclusionAllows designation label NA values one stepMore complicated code, arguably prone errorAllow flexibility include variables logicIf using case_when() please review proper use, logic order assignment important understand avoid errors.CAUTION: case_when() right-hand side values must class. Thus, categories character values (e.g. “20-30 years”) designated outcome NA age values must also character (“Missing”, special NA_character_ instead NA).need designate column factor (wrapping case_when() function factor()) provide ordering factor levels using levels = argument close case_when() function. using cut(), factor ordering levels done automatically.","code":"\nlinelist <- linelist %>% \n  mutate(age_cat = factor(case_when(\n          # provide the case_when logic and outcomes\n          age_years >= 0 & age_years < 5     ~ \"0-4\",          # logic by age_year value\n          age_years >= 5 & age_years < 10    ~ \"5-9\",\n          age_years >= 10 & age_years < 15   ~ \"10-14\",\n          age_years >= 15 & age_years < 20   ~ \"15-19\",\n          age_years >= 20 & age_years < 30   ~ \"20-29\",\n          age_years >= 30 & age_years < 50   ~ \"30-49\",\n          age_years >= 50 & age_years < 70   ~ \"50-69\",\n          age_years >= 45 & age_years <= 100 ~ \"70-100\",\n          is.na(age_years)                   ~ \"Missing\",  # if age_years is missing\n          TRUE                               ~ \"Check value\"   # catch-all alarm to trigger review\n          ), levels = c(\"0-4\",\"5-9\", \"10-14\", \"15-19\", \"20-29\", \"30-49\", \"50-69\", \"70-100\", \"Missing\", \"Check value\"))\n         )\n\n\ntable(linelist$age_cat, useNA = \"always\")## \r\n##         0-4         5-9       10-14       15-19       20-29       30-49       50-69      70-100     Missing Check value \r\n##        1159        1225        1045         839        1117         844         134          12         104           0 \r\n##        <NA> \r\n##           0"},{"path":"cleaning-data.html","id":"add-to-pipe-chain-2","chapter":"1 Cleaning data","heading":"1.11.4 Add to pipe chain","text":", code create two categorical age columns added cleaning pipe chain:","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n\n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %>% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% \n    \n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %>% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %>% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age,\n          TRUE ~ NA_real_)) %>% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################   \n    mutate(\n          # age categories: custom\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # age categories: 0 to 85 by 5s\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5)))"},{"path":"cleaning-data.html","id":"add-rows","chapter":"1 Cleaning data","heading":"1.12 Add rows","text":"Remember column must contain values one class (either character, numeric, logical, etc.). adding row requires nuance maintain .use ... .= 3 put 3rd row. Default add end. columns specified let empty.\r\nnew row number may look strange (“…23”) row numbers changed. using command twice examine/test carefully.class see error like : Error: Can’t combine ..1$infection date  ..2$infection date .\r\n(date value remember wrap date functionas.Date() like .Date(\"2020-10-10\"))","code":"\nlinelist <- linelist %>% \n  add_row(row_num = 666, case_id = \"abc\", generation = 4, `infection date` = as.Date(\"2020-10-10\"), .before = 2)"},{"path":"cleaning-data.html","id":"filter-rows","chapter":"1 Cleaning data","heading":"1.13 Filter rows","text":"typical early cleaning step filter dataframe specific rows using dplyr verb filter(). Within filter(), give logic must TRUE row dataset kept.tabs show filter rows based simple complex logical conditions, filter/subset rows stand-alone command base R","code":""},{"path":"cleaning-data.html","id":"a-simple-filter","chapter":"1 Cleaning data","heading":"1.13.1 A simple filter()","text":"simple example re-defines dataframe linelist , filtered rows meet logical condition. rows logical statement within parentheses TRUE kept.case, logical statement !.na(case_id), asking whether value column case_id missing (NA). Thus, rows case_id missing kept.filter applied, number rows linelist 6479.filter applied, number rows linelist 6474.","code":"\nlinelist <- linelist %>% \n  filter(!is.na(case_id))  # keep only rows where case_id is not missing"},{"path":"cleaning-data.html","id":"a-complex-filter","chapter":"1 Cleaning data","heading":"1.13.2 A complex filter()","text":"complex example using filter():","code":""},{"path":"cleaning-data.html","id":"examine-the-data","chapter":"1 Cleaning data","heading":"Examine the data","text":"simple one-line command create histogram onset dates. See second smaller outbreak 2012-2013 also included dataset. analyses, want remove entries earlier outbreak.","code":"\nhist(linelist$date_onset, breaks = 50)"},{"path":"cleaning-data.html","id":"how-filters-handle-missing-numeric-and-date-values","chapter":"1 Cleaning data","heading":"How filters handle missing numeric and date values","text":"Can just filter date_onset rows June 2013? Caution! Applying code filter(date_onset > .Date(\"2013-06-01\"))) accidentally remove rows later epidemic missing date onset!DANGER: Filtering greater (>) less (<) date number can remove rows missing values (NA)! NA treated infinitely large small.","code":""},{"path":"cleaning-data.html","id":"design-the-filter","chapter":"1 Cleaning data","heading":"Design the filter","text":"Examine cross-tabulation make sure exclude correct rows:criteria can filter remove first outbreak dataset? see :first epidemic occurred Hospital , Hospital B, also 10 cases Port Hospital.Hospitals & B cases second epidemic, Port Hospital .want exclude:586 rows onset 2012 2013 either hospital , B, Port:\r\nExclude 586 rows onset 2012 2013\r\nExclude 0 rows Hospitals & B missing onset dates\r\nexclude 0 rows missing onset dates.\r\nExclude 586 rows onset 2012 2013Exclude 0 rows Hospitals & B missing onset datesDo exclude 0 rows missing onset dates.start linelist nrow(linelist). filter statement:re-make cross-tabulation, see Hospitals & B removed completely, 10 Port Hospital cases 2012 & 2013 removed, values - just wanted.Multiple statements can included within one filter command (separated commas), can always pipe separate filter() command clarity.Note: readers may notice easier just filter date_hospitalisation 100% complete missing values. true. date_onset used purposes demonstrating complex filter.","code":"\ntable(Hospital  = linelist$hospital,                     # hospital name\n      YearOnset = lubridate::year(linelist$date_onset),  # year of date_onset\n      useNA     = \"always\")                              # show missing values##                                       YearOnset\r\n## Hospital                               2012 2013 2014 2015 <NA>\r\n##   Central Hospital                        0    0  359   95    0\r\n##   Hospital A                            244   44    0    0    0\r\n##   Hospital B                            253   35    0    0    0\r\n##   Military Hospital                       0    0  698  198    0\r\n##   Missing                                 0    0 1159  310    0\r\n##   Other                                   0    0  713  172    0\r\n##   Port Hospital                           7    3 1423  339    0\r\n##   St. Mark's Maternity Hospital (SMMH)    0    0  331   91    0\r\n##   <NA>                                    0    0    0    0    0\nlinelist <- linelist %>% \n  # keep rows where onset is after 1 June 2013 OR where onset is missing and it was a hospital OTHER than Hospital A or B\n  filter(date_onset > as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))\n\nnrow(linelist)## [1] 5888\ntable(Hospital  = linelist$hospital,                     # hospital name\n      YearOnset = lubridate::year(linelist$date_onset),  # year of date_onset\n      useNA     = \"always\")                              # show missing values##                                       YearOnset\r\n## Hospital                               2014 2015 <NA>\r\n##   Central Hospital                      359   95    0\r\n##   Military Hospital                     698  198    0\r\n##   Missing                              1159  310    0\r\n##   Other                                 713  172    0\r\n##   Port Hospital                        1423  339    0\r\n##   St. Mark's Maternity Hospital (SMMH)  331   91    0\r\n##   <NA>                                    0    0    0"},{"path":"cleaning-data.html","id":"filter-stand-alone-command","chapter":"1 Cleaning data","heading":"1.13.3 Filter stand-alone command","text":"Filtering can also done stand-alone command (part pipe chain). Like dplyr verbs, case first argument must dataset .can also use base R subset using square brackets reflect [rows, columns] want retain.TIP: Use bracket-subset syntax View() quickly review records.","code":"\n# dataframe <- filter(dataframe, condition(s) for rows to keep)\n\nlinelist <- filter(linelist, !is.na(case_id))\n# dataframe <- dataframe[row conditions, column conditions] (blank means keep all)\n\nlinelist <- linelist[!is.na(case_id), ]"},{"path":"cleaning-data.html","id":"filter-to-quickly-review-observations","chapter":"1 Cleaning data","heading":"1.13.4 Filter to quickly review observations","text":"base R syntax can handy want quickly view subset rows columns. Use base R View() command (note capital “V”) around [] subset want see. result appear dataframe RStudio viewer panel. example, want review onset hospitalization dates 3 specific cases:View linelist viewer panel:View specific data three cases:Note: command can also written dplyr verbs filter() select() :","code":"\nView(linelist)\nView(linelist[linelist$case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\"), c(\"date_onset\", \"date_hospitalisation\")])\nView(linelist %>%\n       filter(case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\")) %>%\n       select(date_onset, date_hospitalisation))"},{"path":"cleaning-data.html","id":"add-to-pipe-chain-3","chapter":"1 Cleaning data","heading":"1.13.5 Add to pipe chain","text":"","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n\n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %>% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% \n    \n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %>% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %>% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age,\n          TRUE ~ NA_real_)) %>% \n  \n    mutate(\n          # age categories: custom\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # age categories: 0 to 85 by 5s\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5))) %>% \n    \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################\n    filter(\n          # keep only rows where case_id is not missing\n          !is.na(case_id),  \n          \n          # also filter to keep only the second outbreak\n          date_onset > as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))"},{"path":"cleaning-data.html","id":"rowwise-dplyr","chapter":"1 Cleaning data","heading":"1.14 rowwise() dplyr()","text":"https://cran.r-project.org/web/packages/dplyr/vignettes/rowwise.html","code":"\nlinelist <- linelist %>%\n  rowwise() %>%\n  mutate(num_symptoms = sum(c(fever, chills, cough, aches, vomit) == \"yes\"))"},{"path":"cleaning-data.html","id":"transformations-across-multiple-columns","chapter":"1 Cleaning data","heading":"1.15 Transformations across multiple columns","text":"Often write concise code want apply transformation multiple columns . transformation can applied multiple variables using across() function package dplyr (contained within tidyverse package).across() can used dplyr verb, commonly mutate(), filter(), summarise().\r\nacross() allows specify columns want function apply . specify columns, can name indvidually, use helped functions.transformation .character() applied specific columns named within across(). Note functions across() written without parentheses ( )helpers available assist specifying columns:everything() - columns mentionedlast_col() - last columnwhere() - applies function columns selects TRUEstarts_with() - matches specified prefix. Example: select(starts_with(\"date\"))ends_with() - matches specified suffix. Example: select(ends_with(\"_end\"))contains() - columns containing character string. Example: select(contains(\"time\"))matches() - apply regular expression (regex). Example: select(contains(\"[pt]al\"))num_range() -any_of() - matches column named. Useful name might exist. Example: select(any_of(date_onset, date_death, cardiac_arrest))example one change columns character class:Columns name contains string “date” (note placement commas parentheses):, want mutate columns class POSIXct (datetime class shows timestamps) - function .POSIXct() evaluates TRUE. want apply function .Date() column convert class Date.Note within across() also use function ()Note .POSIXct package lubridate. similar functions (.character(), .numeric(), .logical()) base RHere online resources using across(): creator Hadley Wickham’s thoughts/rationale","code":"\nlinelist <- linelist %>% \n  mutate(across(c(temp, ht_cm, wt_kg), as.character))\n#to change all columns to character class\nlinelist <- linelist %>% \n  mutate(across(everything(), as.character))\n#to change all columns to character class\nlinelist <- linelist %>% \n  mutate(across(contains(\"date\"), as.character))\nlinelist <- linelist %>% \n  mutate(across(where(lubridate::is.POSIXct), as.Date))## [1] \"2014-04-17\"## [1] \"2014-04-19\""}]
