[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"","code":""},{"path":"index.html","id":"about-this-handbook","chapter":"Welcome","heading":"About this handbook","text":"free open-source R reference guide catered applied epidemiologists.book strives :Serve quick reference guide - textbookAddress common epidemiological problems via task-centered examplesBe accessible settings limited technical support low internet-connectivity (downloadable version)Contain clear simple language, step--step instructions many commentsBe living document, growing adapting new best practices“Epis” using R must often search online read dozens forum pages complete common data manipulation visualization tasks. online tutorials epidemiology-oriented. Furthermore, epidemiologists often work low internet-connectivity environments limited technical support. handbook aims fill gaps.","code":""},{"path":"index.html","id":"how-to-read-this-handbook","chapter":"Welcome","heading":"How to read this handbook","text":"Review pages tabs Table ContentsReview pages tabs Table ContentsSearch via search box Table ContentsSearch via search box Table ContentsClick “clipboard” icon upper-right code chunk copy itClick “clipboard” icon upper-right code chunk copy itClick download offline versionClick download offline versionIf use appreciate resource, let us know !use appreciate resource, let us know !","code":""},{"path":"index.html","id":"contribute","chapter":"Welcome","heading":"Contribute","text":"suggestions want contribute, please post issue github repository.","code":""},{"path":"index.html","id":"acknowledgements","chapter":"Welcome","heading":"Acknowledgements","text":"","code":""},{"path":"index.html","id":"contributors","chapter":"Welcome","heading":"Contributors","text":"handbook collaborative team production; conceived, written, edited epidemiologists public health practitioners around world. team members:Editor--Chief:Editorial core team: …(list)…Authors: …(list)…Reviewers: …(list)…Advisers …(list)…","code":""},{"path":"index.html","id":"funding-and-programmatic-support","chapter":"Welcome","heading":"Funding and programmatic support","text":"Training Programs Epidemiology Public Health Interventions Network (TEPHINET)EPIET Alumni Network (EAN)","code":""},{"path":"index.html","id":"data-sources","chapter":"Welcome","heading":"Data sources","text":"outbreaks R package","code":""},{"path":"index.html","id":"inspiration","chapter":"Welcome","heading":"Inspiration","text":"“R4Epis” project (collaboration MSF RECON)R Epidemics Consortium (RECON)R Data Science book (R4DS)bookdown: Authoring Books Technical Documents R Markdown\r\nspecific tutorials vignettes credited relevant pages","code":""},{"path":"index.html","id":"image-credits","chapter":"Welcome","heading":"Image credits","text":"Logo: CDC Public Health Image library, R Graph Gallery2013 Yemen looking mosquito breeding sitesEbola virusSurvey RajasthanNetwork","code":""},{"path":"index.html","id":"license-and-terms-of-use","chapter":"Welcome","heading":"License and Terms of Use","text":"Creative Commons license TBD…","code":""},{"path":"cleaning-data.html","id":"cleaning-data","chapter":"1 Cleaning data","heading":"1 Cleaning data","text":"","code":""},{"path":"cleaning-data.html","id":"overview","chapter":"1 Cleaning data","heading":"1.1 Overview","text":"page demonstrates common steps necessary clean dataset, starting importing raw data demonstrating “pipe chain” cleaning steps.page uses simulated Ebola case linelist, referenced throughout handbook.functions described page:%>% - pipe pass dataset one function nextmutate() - create, transform, re-define columnsselect() - select re-name columnsrename() - rename columnsacross() - transform multiple columns one timefilter() - keep certain rowsadd_row() - add row manuallyclean_names() - standardize syntax column namesas.characer(), .numeric(), .Date(), etc. - convert class columnrecode() - re-code values columncase_when() - re-code values column using complex logical criteriareplace_na(), na_if(), coalesce() - special functions re-codingclean_data() - re-code/clean using data dictionaryage_categories() cut() - create categorical groups numeric columndistinct() - de-duplicate rows","code":""},{"path":"cleaning-data.html","id":"load-packages","chapter":"1 Cleaning data","heading":"1.2 Load packages","text":"packages used page clean data:","code":"\npacman::p_load(\n  rio,        # importing data  \n  here,       # relative file pathways  \n  janitor,    # data cleaning\n  lubridate,  # working with dates\n  epikit,     # age_categories() function\n  tidyverse   # data manipulation and visualization\n)"},{"path":"cleaning-data.html","id":"import-data","chapter":"1 Cleaning data","heading":"1.3 Import data","text":"See page importing data details. import raw .xlsx dataset using import() function package rio, save initially dataframe object linelist_raw. (LINK IMPORT PAGE)can view first 50 rows original “raw” dataset :","code":"\nlinelist_raw <- import(\"linelist_raw.xlsx\")"},{"path":"cleaning-data.html","id":"cleaning-pipeline","chapter":"1 Cleaning data","heading":"1.4 Cleaning pipeline","text":"epidemiological analysis data processing, cleaning steps often performed linked together, sequentially. R often manifests cleaning “pipeline”, raw dataset passed “piped” one cleaning step another.chain utilizes dplyr verbs magrittr pipe operator (see handbook page dplyr tidyverse coding style (LINK ). pipe begins “raw” data (linelist_raw) ends “clean” dataset (linelist).cleaning pipeline order steps important. Cleaning steps might include:Importing dataColumn names cleaned changedRows filtered, added, de-duplicatedColumns selected, added, transformed, re-orderedValues re-coded, cleaned, grouped","code":""},{"path":"cleaning-data.html","id":"column-names","chapter":"1 Cleaning data","heading":"1.5 Column names","text":"Column names used often must “clean” syntax. suggest following:Short namesNo spaces (replaced underscores (_),unusual characters (&, #, <, >, …)Similar style nomenclature (e.g. date columns named like date_onset, date_report, date_death…)columns names linelist_raw . can see :contain spacesDifferent naming patterns used dates (‘date onset’ vs. ‘infection date’)must merged header across two last columns .xlsx - resolve , import() used name first two columns (“merged_header”), assigned second column name “…28”, empty (28th column)Note: column name include spaces, surround name back-ticks, example: linelist$`infection date`. note keyboard, back-tick (`) different single quotation mark (’).","code":"\nnames(linelist_raw)##  [1] \"date_of_outcome\" \"outcome\"         \"gender\"          \"hospital\"        \"lon\"             \"lat\"             \"infector\"        \"source\"          \"age\"            \r\n## [10] \"age_unit\"        \"row_num\"         \"case_id\"         \"generation\"      \"infection date\"  \"date onset\"      \"hosp date\"       \"wt_kg\"           \"ht_cm\"          \r\n## [19] \"ct_blood\"        \"fever\"           \"chills\"          \"cough\"           \"aches\"           \"vomit\"           \"temp\"            \"time_admission\"  \"merged_header\"  \r\n## [28] \"...28\""},{"path":"cleaning-data.html","id":"automatic-name-cleaning","chapter":"1 Cleaning data","heading":"1.5.1 Automatic name cleaning","text":"function clean_names() package janitor standardizes column names makes unique following:Converts names consist underscores, numbers, lettersAccented characters transliterated ASCII (e.g. german o umlaut becomes “o”, spanish “enye” becomes “n”)Capitalization preference can specified using case = argument (“snake” default, alternatives include “sentence”, “title”, “small_camel”…)can designate specific name replacements replace = argument (e.g. replace = c(onset = “date_of_onset”))online vignetteBelow, cleaning pipeline begins using clean_names() raw linelist.NOTE: last column name “…28” changed “x28”.","code":"\n# send the dataset through the function clean_names()\nlinelist <- linelist_raw %>% \n  janitor::clean_names()\n\n# see the new names\nnames(linelist)##  [1] \"date_of_outcome\" \"outcome\"         \"gender\"          \"hospital\"        \"lon\"             \"lat\"             \"infector\"        \"source\"          \"age\"            \r\n## [10] \"age_unit\"        \"row_num\"         \"case_id\"         \"generation\"      \"infection_date\"  \"date_onset\"      \"hosp_date\"       \"wt_kg\"           \"ht_cm\"          \r\n## [19] \"ct_blood\"        \"fever\"           \"chills\"          \"cough\"           \"aches\"           \"vomit\"           \"temp\"            \"time_admission\"  \"merged_header\"  \r\n## [28] \"x28\""},{"path":"cleaning-data.html","id":"manual-name-cleaning","chapter":"1 Cleaning data","heading":"1.5.2 Manual name cleaning","text":"Re-naming columns manually often necessary. , re-naming performed using rename() function dplyr package, part pipe chain. rename() uses style “NEW = OLD”, new column name given old column name., re-name command added cleaning pipeline:Now can see columns names changed:","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome)##  [1] \"date_outcome\"         \"outcome\"              \"gender\"               \"hospital\"             \"lon\"                  \"lat\"                  \"infector\"            \r\n##  [8] \"source\"               \"age\"                  \"age_unit\"             \"row_num\"              \"case_id\"              \"generation\"           \"date_infection\"      \r\n## [15] \"date_onset\"           \"date_hospitalisation\" \"wt_kg\"                \"ht_cm\"                \"ct_blood\"             \"fever\"                \"chills\"              \r\n## [22] \"cough\"                \"aches\"                \"vomit\"                \"temp\"                 \"time_admission\"       \"merged_header\"        \"x28\""},{"path":"cleaning-data.html","id":"rename-by-column-position","chapter":"1 Cleaning data","heading":"Rename by column position","text":"can also rename column position, instead column name, example:","code":"\nrename(newNameForFirstColumn  = 1,\n       newNameForSecondColumn = 2)"},{"path":"cleaning-data.html","id":"rename-via-select","chapter":"1 Cleaning data","heading":"Rename via select()","text":"can also rename columns within dplyr select() function, used retain certain columns (covered later page). approach also uses format new_name = old_name. example:","code":"\nlinelist_raw %>% \n  select(# NEW name             # OLD name\n         date_infection       = `infection date`,    # rename and KEEP ONLY these columns\n         date_hospitalisation = `hosp date`)"},{"path":"cleaning-data.html","id":"other-name-challenges","chapter":"1 Cleaning data","heading":"1.5.3 Other name challenges","text":"","code":""},{"path":"cleaning-data.html","id":"empty-excel-column-names","chapter":"1 Cleaning data","heading":"Empty Excel column names","text":"importing Excel sheet missing column name, depending import function used, R likely create column name value like “…1” “…2”. can clean names manually referencing position number (see example ), name (linelist_raw$...1).","code":""},{"path":"cleaning-data.html","id":"merged-excel-column-names","chapter":"1 Cleaning data","heading":"Merged Excel column names","text":"Merged cells Excel file common occurrence receiving data field level. Merged cells can nice human reading data, cause many problems machine reading data. R accommodate merged cells.Remind people data entry human-readable data machine-readable data. Strive train users principles tidy data. possible, try change procedures data arrive tidy format without merged cells.variable must column.observation must row.value must cell.using rio’s import() function, value merged cell assigned first cell subsequent cells empty.One solution deal merged cells import data function readWorkbook() package openxlsx. Set argument fillMergedCells = TRUE. gives value merged cell cells within merge range.DANGER: column names merged, end duplicate column names, need fix manually - R work well duplicate column names! can re-name referencing position (e.g. column 5), explained section manual column name cleaning..","code":"\nlinelist_raw <- openxlsx::readWorkbook(\"linelist_raw.xlsx\", fillMergedCells = TRUE)"},{"path":"cleaning-data.html","id":"skip-import-of-rows","chapter":"1 Cleaning data","heading":"Skip import of rows","text":"Sometimes, may want avoid importing row data (e.g. column names, row 1).\r\ncan argument skip = using import() rio package .xlsx .csv file. Provide number rows want skip.Unfortunately skip = accepts one integer value, range (e.g. “2:10”). skip import specific rows consecutive top, consider importing multiple times using bind_rows() dplyr. See example skipping row 2.","code":"\nlinelist_raw <- import(\"linelist_raw.xlsx\", skip = 1)  # does not import header row"},{"path":"cleaning-data.html","id":"removing-a-second-header-row","chapter":"1 Cleaning data","heading":"Removing a second header row","text":"data may second row data, example may “data dictionary” row looks like :situation can problematic can result columns imported class “character”, even numbers another class. solve , likely need import data twice.Import data order store correct column namesImport data , skipping first two rows (header second rows)Bind correct names onto reduced dataframeThe exact arguments used bind correct column names depends type data file (.csv, .tsv, .xlsx, etc.). using rio’s import() function, understand function rio uses import data, give appropriate argument skip lines /designate column names. See handbook page importing data (LINK) details rio.Excel files:CSV files:Backup option - changing column names separate commandBonus! second row data dictionary, can easily create proper data dictionary using gather() command tidyr package.\r\nsource: https://alison.rbind.io/post/2018-02-23-read-multiple-header-rows/","code":"\n# For excel files (remove 2nd row)\nlinelist_raw_names <- import(\"linelist_raw.xlsx\") %>% names()  # save true column names\n\n# import, skip row 2, assign to col_names =\nlinelist_raw <- import(\"linelist_raw.xlsx\", skip = 2, col_names = linelist_raw_names) \n# For csv files\nlinelist_raw_names <- import(\"linelist_raw.csv\") %>% names() # save true column names\n\n# note argument is 'col.names ='\nlinelist_raw <- import(\"linelist_raw.csv\", skip = 2, col.names = linelist_raw_names) \n# assign/overwrite headers using the base 'colnames()' function\ncolnames(linelist_raw) <- linelist_raw_names\nlibrary(tidyr)\ndict <- linelist_raw %>% \n  clean_names() %>% \n  gather(variable_name, variable_description)\ndict"},{"path":"cleaning-data.html","id":"combine-two-header-rows","chapter":"1 Cleaning data","heading":"1.5.4 Combine two header rows","text":"cases, may want combine two header rows one. command define column names combination (pasting together) existing column names value underneath first row. Replace “df” name dataset.","code":"\nnames(df) <- paste(names(df), df[1, ], sep = \"_\")"},{"path":"cleaning-data.html","id":"select-or-re-order-columns","chapter":"1 Cleaning data","heading":"1.6 Select or re-order columns","text":"Often first step cleaning data selecting columns want work , set order dataframe. dplyr chain verbs, done select().CAUTION: examples , linelist modified select() -written. New column names displayed purpose example.column names linelist:Select columns want remain, order appearanceNote examples modify column names display result, assign/overwrite lineline.Indicate columns remove placing minus symbol “-” front column name (e.g. select(-outcome)), vector column names (). columns retained. Inside select() can use normal operators c() list several columns, : consecutive columns, ! opposite, & , | .Re-order columns - use everything() signify columns specified select() command:well everything() several helpers work within select(), namely:everything() - columns mentionedlast_col() - last columnwhere() - applies function columns selects TRUEstarts_with() - matches specified prefix. Example: select(starts_with(\"date\"))ends_with() - matches specified suffix. Example: select(ends_with(\"_end\"))contains() - columns containing character string. Example: select(contains(\"time\"))matches() - apply regular expression (regex). Example: select(contains(\"[pt]al\"))num_range() -any_of() - matches column named. Useful name might exist. Example: select(any_of(date_onset, date_death, cardiac_arrest))example using ():select() can also used independent command (pipe chain). case, first argument original dataframe operated upon.Add pipe chainIn linelist, columns need: row_num, merged_header, x28. Remove adding select() command cleaning pipe chain:","code":"\nnames(linelist)##  [1] \"date_outcome\"         \"outcome\"              \"gender\"               \"hospital\"             \"lon\"                  \"lat\"                  \"infector\"            \r\n##  [8] \"source\"               \"age\"                  \"age_unit\"             \"row_num\"              \"case_id\"              \"generation\"           \"date_infection\"      \r\n## [15] \"date_onset\"           \"date_hospitalisation\" \"wt_kg\"                \"ht_cm\"                \"ct_blood\"             \"fever\"                \"chills\"              \r\n## [22] \"cough\"                \"aches\"                \"vomit\"                \"temp\"                 \"time_admission\"       \"merged_header\"        \"x28\"\n# linelist dataset is piped through select() command, and names() prints just the column names\nlinelist %>% \n  select(case_id, date_onset, date_hospitalisation, fever) %>% \n  names() # display the column names## [1] \"case_id\"              \"date_onset\"           \"date_hospitalisation\" \"fever\"\nlinelist %>% \n  select(-c(date_onset, fever:vomit)) %>% # remove onset and all symptom columns\n  names()##  [1] \"date_outcome\"         \"outcome\"              \"gender\"               \"hospital\"             \"lon\"                  \"lat\"                  \"infector\"            \r\n##  [8] \"source\"               \"age\"                  \"age_unit\"             \"row_num\"              \"case_id\"              \"generation\"           \"date_infection\"      \r\n## [15] \"date_hospitalisation\" \"wt_kg\"                \"ht_cm\"                \"ct_blood\"             \"temp\"                 \"time_admission\"       \"merged_header\"       \r\n## [22] \"x28\"\n# move case_id, date_onset, date_hospitalisation, and gender to beginning\nlinelist %>% \n  select(case_id, date_onset, date_hospitalisation, gender, everything()) %>% \n  names()##  [1] \"case_id\"              \"date_onset\"           \"date_hospitalisation\" \"gender\"               \"date_outcome\"         \"outcome\"              \"hospital\"            \r\n##  [8] \"lon\"                  \"lat\"                  \"infector\"             \"source\"               \"age\"                  \"age_unit\"             \"row_num\"             \r\n## [15] \"generation\"           \"date_infection\"       \"wt_kg\"                \"ht_cm\"                \"ct_blood\"             \"fever\"                \"chills\"              \r\n## [22] \"cough\"                \"aches\"                \"vomit\"                \"temp\"                 \"time_admission\"       \"merged_header\"        \"x28\"\n# select columns containing certain characters\nlinelist %>% \n  select(contains(\"date\")) %>% \n  names()## [1] \"date_outcome\"         \"date_infection\"       \"date_onset\"           \"date_hospitalisation\"\n# searched for multiple character matches\nlinelist %>% \n  select(matches(\"onset|hosp|fev\")) %>%   # note the OR symbol \"|\"\n  names()## [1] \"hospital\"             \"date_onset\"           \"date_hospitalisation\" \"fever\"\n# Create a new linelist with id and age-related columns\nlinelist_age <- select(linelist, case_id, contains(\"age\"))\n\n# display the column names\nnames(linelist_age)## [1] \"case_id\"  \"age\"      \"age_unit\"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    #####################################################\n\n    # remove column\n    select(-c(row_num, merged_header, x28))"},{"path":"cleaning-data.html","id":"deduplication","chapter":"1 Cleaning data","heading":"1.7 Deduplication","text":"See handbook page de-duplications (LINK). simple de-duplication addressed .package dplyr offers distinct() function reduce dataframe unique rows - removing rows 100% duplicates.\r\njust add simple command distinct() pipe chain:begin 6609 rows linelist.de-duplication 6479 rows., distinct() command added cleaning pipe chain:","code":"\nlinelist <- linelist %>% \n  distinct()\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    #####################################################\n    \n    # de-duplicate\n    distinct()"},{"path":"cleaning-data.html","id":"column-creation-and-transformation","chapter":"1 Cleaning data","heading":"1.8 Column creation and transformation","text":"verb mutate() used add new column, modify existing one. example creating new columns mutate(). syntax : mutate(new_column_name = value transformation)","code":""},{"path":"cleaning-data.html","id":"new-columns","chapter":"1 Cleaning data","heading":"1.8.1 New columns","text":"basic mutate() command create new column might look like . creates new column new_col value every row 10.can also reference values columns, perform calculations. example Body Mass Index (BMI) calculated height weight using formula BMI = kg/m^2.creating multiple new columns, separate comma new line. , examples ways new columns, including pasting together values columns using str_glue() stringr package:Scroll right see new columns (first 50 rows shown):TIP: verb transmute() adds new columns just like mutate() also drops/removes columns mention.","code":"\nlinelist <- linelist %>% \n  mutate(new_col = 10)\nlinelist <- linelist %>% \n  mutate(bmi = wt_kg / (ht_cm/100)^2)\nlinelist <- linelist %>%                       \n  mutate(new_var_dup    = case_id,             # new column = duplicate/copy another existing column\n         new_var_static = 7,                   # new column = all values the same\n         new_var_static = new_var_static + 5,  # you can overwrite a column, and it can be a calculation using other variables\n         new_var_paste  = stringr::str_glue(\"{hospital} on ({date_hospitalisation})\") # new column = pasting together values from other columns\n         ) "},{"path":"cleaning-data.html","id":"add-or-transform-columns-using-base-r","chapter":"1 Cleaning data","heading":"1.8.2 Add or transform columns using base R","text":"define new column (re-define column) using base R, just use assignment operator .\r\nRemember using base R must specify dataframe writing column name (e.g. dataframe$column). two dummy examples:","code":"\nlinelist$old_var <- linelist$old_var + 7\nlinelist$new_var <- linelist$old_var + linelist$age"},{"path":"cleaning-data.html","id":"add-to-pipe-chain","chapter":"1 Cleaning data","heading":"Add to pipe chain","text":", new column added pipe chain.","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################\n    # add new column\n    mutate(bmi = wt_kg / (ht_cm/100)^2)    "},{"path":"cleaning-data.html","id":"convert-column-class","chapter":"1 Cleaning data","heading":"1.8.3 Convert column class","text":"Often need set correct class column. ways set column class import commands, often often cumbersome. See section object classes learn converting class objects, including columns.First, run checks important columns see correct class:Currently, class “age” column character. perform quantitative analyses, need numbers recognized numeric!class “date_onset” column also character! perform analyses, dates must recognized dates!case, use mutate() define column , converted different class. basic example, converting ensuring column age class Numeric:Examples converting functions:Dates can especially difficult! date values must format conversion work correctly (e.g “MM/DD/YYYY”, “DD Mmm YYYY”). See page Working Dates (LINK) details. Especially converting class date, check data visually cross-table confirm value converted correctly. .Date(), format = argument often source errors.","code":"\nclass(linelist$age)## [1] \"character\"\nclass(linelist$date_onset)## [1] \"character\"\nlinelist <- linelist %>% \n  mutate(age = as.numeric(age))\n# Examples of modifying class\nlinelist <- linelist %>% \n  mutate(date_var      = as.Date(date_var, format = \"MM/DD/YYYY\"),  # See page on Dates for details  \n         numeric_var   = as.numeric(numeric_var),\n         character_var = as.character(character_var),\n         factor_var    = factor(factor_var, levels = c(...), labels = c(...))  # See page on Factors for details  \n         )"},{"path":"cleaning-data.html","id":"re-code-values","chapter":"1 Cleaning data","heading":"1.9 Re-code values","text":"scenarios need re-code (change) values:edit one specific value, example date incorrect year formatto reconcile values spelled sameto create new column groupings categorical valuesto create new column grouping numeric values (e.g. age categories)","code":""},{"path":"cleaning-data.html","id":"re-code-specific-values","chapter":"1 Cleaning data","heading":"Re-code specific values","text":"change values manually can use recode() function within mutate() function.Imagine nonsensical date data: fix date source data, , write change cleaning pipeline via mutate() recode().mutate() line can read : “mutate column date_onset equal column date_onset re-coded OLD VALUE changed NEW VALUE”. Note pattern (OLD = NEW) recode() opposite R patterns (new = old). R development community working revising .another example re-coding multiple values within one column.linelist values column “hospital” must cleaned. several different spellings many missing values.recode() command re-defines column “hospital” current column “hospital”, specified recode changes. Don’t forget commas !Now see spellings hospital column corrected consolidated:TIP: number spaces equals sign matter. Make code easier read aligning = rows. Also, consider adding hashed comment row clarify future readers side OLD side NEW. TIP: Sometimes blank character value exists dataset (recognized R’s value missing - NA). can reference value two quotation marks space inbetween (\"\").","code":"\n# fix incorrect values                   # old value       # new value\nlinelist <- linelist %>% \n  mutate(date_onset = recode(date_onset, \"2014-14-15\" = \"2014-04-15\"))\ntable(linelist$hospital, useNA = \"always\")## \r\n##                      Central Hopital                     Central Hospital                           Hospital A                           Hospital B \r\n##                                   11                                  443                                  289                                  289 \r\n##                     Military Hopital                    Military Hospital                     Mitylira Hopital                    Mitylira Hospital \r\n##                                   30                                  786                                    1                                   79 \r\n##                                Other                         Port Hopital                        Port Hospital St. Mark's Maternity Hospital (SMMH) \r\n##                                  885                                   47                                 1725                                  411 \r\n##   St. Marks Maternity Hopital (SMMH)                                 <NA> \r\n##                                   11                                 1472\nlinelist <- linelist %>% \n  mutate(hospital = recode(hospital,\n                      #    reference: OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      ))\ntable(linelist$hospital, useNA = \"always\")## \r\n##                     Central Hospital                           Hospital A                           Hospital B                    Military Hospital \r\n##                                  454                                  289                                  289                                  896 \r\n##                                Other                        Port Hospital St. Mark's Maternity Hospital (SMMH)                                 <NA> \r\n##                                  885                                 1772                                  422                                 1472"},{"path":"cleaning-data.html","id":"re-code-missing-values","chapter":"1 Cleaning data","heading":"Re-code missing values","text":"dplyr offers two special function handling missing values:replace_na()change missing values (NA) specific value, “Missing”, use function replace_na() within mutate(). Note used manner recode - name variable must repeated within replace_na().na_if()convert specific value NA, use na_if(). command performs opposite operation replace_na(). example , values “Missing” column hospital converted NA.Note: na_if() used logic criteria (e.g. “values > 99”) - use replace() case_when() :","code":"\nlinelist <- linelist %>% \n  mutate(hospital = replace_na(hospital, \"Missing\"))\nlinelist <- linelist %>% \n  mutate(hospital = na_if(hospital, \"Missing\"))\n# Convert temperatures above 40 to NA \nlinelist <- linelist %>% \n  mutate(temp = replace(temp, temp > 40, NA))\n\n# Convert onset dates earlier than 2000 to missing\nlinelist <- linelist %>% \n  mutate(temp = replace(date_onset, date_onset > as.Date(\"2000-01-01\"), NA))"},{"path":"cleaning-data.html","id":"re-code-by-logic","chapter":"1 Cleaning data","heading":"1.9.1 Re-code by logic","text":"tabs demonstrate re-coding values column using logic conditions:Using replace(), ifelse() if_else() simple logicUsing case_when() complex logic","code":""},{"path":"cleaning-data.html","id":"re-code-with-simple-logic","chapter":"1 Cleaning data","heading":"Re-code with simple logic","text":"","code":""},{"path":"cleaning-data.html","id":"replace","chapter":"1 Cleaning data","heading":"replace()","text":"re-code simple logical criteria, can use replace() within mutate(). replace() function base R. Use logic condition specify rows change . general syntax :mutate(col_to_change = replace(col_to_change, criteria rows, new value)).One common situation changing one value one row, using unique row identifier. , gender changed “Female” row column case_id “2195”.equivalent command using base R syntax indexing brackets [ ] . reads “Change value dataframe linelist‘s column gender (rows linelist’s column case_id value ’2195’) ‘Female’”.","code":"# Example: change gender of one specific observation to \"Female\" \r\nmutate(gender = replace(gender, case_id == \"2195\", \"Female\")\nlinelist$gender[linelist$case_id == \"2195\"] <- \"Female\""},{"path":"cleaning-data.html","id":"ifelse-and-if_else","chapter":"1 Cleaning data","heading":"ifelse() and if_else()","text":"Another tool simple logical re-coding ifelse() partner if_else(). However, cases better use case_when() (clarity).commands simplified versions else programming statement (LINK). general syntax :ifelse(condition, value return condition evaluates TRUE, value return condition evaluates FALSE), column source_known defined (re-defined). value given row “known” row’s value column source missing. value source missing, value source_known “unknown”.if_else() special version dplyr handles dates. Note ‘true’ value date, ‘false’ value must also qualify date, hence using special character NA_real_ instead just NA.Avoid stringing together many ifelse commands… use case_when() instead! case_when() much easier read ’ll make fewer errors.Outside dataframe, want object used code switch value based criteria, consider using switch() base R. example … . See section using switch() page R interactive console.","code":"\nlinelist <- linelist %>% \n  mutate(source_known = ifelse(!is.na(source), \"known\", \"unknown\"))\nlinelist <- linelist %>% \n  mutate(date_death = if_else(outcome == \"Death\", date_outcome, NA_real_))"},{"path":"cleaning-data.html","id":"re-code-with-complex-logic","chapter":"1 Cleaning data","heading":"Re-code with complex logic","text":"Use dplyr’s case_when() need use complex logic statements re-code values. important differences recode() syntax logic order!case_when() commands Right-Hand Side (RHS) Left-Hand Side (LHS) separated “tilde” ~. logic criteria LHS pursuant value RHS. Statements separated commas. important note :Statements evaluated order written - top--bottom. Thus best write specific criteria first, general last.End TRUE LHS, signifies value meet previous criteraThe values RHS must class - numeric, character, logical, etc.\r\nassign NA, may need use special values NA_character, NA_real (numeric POSIX), .Date(NA)\r\nassign NA, may need use special values NA_character, NA_real (numeric POSIX), .Date(NA)utilize columns age age_unit create column age_years:","code":"\nlinelist <- linelist %>% \n  mutate(age_years = case_when(\n            age_unit == \"years\"  ~ age,       # if age is given in years\n            age_unit == \"months\" ~ age/12,    # if age is given in months\n            is.na(age_unit)      ~ age,       # if age unit is missing, assume years\n            TRUE                 ~ NA_real_)) # any other circumstance assign missing"},{"path":"cleaning-data.html","id":"re-code-with-a-cleaning-dictionary","chapter":"1 Cleaning data","heading":"1.9.2 Re-code with a cleaning dictionary","text":"Use package linelist clean linelist cleaning dictionary.Import cleaning dictionary 3 columns:\r\n“” column (incorrect value)\r\n“” column (correct value)\r\ncolumn specifying column changes applied (*.global apply columns)\r\n“” column (incorrect value)“” column (correct value)column specifying column changes applied (*.global apply columns)Store names columns want “protect” changes. must provided clean_data() numeric logical vector, see use names(.) command (dot means dataframe).Run clean_data() specifying cleaning dictionary, third column nameScroll see values changed - particularly gender (lowercase uppercase), symptoms columns transformed yes/1/0.CAUTION: clean_data() linelist package also clean values data unless columns protected - may encounter changes columns dashes “-” .Note column names cleaning dictionary must correspond names point cleaning script. clean_data() also implements column name cleaning function similar clean_names() janitor standardizes column names prior applying dictionary.See online reference details.","code":"\ncleaning_dict <- rio::import(\"cleaning_dict.csv\")\nprotected_cols <- c(\"case_id\", \"source\")\nlinelist %>% \n  linelist::clean_data(\n    wordlists = cleaning_dict,\n    spelling_vars = \"col\",       #defaults to 3rd column in dict, if not specified\n    protect = names(.) %in% protected_cols\n  )##    date_outcome outcome gender                          hospital       lon      lat infector  source age age_unit case_id generation date_infection date_onset\r\n## 1          <NA>    <NA>      F                     port_hospital -13.26207 8.486169   8508df   other  22    years  40ae5f          4     2014-05-04       <NA>\r\n## 2          <NA>    <NA>      F                     port_hospital -13.23637 8.475476   f90f5f   other   6    years  b8812a          3     2014-05-04 2014_05_18\r\n## 3    2014-05-23 recover      M st_mark_s_maternity_hospital_smmh -13.25236 8.460107   11f8ea   other  14    years  f96aa5          3     2014-05-17 2014_05_19\r\n## 4    2014-06-06 recover      M                              <NA> -13.26243 8.485050   7a9f33   other  20    years  47a5f5          3     2014-05-03 2014_05_26\r\n## 5    2014-06-03 recover      M                             other -13.21294 8.483315   be7f8a   other   4    years  566f9e          3     2014-05-24 2014_05_27\r\n## 6    2014-06-27 recover      M                  central_hospital -13.26890 8.478460   1511c5   other  27    years  acf422          6     2014-05-25 2014_05_27\r\n## 7    2014-06-17   death      M                     port_hospital -13.22437 8.470248   53da57   other  22    years  ce9c02          5     2014-05-27 2014_05_27\r\n## 8          <NA>   death      F st_mark_s_maternity_hospital_smmh -13.21152 8.450944     <NA>    <NA>   4    years  56d39e          5           <NA> 2014_05_27\r\n## 9    2014-06-01 recover      F                              <NA> -13.23315 8.462729   893f25   other  17    years  07e3e8          4     2014-05-22 2014_05_27\r\n## 10   2014-06-05    <NA>      M                     port_hospital -13.21647 8.486664     <NA>    <NA>  17    years  dbebea          7           <NA> 2014_06_02\r\n## 11   2014-06-11   death      F                     port_hospital -13.22571 8.470969     <NA>    <NA>   5    years  ab034a          4           <NA> 2014_06_03\r\n## 12   2014-06-11   death      F                             other -13.21307 8.477846   dae8c7   other   2    years  7e95d1          4     2014-05-25       <NA>\r\n## 13   2014-06-15   death      M                     port_hospital -13.22063 8.484016   996f3a   other  18    years  2978ac          4     2014-05-30 2014_06_06\r\n## 14   2014-06-22   death      F                             other -13.21287 8.458989     <NA>    <NA>  14    years  211b45          5           <NA>       <NA>\r\n## 15         <NA>   death      M                              <NA> -13.21833 8.479677     <NA>    <NA>   7    years  d6f195          4           <NA> 2014_06_10\r\n## 16   2014-06-16    <NA>      F                     port_hospital -13.20722 8.458307     <NA>    <NA>   6    years  e0fb09          6           <NA> 2014_06_11\r\n## 17         <NA> recover      F                              <NA> -13.21803 8.471555   cbbe78 funeral  14    years  057e7a          7     2014-06-04 2014_06_14\r\n## 18   2014-06-26 recover      F                             other -13.21907 8.477376   3ff1bc funeral   3    years  a6c614          5     2014-06-05       <NA>\r\n## 19   2014-06-24   death      M                     port_hospital -13.26197 8.484759   057e7a   other  16    years  c36eb4          8     2014-06-15 2014_06_20\r\n## 20   2014-07-13    <NA>      F                              <NA> -13.23713 8.487775     <NA>    <NA>  18    years  af9f9a          6           <NA> 2014_06_20\r\n## 21   2014-06-26   death      M                              <NA> -13.20931 8.454159     <NA>    <NA>  13    years  88a4e0          6           <NA> 2014_06_22\r\n## 22   2014-07-08 recover      M st_mark_s_maternity_hospital_smmh -13.21164 8.470845   02d8fd   other  26    years  9e74c4         10     2014-06-20 2014_06_22\r\n## 23   2014-07-01    <NA>      F                     port_hospital -13.23361 8.478048     <NA>    <NA>   7    years  f50e8a         10           <NA> 2014_06_22\r\n## 24   2014-06-25    <NA>      F                     port_hospital -13.21422 8.485280     <NA>    <NA>  33    years  3a7673          8           <NA> 2014_06_23\r\n## 25         <NA>   death      F                 military_hospital -13.23941 8.478590   1ab6a6   other   3    years  0ae14e          7     2014-06-28 2014_07_03\r\n## 26   2014-07-11   death      M                     port_hospital -13.23386 8.484291   542d07   other   4    years  71577a          6     2014-06-23 2014_07_05\r\n## 27   2014-07-14   death      M                             other -13.23969 8.453711     <NA>    <NA>  45    years  92b1ef         10           <NA> 2014_07_05\r\n## 28   2014-07-18   death      F st_mark_s_maternity_hospital_smmh -13.22442 8.460715     <NA>    <NA>   4    years  895618          8           <NA> 2014_07_06\r\n## 29   2014-07-31 recover      M                     port_hospital -13.24717 8.488115     <NA>    <NA>   4    years  ceed40          5           <NA> 2014_07_07\r\n## 30   2014-07-20    <NA>      F st_mark_s_maternity_hospital_smmh -13.26807 8.473437     <NA>    <NA>  37    years  9371a9          8           <NA> 2014_07_08\r\n## 31         <NA>    <NA>      M                              <NA> -13.22667 8.484083   b799eb   other  24    years  bc2adf          6     2014-07-03 2014_07_09\r\n## 32   2014-07-27 recover      M                     port_hospital -13.23530 8.468499     <NA>    <NA>  27    years  7fd086          7           <NA> 2014_07_11\r\n## 33   2014-07-14   death      F                     port_hospital -13.21135 8.479824   3e6957   other   9    years  1c1848          8     2014-07-09 2014_07_12\r\n## 34   2014-07-16    <NA>      F                     port_hospital -13.21934 8.450572     <NA>    <NA>  24    years  006e2f         11           <NA> 2014_07_12\r\n## 35   2014-07-16    <NA>      M                     port_hospital -13.26149 8.456231   ea3740   other  11    years  90e5fe          5     2014-06-18 2014_07_13\r\n## 36   2014-07-21 recover      M                              <NA> -13.21929 8.485941     <NA>    <NA>  21    years  dd9d20          7           <NA> 2014_07_15\r\n## 37         <NA> recover      M                              <NA> -13.21991 8.469393   36e2e7   other   5    years  6d788e         11     2014-07-12 2014_07_16\r\n##    date_hospitalisation wt_kg ht_cm ct_blood fever chills cough aches vomit temp time_admission       bmi age_years\r\n## 1            2014-05-08    59   146       21     0      1     1     0     1 36.9          16_58  27.67874        22\r\n## 2            2014-05-20    26    95       22     0      0     0     1     1 37.1          12_38  28.80886         6\r\n## 3            2014-05-20    69   168       23     0      0     1     0     1 37.5          09_34  24.44728        14\r\n## 4            2014-05-26    70   141       21     0      0     1     0     0 36.9          08_40  35.20950        20\r\n## 5            2014-05-28    44    71       22  <NA>   <NA>  <NA>  <NA>  <NA> 36.4           <NA>  87.28427         4\r\n## 6            2014-05-28    71   144       21     0      0     1     0     0 37.2          16_32  34.23997        27\r\n## 7            2014-05-29    67   139       23     0      0     1     0     0 37.4          12_14  34.67729        22\r\n## 8            2014-05-28    40    50       20     0      0     1     0     1 36.9          09_03 160.00000         4\r\n## 9            2014-05-29    60   120       22     0      0     1     0     1 37.2          10_28  41.66667        17\r\n## 10           2014-06-03    65   144       22     0      0     1     0     0 37.0           <NA>  31.34645        17\r\n## 11           2014-06-05    41    83       22  <NA>   <NA>  <NA>  <NA>  <NA> 37.4          17_55  59.51517         5\r\n## 12           2014-06-07    32    43       22  <NA>   <NA>  <NA>  <NA>  <NA> 37.4          05_49 173.06652         2\r\n## 13           2014-06-08    70   130       22     0      0     1     0     0 37.4          04_45  41.42012        18\r\n## 14           2014-06-08    68   142       22     0      0     1     0     0 36.5           <NA>  33.72347        14\r\n## 15           2014-06-12    51   107       22  <NA>   <NA>  <NA>  <NA>  <NA> 37.0          06_52  44.54538         7\r\n## 16           2014-06-13    45    76       21     0      1     1     0     0 37.0          21_42  77.90859         6\r\n## 17           2014-06-15    54   138       21     0      0     1     1     1 36.3          15_01  28.35539        14\r\n## 18           2014-06-18    41    68       21     0      0     1     0     0 36.7          13_18  88.66782         3\r\n## 19           2014-06-21    58   170       22     0      0     0     0     1 37.1          15_24  20.06920        16\r\n## 20           2014-06-20    67   138       21     0      0     1     0     1 36.5          16_04  35.18168        18\r\n## 21           2014-06-23    61   147       21  <NA>   <NA>  <NA>  <NA>  <NA> 37.0          12_58  28.22898        13\r\n## 22           2014-06-24    82   156       22  <NA>   <NA>  <NA>  <NA>  <NA> 36.6          14_25  33.69494        26\r\n## 23           2014-06-23    38    89       22     0      0     1     0     0 36.0          15_23  47.97374         7\r\n## 24           2014-06-24    69   171       21     0      1     1     0     1 36.3          15_27  23.59700        33\r\n## 25           2014-07-04    41    61       22  <NA>   <NA>  <NA>  <NA>  <NA> 36.9           <NA> 110.18543         3\r\n## 26           2014-07-06    50    73       21     0      1     1     0     0 36.9          16_26  93.82623         4\r\n## 27           2014-07-06    99   177       22     0      0     0     0     1 36.8           <NA>  31.60011        45\r\n## 28           2014-07-06    38    75       21     0      0     1     0     1 36.6          10_33  67.55556         4\r\n## 29           2014-07-09    42    64       21     0      0     1     0     0 35.9          15_27 102.53906         4\r\n## 30           2014-07-09    74   180       22     0      0     1     0     0 37.4          16_41  22.83951        37\r\n## 31           2014-07-09    62   132       22     0      0     0     0     1 36.0          18_11  35.58310        24\r\n## 32           2014-07-13    68   149       21     0      0     1     0     0 38.0          12_05  30.62925        27\r\n## 33           2014-07-14    44   108       23     0      1     1     0     1 37.0          20_18  37.72291         9\r\n## 34           2014-07-14    71   167       22     0      0     1     0     0 36.9          11_37  25.45807        24\r\n## 35           2014-07-14    61   123       20  <NA>   <NA>  <NA>  <NA>  <NA> 37.9          13_41  40.31992        11\r\n## 36           2014-07-17    63   125       22     0      0     1     0     0 37.1          11_30  40.32000        21\r\n## 37           2014-07-17    51    92       22     0      0     0     0     0 36.8          11_30  60.25520         5\r\n##  [ reached 'max' / getOption(\"max.print\") -- omitted 6442 rows ]"},{"path":"cleaning-data.html","id":"mutate-on-grouped-values","chapter":"1 Cleaning data","heading":"Mutate on grouped values","text":"dataframe already grouped (LINK grouping page), mutate() may behave differently dataframe grouped. summarizing functions, like mean(), median(), max(), etc. based grouped rows, rows.Read using mutate grouped dataframes: https://dplyr.tidyverse.org/reference/mutate.html","code":"\n# age normalized to mean of ALL rows\nlinelist %>% \n  select(case_id, age, hospital) %>% \n  mutate(age_norm = age / mean(age, na.rm=T))\n\n# age normalized to mean of hospital group\nlinelist %>% \n  select(case_id, age, hospital) %>% \n  group_by(hospital) %>% \n  mutate(age_norm = age / mean(age, na.rm=T))"},{"path":"cleaning-data.html","id":"other-transformations","chapter":"1 Cleaning data","heading":"1.10 Other transformations","text":"","code":""},{"path":"cleaning-data.html","id":"special-re-coding-tools","chapter":"1 Cleaning data","heading":"1.10.1 Special re-coding tools","text":"coalesce()dplyr function finds first non-missing value position. , provide columns row fill value first non-missing value columns provided.example, might use thiscoalesce()` create “location” variable hypothetical variables “patient_residence” “reporting_jurisdiction”, prioritize patient residence information, exists.\r\nlead(), lag()\r\ncumsum(), cummean(), cummin(), cummax(), cumany(), cumall(),","code":"\nlinelist <- linelist %>% \n  mutate(location = coalesce(patient_residence, reporting_jurisdiction))"},{"path":"cleaning-data.html","id":"add-to-pipe-chain-1","chapter":"1 Cleaning data","heading":"Add to pipe chain","text":", new columns column transformations added pipe chain.","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################\n    \n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %>% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% \n    \n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %>% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %>% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age,\n          TRUE ~ NA_real_))"},{"path":"cleaning-data.html","id":"num_cats","chapter":"1 Cleaning data","heading":"1.11 Numeric categories","text":"describe special approaches creating numeric categories. Common examples include age categories, groups lab values, etc. discuss:age_categories(), epikit packagecut(), base Rcase_when()using percentiles break numbersnatural break points… ? DOSometimes, numeric variables import class “character”. occurs non-numeric characters values, example entry “2 months” age, (depending R locale settings) comma used decimals place (e.g. “4,5” mean four one half years).example create age_cat column using age_years column.First, examine distribution data, make appropriate cut-points. See page Plotting Continuous Data (LINK).","code":"\n#check the class of the linelist variable age\nclass(linelist$age_years)## [1] \"numeric\"\n# examine the distribution\nhist(linelist$age_years)\nsummary(linelist$age_years, na.rm=T)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \r\n##    0.00    6.00   13.00   15.08   22.00   70.00     106"},{"path":"cleaning-data.html","id":"age_categories","chapter":"1 Cleaning data","heading":"1.11.1 age_categories()","text":"epikit package, can use age_categories() function easily categorize label numeric columns (note: function can applied non-age numeric variables ). output ordered factor.optional arguments demonstrated :lower = Default 0). lowest number want considered.upper = highest number want considered.= number years groups.separator = Default “-”. Character ages labels.ceiling = Default FALSE. TRUE, highest break value ceiling category “XX+” included. values highest break upper (defined) categorized NA.See function’s Help page details (enter ?age_categories R console).First, simple example:break values specify default included “higher” group - groups “open” lower/left side. shown , can add 1 break value achieve groups open top/right.","code":"\n# Simple example\n################\nlibrary(epikit)\n\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years,\n      breakers = c(0, 5, 10, 15, 20, 30, 40, 50, 60, 70)\n      ))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \r\n##   0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-69   70+  <NA> \r\n##  1193  1176  1139   875  1266   521   169    29     4     1   106\n# Include upper ends for the same categories\n############################################\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 6, 11, 16, 21, 31, 41, 51, 61, 71)))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \r\n##   0-5  6-10 11-15 16-20 21-30 31-40 41-50 51-60 61-70   71+  <NA> \r\n##  1411  1197  1095   839  1201   449   154    23     4     0   106\n# With ceiling set to TRUE\n##########################\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 5, 10, 15, 20, 30, 40, 50, 60, 70),\n      ceiling = TRUE)) # 70 is ceiling, all above become NA\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \r\n##   0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-70  <NA> \r\n##  1193  1176  1139   875  1266   521   169    29     5   106"},{"path":"cleaning-data.html","id":"cut","chapter":"1 Cleaning data","heading":"1.11.2 cut()","text":"can also use base R function cut(), creates categories numeric column. differences age_categories() :need install/load another packageYou can specify whether groups open/closed right/leftYou must provide accurate labels yourselfIf want 0 included lowest group must specify thisThe basic syntax within cut() first provide numeric variable cut (age_years), breaks argument, numeric vector (c()) break points. Using cut(), resulting column ordered factor. used within mutate() (dplyr verb) necessary specify dataframe column name (e.g. linelist$age_years).Create new column age categories (age_cat) cutting numeric age_year column specified break points.Specify numeric vector break pointsDefault behavior cut() lower break values excluded category, upper break values included. opposite behavior age_categories() function.Include 0 lowest category adding include.lowest = TRUEAdd vector customized labels using labels = argumentCheck work cross-tabulation numeric category columns - aware missing valuesBelow detailed description behavior using cut() make age_cat column. Key points:Inclusion/exclusion behavior break pointsCustom category labelsHandling missing valuesCheck work!simple example cut() applied age_years make new variable age_cat :default, categorization occurs right/upper side “open” inclusive (left/lower side “closed” exclusive). default labels use notation “(, B]”, means group include (lower break value), includes B (upper break value). Reverse behavior providing right = TRUE argument.default, categorization occurs right/upper side “open” inclusive (left/lower side “closed” exclusive). default labels use notation “(, B]”, means group include (lower break value), includes B (upper break value). Reverse behavior providing right = TRUE argument.Thus, default “0” values excluded lowest group, categorized NA. “0” values infants coded age 0. change add argument include.lowest = TRUE. , “0” values included lowest group. automatically-generated label lowest category change “(0,B]” “[0,B]”, signifies 0 values included.Thus, default “0” values excluded lowest group, categorized NA. “0” values infants coded age 0. change add argument include.lowest = TRUE. , “0” values included lowest group. automatically-generated label lowest category change “(0,B]” “[0,B]”, signifies 0 values included.Check work!!! Verify age value assigned correct category cross-tabulating numeric category columns. Examine assignment boundary values (e.g. 15, neighboring categories 10-15 15-20).Check work!!! Verify age value assigned correct category cross-tabulating numeric category columns. Examine assignment boundary values (e.g. 15, neighboring categories 10-15 15-20).Reverse break inclusion behavior cut()Lower break values included category (upper break values excluded) argument right = included set TRUE. applied - note values shifted among categories.NOTE: include include.lowest = TRUE argument right = TRUE, extreme inclusion now apply highest break point value category, lowest.Add labelsAs manually written, careful ensure accurate! Check work using cross-tabulation, described .\r\ncode , manual labels added.Re-labeling NA values cut()cut() automatically label NA values, may want assign label “Missing”. requires extra steps cut() automatically classified new column age_cat class Factor (rigid class limited defined values).First, convert age_cut Factor Character class, flexibility add new character values (e.g. “Missing”). Otherwise encounter error. , use dplyr verb replace_na() replace NA values character value like “Missing”. steps can combined one step, shown .Note Missing added, order categories now wrong (alphabetical considering numbers characters).fix , re-convert age_cat factor, define order levels correctly.seems cumbersome, consider using age_categories() instead, described .Make breaks labelsFor fast way make breaks labels manually, use something like . See page using seq() rep() c() DOMake breaks quantile(). stats package comes base R.Read cut() Help page entering ?cut R console.","code":"\n# Create new variable, by cutting the numeric age variable\n# by default, upper break is excluded and lower break excluded from each category\nlinelist <- linelist %>% \n  mutate(\n    age_cat = cut(\n      age_years,\n      breaks = c(0, 5, 10, 15, 20,\n                 30, 50, 70, 100),\n      include.lowest = TRUE         # include 0 in lowest group\n      ))\n\n# tabulate the number of observations per group\ntable(linelist$age_cat, useNA = \"always\")## \r\n##    [0,5]   (5,10]  (10,15]  (15,20]  (20,30]  (30,50]  (50,70] (70,100]     <NA> \r\n##     1411     1197     1095      839     1201      603       27        0      106\n# Cross tabulation of the numeric and category columns. \ntable(\"Numeric Values\" = linelist$age_years,   # names specified in table for clarity.\n      \"Categories\"     = linelist$age_cat,\n      useNA = \"always\")                        # don't forget to examine NA values##                    Categories\r\n## Numeric Values      [0,5] (5,10] (10,15] (15,20] (20,30] (30,50] (50,70] (70,100] <NA>\r\n##   0                   142      0       0       0       0       0       0        0    0\r\n##   0.166666666666667     1      0       0       0       0       0       0        0    0\r\n##   0.25                  4      0       0       0       0       0       0        0    0\r\n##   0.333333333333333     1      0       0       0       0       0       0        0    0\r\n##   0.416666666666667     2      0       0       0       0       0       0        0    0\r\n##   0.5                   2      0       0       0       0       0       0        0    0\r\n##   0.666666666666667     4      0       0       0       0       0       0        0    0\r\n##   0.75                  5      0       0       0       0       0       0        0    0\r\n##   0.916666666666667     1      0       0       0       0       0       0        0    0\r\n##   1                   245      0       0       0       0       0       0        0    0\r\n##   1.5                   4      0       0       0       0       0       0        0    0\r\n##   2                   270      0       0       0       0       0       0        0    0\r\n##   3                   270      0       0       0       0       0       0        0    0\r\n##   4                   242      0       0       0       0       0       0        0    0\r\n##   5                   218      0       0       0       0       0       0        0    0\r\n##   6                     0    266       0       0       0       0       0        0    0\r\n##   7                     0    240       0       0       0       0       0        0    0\r\n##   8                     0    212       0       0       0       0       0        0    0\r\n##   9                     0    240       0       0       0       0       0        0    0\r\n##   10                    0    239       0       0       0       0       0        0    0\r\n##   11                    0      0     198       0       0       0       0        0    0\r\n##   12                    0      0     249       0       0       0       0        0    0\r\n##   13                    0      0     218       0       0       0       0        0    0\r\n##   14                    0      0     235       0       0       0       0        0    0\r\n##   15                    0      0     195       0       0       0       0        0    0\r\n##   16                    0      0       0     190       0       0       0        0    0\r\n##   17                    0      0       0     156       0       0       0        0    0\r\n##   18                    0      0       0     201       0       0       0        0    0\r\n##   19                    0      0       0     133       0       0       0        0    0\r\n##   20                    0      0       0     159       0       0       0        0    0\r\n##   21                    0      0       0       0     151       0       0        0    0\r\n##   22                    0      0       0       0     144       0       0        0    0\r\n##   23                    0      0       0       0     160       0       0        0    0\r\n##   24                    0      0       0       0     151       0       0        0    0\r\n##   25                    0      0       0       0     119       0       0        0    0\r\n##   26                    0      0       0       0      99       0       0        0    0\r\n##   27                    0      0       0       0     103       0       0        0    0\r\n##   28                    0      0       0       0      82       0       0        0    0\r\n##   29                    0      0       0       0      98       0       0        0    0\r\n##   30                    0      0       0       0      94       0       0        0    0\r\n##   31                    0      0       0       0       0      69       0        0    0\r\n##   32                    0      0       0       0       0      67       0        0    0\r\n##   33                    0      0       0       0       0      67       0        0    0\r\n##   34                    0      0       0       0       0      57       0        0    0\r\n##   35                    0      0       0       0       0      38       0        0    0\r\n##   36                    0      0       0       0       0      34       0        0    0\r\n##   37                    0      0       0       0       0      47       0        0    0\r\n##   38                    0      0       0       0       0      28       0        0    0\r\n##   39                    0      0       0       0       0      20       0        0    0\r\n##   40                    0      0       0       0       0      22       0        0    0\r\n##   41                    0      0       0       0       0      26       0        0    0\r\n##   42                    0      0       0       0       0      25       0        0    0\r\n##   43                    0      0       0       0       0      12       0        0    0\r\n##   44                    0      0       0       0       0      20       0        0    0\r\n##   45                    0      0       0       0       0      32       0        0    0\r\n##   46                    0      0       0       0       0       7       0        0    0\r\n##   47                    0      0       0       0       0      10       0        0    0\r\n##   48                    0      0       0       0       0       9       0        0    0\r\n##   49                    0      0       0       0       0       6       0        0    0\r\n##   50                    0      0       0       0       0       7       0        0    0\r\n##   51                    0      0       0       0       0       0       6        0    0\r\n##   52                    0      0       0       0       0       0       7        0    0\r\n##   53                    0      0       0       0       0       0       2        0    0\r\n##   54                    0      0       0       0       0       0       2        0    0\r\n##   56                    0      0       0       0       0       0       3        0    0\r\n##   58                    0      0       0       0       0       0       1        0    0\r\n##   59                    0      0       0       0       0       0       1        0    0\r\n##   60                    0      0       0       0       0       0       1        0    0\r\n##   61                    0      0       0       0       0       0       2        0    0\r\n##   66                    0      0       0       0       0       0       1        0    0\r\n##   70                    0      0       0       0       0       0       1        0    0\r\n##   <NA>                  0      0       0       0       0       0       0        0  106\nlinelist <- linelist %>% \n  mutate(\n    age_cat = cut(\n      age_years,\n      breaks = c(0, 5, 10, 15, 20,\n                 30, 50, 70, 100),  # same breaks as above\n      right = FALSE,                # include each *lower* break point\n      include.lowest = TRUE         # include *highest* value *highest* group\n      ))                                                 \n\ntable(linelist$age_cat, useNA = \"always\")## \r\n##    [0,5)   [5,10)  [10,15)  [15,20)  [20,30)  [30,50)  [50,70) [70,100]     <NA> \r\n##     1193     1176     1139      875     1266      690       33        1      106\nlinelist <- linelist %>% \n  mutate(\n    age_cat = cut(\n      age_years,\n      breaks = c(0, 5, 10, 15, 20,\n                 30, 50, 70, 100),  # same breaks as above\n      right = FALSE,                # include each *lower* break point\n      include.lowest = TRUE,        # include *highest* value *highest* group\n      labels = c(\"0-4\", \"5-9\", \"10-14\",\n                 \"15-19\", \"20-29\", \"30-49\",\n                 \"50-69\", \"70-100\")\n      ))\n\ntable(linelist$age_cat, useNA = \"always\")## \r\n##    0-4    5-9  10-14  15-19  20-29  30-49  50-69 70-100   <NA> \r\n##   1193   1176   1139    875   1266    690     33      1    106\nlinelist <- linelist %>% \n  \n  # cut() creates age_cat, automatically of class Factor      \n  mutate(age_cat = cut(age_years,\n                          breaks = c(0, 5, 10, 15, 20, 30, 50, 70, 100),          \n                          right = FALSE,\n                          include.lowest = TRUE,        \n                          labels = c(\"0-4\", \"5-9\", \"10-14\", \"15-19\",\n                                     \"20-29\", \"30-49\", \"50-69\", \"70-100\")),\n         \n         # convert to class Character, and replace NA with \"Missing\"\n         age_cat = replace_na(as.character(age_cat), \"Missing\"))\n\n\ntable(linelist$age_cat, useNA = \"always\")## \r\n##     0-4   10-14   15-19   20-29   30-49     5-9   50-69  70-100 Missing    <NA> \r\n##    1193    1139     875    1266     690    1176      33       1     106       0\nlinelist <- linelist %>% \n  \n  # cut() creates age_cat, automatically of class Factor      \n  mutate(age_cat = cut(age_years,\n                          breaks = c(0, 5, 10, 15, 20, 30, 50, 70, 100),          \n                          right = FALSE,\n                          include.lowest = TRUE,        \n                          labels = c(\"0-4\", \"5-9\", \"10-14\", \"15-19\",\n                                     \"20-29\", \"30-49\", \"50-69\", \"70-100\")),\n         \n         # convert to class Character, and replace NA with \"Missing\"\n         age_cat = replace_na(as.character(age_cat), \"Missing\"),\n         \n         # re-classify age_cat as Factor, with correct level order and new \"Missing\" level\n         age_cat = factor(age_cat, levels = c(\"0-4\", \"5-9\", \"10-14\", \"15-19\", \"20-29\",\n                                              \"30-49\", \"50-69\", \"70-100\", \"Missing\")))    \n  \n\ntable(linelist$age_cat, useNA = \"always\")## \r\n##     0-4     5-9   10-14   15-19   20-29   30-49   50-69  70-100 Missing    <NA> \r\n##    1193    1176    1139     875    1266     690      33       1     106       0\n# Make break points from 0 to 90 by 5\nage_seq = seq(from = 0, to = 90, by = 5)\nage_seq\n\n# Make labels for the above categories, assuming default cut() settings\nage_labels = paste0(age_seq+1, \"-\", age_seq + 5)\nage_labels\n\n# check that both vectors are the same length\nlength(age_seq) == length(age_labels)\nage_quantiles <- quantile(linelist$age_years, c(0, .25, .50, .75, .90, .95), na.rm=T)\nage_quantiles##  0% 25% 50% 75% 90% 95% \r\n##   0   6  13  22  30  36\n# to return only the numbers use unname()\nage_quantiles <- unname(age_quantiles)\nage_quantiles## [1]  0  6 13 22 30 36"},{"path":"cleaning-data.html","id":"case_when","chapter":"1 Cleaning data","heading":"1.11.3 case_when()","text":"dplyr function case_when() can also used create numeric categories.Allows explicit setting break point inclusion/exclusionAllows designation label NA values one stepMore complicated code, arguably prone errorAllow flexibility include variables logicIf using case_when() please review proper use, logic order assignment important understand avoid errors.CAUTION: case_when() right-hand side values must class. Thus, categories character values (e.g. “20-30 years”) designated outcome NA age values must also character (“Missing”, special NA_character_ instead NA).need designate column factor (wrapping case_when() function factor()) provide ordering factor levels using levels = argument close case_when() function. using cut(), factor ordering levels done automatically.","code":"\nlinelist <- linelist %>% \n  mutate(age_cat = factor(case_when(\n          # provide the case_when logic and outcomes\n          age_years >= 0 & age_years < 5     ~ \"0-4\",          # logic by age_year value\n          age_years >= 5 & age_years < 10    ~ \"5-9\",\n          age_years >= 10 & age_years < 15   ~ \"10-14\",\n          age_years >= 15 & age_years < 20   ~ \"15-19\",\n          age_years >= 20 & age_years < 30   ~ \"20-29\",\n          age_years >= 30 & age_years < 50   ~ \"30-49\",\n          age_years >= 50 & age_years < 70   ~ \"50-69\",\n          age_years >= 45 & age_years <= 100 ~ \"70-100\",\n          is.na(age_years)                   ~ \"Missing\",  # if age_years is missing\n          TRUE                               ~ \"Check value\"   # catch-all alarm to trigger review\n          ), levels = c(\"0-4\",\"5-9\", \"10-14\", \"15-19\", \"20-29\", \"30-49\", \"50-69\", \"70-100\", \"Missing\", \"Check value\"))\n         )\n\n\ntable(linelist$age_cat, useNA = \"always\")## \r\n##         0-4         5-9       10-14       15-19       20-29       30-49       50-69      70-100     Missing Check value        <NA> \r\n##        1193        1176        1139         875        1266         690          33           1         106           0           0"},{"path":"cleaning-data.html","id":"add-to-pipe-chain-2","chapter":"1 Cleaning data","heading":"1.11.4 Add to pipe chain","text":", code create two categorical age columns added cleaning pipe chain:","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n\n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %>% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% \n    \n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %>% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %>% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age,\n          TRUE ~ NA_real_)) %>% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################   \n    mutate(\n          # age categories: custom\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # age categories: 0 to 85 by 5s\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5)))"},{"path":"cleaning-data.html","id":"add-rows","chapter":"1 Cleaning data","heading":"1.12 Add rows","text":"Remember column must contain values one class (either character, numeric, logical, etc.). adding row requires nuance maintain .use ... .= 3 put 3rd row. Default add end. columns specified let empty.\r\nnew row number may look strange (“…23”) row numbers changed. using command twice examine/test carefully.class see error like : Error: Can’t combine ..1$infection date  ..2$infection date .\r\n(date value remember wrap date functionas.Date() like .Date(\"2020-10-10\"))","code":"\nlinelist <- linelist %>% \n  add_row(row_num = 666, case_id = \"abc\", generation = 4, `infection date` = as.Date(\"2020-10-10\"), .before = 2)"},{"path":"cleaning-data.html","id":"filter-rows","chapter":"1 Cleaning data","heading":"1.13 Filter rows","text":"typical early cleaning step filter dataframe specific rows using dplyr verb filter(). Within filter(), give logic must TRUE row dataset kept.tabs show filter rows based simple complex logical conditions, filter/subset rows stand-alone command base R","code":""},{"path":"cleaning-data.html","id":"a-simple-filter","chapter":"1 Cleaning data","heading":"1.13.1 A simple filter()","text":"simple example re-defines dataframe linelist , filtered rows meet logical condition. rows logical statement within parentheses TRUE kept.case, logical statement !.na(case_id), asking whether value column case_id missing (NA). Thus, rows case_id missing kept.filter applied, number rows linelist 6479.filter applied, number rows linelist 6475.","code":"\nlinelist <- linelist %>% \n  filter(!is.na(case_id))  # keep only rows where case_id is not missing"},{"path":"cleaning-data.html","id":"a-complex-filter","chapter":"1 Cleaning data","heading":"1.13.2 A complex filter()","text":"complex example using filter():","code":""},{"path":"cleaning-data.html","id":"examine-the-data","chapter":"1 Cleaning data","heading":"Examine the data","text":"simple one-line command create histogram onset dates. See second smaller outbreak 2012-2013 also included dataset. analyses, want remove entries earlier outbreak.","code":"\nhist(linelist$date_onset, breaks = 50)"},{"path":"cleaning-data.html","id":"how-filters-handle-missing-numeric-and-date-values","chapter":"1 Cleaning data","heading":"How filters handle missing numeric and date values","text":"Can just filter date_onset rows June 2013? Caution! Applying code filter(date_onset > .Date(\"2013-06-01\"))) accidentally remove rows later epidemic missing date onset!DANGER: Filtering greater (>) less (<) date number can remove rows missing values (NA)! NA treated infinitely large small.","code":""},{"path":"cleaning-data.html","id":"design-the-filter","chapter":"1 Cleaning data","heading":"Design the filter","text":"Examine cross-tabulation make sure exclude correct rows:criteria can filter remove first outbreak dataset? see :first epidemic occurred Hospital , Hospital B, also 10 cases Port Hospital.Hospitals & B cases second epidemic, Port Hospital .want exclude:587 rows onset 2012 2013 either hospital , B, Port:\r\nExclude 558 rows onset 2012 2013\r\nExclude 29 rows Hospitals & B missing onset dates\r\nexclude 244 rows missing onset dates.\r\nExclude 558 rows onset 2012 2013Exclude 29 rows Hospitals & B missing onset datesDo exclude 244 rows missing onset dates.start linelist nrow(linelist). filter statement:re-make cross-tabulation, see Hospitals & B removed completely, 10 Port Hospital cases 2012 & 2013 removed, values - just wanted.Multiple statements can included within one filter command (separated commas), can always pipe separate filter() command clarity.Note: readers may notice easier just filter date_hospitalisation 100% complete missing values. true. date_onset used purposes demonstrating complex filter.","code":"\ntable(Hospital  = linelist$hospital,                     # hospital name\n      YearOnset = lubridate::year(linelist$date_onset),  # year of date_onset\n      useNA     = \"always\")                              # show missing values##                                       YearOnset\r\n## Hospital                               2012 2013 2014 2015 <NA>\r\n##   Central Hospital                        0    0  344   94   16\r\n##   Hospital A                            227   51    0    0   11\r\n##   Hospital B                            231   40    0    0   18\r\n##   Military Hospital                       0    0  664  198   34\r\n##   Missing                                 0    0 1103  309   57\r\n##   Other                                   0    0  667  171   47\r\n##   Port Hospital                           7    2 1351  337   74\r\n##   St. Mark's Maternity Hospital (SMMH)    0    0  315   91   16\r\n##   <NA>                                    0    0    0    0    0\nlinelist <- linelist %>% \n  # keep rows where onset is after 1 June 2013 OR where onset is missing and it was a hospital OTHER than Hospital A or B\n  filter(date_onset > as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))\n\nnrow(linelist)## [1] 5888\ntable(Hospital  = linelist$hospital,                     # hospital name\n      YearOnset = lubridate::year(linelist$date_onset),  # year of date_onset\n      useNA     = \"always\")                              # show missing values##                                       YearOnset\r\n## Hospital                               2014 2015 <NA>\r\n##   Central Hospital                      344   94   16\r\n##   Military Hospital                     664  198   34\r\n##   Missing                              1103  309   57\r\n##   Other                                 667  171   47\r\n##   Port Hospital                        1351  337   74\r\n##   St. Mark's Maternity Hospital (SMMH)  315   91   16\r\n##   <NA>                                    0    0    0"},{"path":"cleaning-data.html","id":"filter-stand-alone-command","chapter":"1 Cleaning data","heading":"1.13.3 Filter stand-alone command","text":"Filtering can also done stand-alone command (part pipe chain). Like dplyr verbs, case first argument must dataset .can also use base R subset using square brackets reflect [rows, columns] want retain.TIP: Use bracket-subset syntax View() quickly review records.","code":"\n# dataframe <- filter(dataframe, condition(s) for rows to keep)\n\nlinelist <- filter(linelist, !is.na(case_id))\n# dataframe <- dataframe[row conditions, column conditions] (blank means keep all)\n\nlinelist <- linelist[!is.na(case_id), ]"},{"path":"cleaning-data.html","id":"filter-to-quickly-review-observations","chapter":"1 Cleaning data","heading":"1.13.4 Filter to quickly review observations","text":"base R syntax can handy want quickly view subset rows columns. Use base R View() command (note capital “V”) around [] subset want see. result appear dataframe RStudio viewer panel. example, want review onset hospitalization dates 3 specific cases:View linelist viewer panel:View specific data three cases:Note: command can also written dplyr verbs filter() select() :","code":"\nView(linelist)\nView(linelist[linelist$case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\"), c(\"date_onset\", \"date_hospitalisation\")])\nView(linelist %>%\n       filter(case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\")) %>%\n       select(date_onset, date_hospitalisation))"},{"path":"cleaning-data.html","id":"add-to-pipe-chain-3","chapter":"1 Cleaning data","heading":"1.13.5 Add to pipe chain","text":"","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n\n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %>% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% \n    \n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %>% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %>% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age,\n          TRUE ~ NA_real_)) %>% \n  \n    mutate(\n          # age categories: custom\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # age categories: 0 to 85 by 5s\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5))) %>% \n    \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################\n    filter(\n          # keep only rows where case_id is not missing\n          !is.na(case_id),  \n          \n          # also filter to keep only the second outbreak\n          date_onset > as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))"},{"path":"cleaning-data.html","id":"rowwise-dplyr","chapter":"1 Cleaning data","heading":"1.14 rowwise() dplyr()","text":"https://cran.r-project.org/web/packages/dplyr/vignettes/rowwise.html","code":"\nlinelist <- linelist %>%\n  rowwise() %>%\n  mutate(num_symptoms = sum(c(fever, chills, cough, aches, vomit) == \"yes\"))"},{"path":"cleaning-data.html","id":"transformations-across-multiple-columns","chapter":"1 Cleaning data","heading":"1.15 Transformations across multiple columns","text":"Often write concise code want apply transformation multiple columns . transformation can applied multiple variables using across() function package dplyr (contained within tidyverse package).across() can used dplyr verb, commonly mutate(), filter(), summarise().\r\nacross() allows specify columns want function apply . specify columns, can name indvidually, use helped functions.transformation .character() applied specific columns named within across(). Note functions across() written without parentheses ( )helpers available assist specifying columns:everything() - columns mentionedlast_col() - last columnwhere() - applies function columns selects TRUEstarts_with() - matches specified prefix. Example: select(starts_with(\"date\"))ends_with() - matches specified suffix. Example: select(ends_with(\"_end\"))contains() - columns containing character string. Example: select(contains(\"time\"))matches() - apply regular expression (regex). Example: select(contains(\"[pt]al\"))num_range() -any_of() - matches column named. Useful name might exist. Example: select(any_of(date_onset, date_death, cardiac_arrest))example one change columns character class:Columns name contains string “date” (note placement commas parentheses):, want mutate columns class POSIXct (datetime class shows timestamps) - function .POSIXct() evaluates TRUE. want apply function .Date() column convert class Date.Note within across() also use function ()Note .POSIXct package lubridate. similar functions (.character(), .numeric(), .logical()) base RHere online resources using across(): creator Hadley Wickham’s thoughts/rationale","code":"\nlinelist <- linelist %>% \n  mutate(across(c(temp, ht_cm, wt_kg), as.character))\n#to change all columns to character class\nlinelist <- linelist %>% \n  mutate(across(everything(), as.character))\n#to change all columns to character class\nlinelist <- linelist %>% \n  mutate(across(contains(\"date\"), as.character))\nlinelist <- linelist %>% \n  mutate(across(where(lubridate::is.POSIXct), as.Date))## [1] \"2014-04-17\"## [1] \"2014-04-19\""}]
