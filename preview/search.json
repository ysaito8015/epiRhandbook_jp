[{"path":"index.html","id":"section","chapter":"","heading":"","text":"DRAFT. REVIEWERS GIVE FEEDBACK LINK.LIKE HANDBOOK? SOMETHING CHANGED? PLEASE TELL US!","code":""},{"path":"index.html","id":"about-this-handbook","chapter":"","heading":"About this handbook","text":"Epi R Handbook R reference manual applied epidemiology public health.book strives :Serve quick R code reference manualProvide task-centered examples addressing common epidemiologic problemsAssist epidemiologists transitioning R SAS, STATA, SPSS, ExcelBe accessible settings low internet-connectivity via offline version ([instructions ][Download handbook data])different R books?written epidemiologists, epidemiologists - leveraging experience local, national, academic, emergency settingsIt provides examples epidemic curves, transmission chains, automated reports dashboards, epidemic modeling projections, demographic pyramids standardization, record matching, outbreak detection, survey analysis, causal diagrams, survival analysis, GIS basics, phylogenetic trees, etc…","code":""},{"path":"index.html","id":"how-to-read-this-handbook","chapter":"","heading":"How to read this handbook","text":"Online versionSearch via search box Table ContentsClick “copy” icons copy codeSee “Resources” section page resources“Follow-along” [downloading example data][Download handbook data]Adjust font size browser zoom settingsOffline versionSee instructions download offline version handbook [Download book data] page.LanguagesWe seeking translate book languages English. can help, please contact us.","code":""},{"path":"index.html","id":"contact-us","chapter":"","heading":"Contact us","text":"Structured feedback formEmail us epiRhandbook@gmail.comSubmit issues pull requests Github repositoryTwitter handle @epirhandbook","code":""},{"path":"index.html","id":"acknowledgements","chapter":"","heading":"Acknowledgements","text":"handbook produced collaboration epidemiologists around world spare time, drawing upon experiences organizations including local, state/provincial, national health agencies, World Health Organization (), MSF (Médecins Sans Frontières / Doctors without Borders), hospital systems, academic institutions.handbook approved product specific organization. Although strive accuracy, provide guarantee content book.","code":""},{"path":"index.html","id":"contributors","chapter":"","heading":"Contributors","text":"Editor--Chief: Neale BatraProject core team: Neale Batra, Alex Spina, Amrish Baidjoe, Pat Keating, Henry Laurenson-Schafer, Finlay CampbellAuthors: Neale Batra, Alex Spina, Paula Blomquist, Finlay Campbell, Henry Laurenson-Schafer, Isaac Florence, Natalie Fischer, Aminata Ndiaye, Liza Coyer, Jonathan Polonsky, Yurie Izawa, Daniel Molling, Isha Berry, Chris Bailey, Emma Buajitti, Wen Lin, Sara HollisReviewers: Pat Keating, Mathilde Mousset, Annick Lenglet, Margot Charette, Isha Berry, Paula Blomquist, Natalie Fischer, Daniely Xavier, Esther Kukielka, Michelle Sloan, Aybüke Koyuncu, Rachel Burke, Daniel Molling, Kate Kelsey, Berhe Etsay, John Rossow, Mackenzie Zendt, James Wright, Wayne Enanoria, Flavio Finger, Tim Taylor, Jae Hyoung Tim Lee, Brianna Bradley, Manual Albela Miranda, Priscilla Spencer, Pattama Ulrich, Joseph Timothy, Olivia Varsaneux, Nienke Meeuwissen, Molly Mantus, Adam Vaughan, Lionel Monteiro, Joao MuiangaIllustrations: Calder Fong","code":""},{"path":"index.html","id":"funding-and-support","chapter":"","heading":"Funding and support","text":"handbook project received supportive funding via COVID-19 emergency capacity-building grant Training Programs Epidemiology Public Health Interventions Network (TEPHINET). handbook supported Cooperative Agreement number NU2GGH001873, funded Centers Disease Control Prevention TEPHINET, program Task Force Global Health. contents solely responsibility authors necessarily represent official views Centers Disease Control Prevention, Department Health Human Services, Task Force Global Health, Inc. TEPHINET.Administrative support provided EPIET Alumni Network (EAN), special thanks Annika Wendland. EPIET European Programme Intervention Epidemiology Training.","code":""},{"path":"index.html","id":"inspiration","chapter":"","heading":"Inspiration","text":"multitude tutorials vignettes provided knowledge development handbook content credited within respective pages.generally, following sources provided inspiration handbook:“R4Epis” project (collaboration MSF RECON)R Epidemics Consortium (RECON)R Data Science book (R4DS)bookdown: Authoring Books Technical Documents R MarkdownNetlify hosts website","code":""},{"path":"index.html","id":"terms-of-use-and-license","chapter":"","heading":"Terms of Use and License","text":"work licensed Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.Universities academic courses welcome use handbook students. questions intended use, email epirhandbook@gmail.com.","code":""},{"path":"import-and-export.html","id":"import-and-export","chapter":"1 Import and export","heading":"1 Import and export","text":"page describe ways locate, import, export files:Using rio package import() export() dataThe package locate files computer R projectSpecific import scenarios, \r\nExcel sheets\r\nGoogle sheets\r\nAPIs\r\nSkipping rows\r\nExcel sheetsGoogle sheetsAPIsSkipping rowsExporting/saving files","code":""},{"path":"import-and-export.html","id":"overview","chapter":"1 Import and export","heading":"1.1 Overview","text":"import “dataset” R, generally creating new data frame object R environment defining imported flat file (Excel, CSV, etc.). learn objects assignment operator, see page [R basics].","code":""},{"path":"import-and-export.html","id":"the-rio-package","chapter":"1 Import and export","heading":"1.2 The rio package","text":"R package recommend : rio. name “rio” abbreviation “R /O” (input/output). functions import() export() can handle many different file types (e.g. .xlsx, .csv, .rds, .tsv). provide file path either functions (including file extension like “.csv”), rio read extension use correct tool import export file.alternative using rio use functions many packages, specific type file. example, read.csv() (base R), read.xlsx() (openxlsx package), write_csv() (readr pacakge), etc. alternatives can difficult remember, whereas using import() export() rio easy.rio’s functions import() export() use appropriate package function given file, based file extension. See end page complete table packages/functions rio uses background. can also used import STATA, SAS, SPSS files, among dozens others.Import/export shapefiles requires packages, detailed page [GIS basics].","code":""},{"path":"import-and-export.html","id":"here","chapter":"1 Import and export","heading":"1.3 The here package","text":"package function () allow describe location files R project relation project’s root directory. useful R project may shared accessed multiple people/computers. prevents complications due unique file paths different computers (e.g. \"C:/Users/Laura/Documents...\" “starting” file path place common users (R project root).() works within R project:package first loaded within R project, places small file called “.” root folder R project “benchmark” “anchor”scripts, reference file R project’s sub-folders, use function () build file path relation anchorTo build file path, specify folders beyond root, within quotes, separated commas, finally ending file name file extension shown belowhere() file paths can used importing exportingFor example, , function import() provided file path constructed ().command (\"data\", \"linelists\", \"ebola_linelist.xlsx\") actually providing full file path unique user’s computer:“C:/Users/Laura/Documents/my_R_project/data/linelists/ebola_linelist.xlsx”beauty R command using () can successfully run computer accessing R project.TIP: unsure “.” root set , run function () empty parentheses.Read package link.","code":"\nlinelist <- import(here(\"data\", \"linelists\", \"ebola_linelist.xlsx\"))"},{"path":"import-and-export.html","id":"file-paths","chapter":"1 Import and export","heading":"1.4 File paths","text":"importing exporting data, must provide file path. can one three ways:Recommended: provide “relative” file path packageProvide “full” / “absolute” file pathManual file selection","code":""},{"path":"import-and-export.html","id":"relative-file-paths","chapter":"1 Import and export","heading":"“Relative” file paths","text":"R, “relative” file paths consist file path relative root R project. allow simple file paths can work different computers (e.g. R project shared drive sent email). described , relative file paths enabled use package.example relative file path constructed () . assume work R project contains sub-folder “data” within subfolder “linelists”, .xlsx file interest.","code":"\nlinelist <- import(here(\"data\", \"linelists\", \"ebola_linelist.xlsx\"))"},{"path":"import-and-export.html","id":"absolute-file-paths","chapter":"1 Import and export","heading":"“Absolute” file paths","text":"Absolute “full” file paths can provided functions like import() “fragile” unique user’s specific computer therefore recommended.example absolute file path, Laura’s computer R project “my_R_project” home/root folder analysis. sub-folder “data” within subfolder “linelists”, .xlsx file.things note absolute file paths:Avoid using absolute file paths break script run different computerUse forward slashes (/), example (note: default Windows file paths)File paths begin double slashes (e.g. “//…”) likely recognized R produce error. Consider moving work “named” “lettered” drive begins letter (e.g. “J:” “C:”). See page [Directory interactions] details issue.One scenario absolute file paths may appropriate want import file shared drive distant R project.TIP: quickly convert \\ /, highlight code interest, use Ctrl+f (Windows), check option box “selection”, use replace functionality convert .","code":"\nlinelist <- import(\"C:/Users/Laura/Documents/my_R_project/data/linelists/ebola_linelist.xlsx\")"},{"path":"import-and-export.html","id":"select-file-manually","chapter":"1 Import and export","heading":"Select file manually","text":"can import data manually via one methods:Environment RStudio Pane, click “Import Dataset”, select type dataClick File / Import Dataset / (select type data)hard-code manual selection, use base R command file.choose() (leaving parentheses empty) trigger appearance pop-window allows user manually select file computer. example:TIP: pop-window may appear BEHIND RStudio window.","code":"\n# Manual selection of a file. When this command is run, a POP-UP window will appear. \n# The file path selected will be supplied to the import() command.\n\nmy_data <- import(file.choose())"},{"path":"import-and-export.html","id":"import-data","chapter":"1 Import and export","heading":"1.5 Import data","text":"use import() import dataset quite simple. Simply provide path file (including file name file extension) quotes. using () build file path, follow instructions . examples:Importing csv file located “working directory” R project root folder:Importing Excel workbook located “data” “linelists” sub-folders R project (file path built using ()):Importing data (.rds file) using absolute file path (recommended):","code":"\nlinelist <- import(\"linelist_cleaned.csv\")\nlinelist <- import(here(\"data\", \"linelists\", \"linelist_cleaned.xlsx\"))\nlinelist <- import(\"C:/Users/Laura/Documents/tuberculosis/data/linelists/linelist_cleaned.rds\")"},{"path":"import-and-export.html","id":"specific-excel-sheets","chapter":"1 Import and export","heading":"1.5.1 Specific Excel sheets","text":"default, provide Excel workbook (.xlsx) import(), workbook’s first sheet imported. want import specific sheet, include sheet name = argument. example:using () method provide relative pathway import(), can still indicate specific sheet adding = argument closing parentheses () function.export data frame R specific Excel sheet rest Excel workbook remain unchanged, import, edit, export alternative package catered purpose openxlsx. See information page [Directory interactions] github page.Excel workbook .xlsb (binary format Excel workbook) may able import using rio. Consider re-saving .xlsx, using package like readxlsb built purpose.","code":"\nmy_data <- import(\"my_excel_file.xlsx\", which = \"Sheetname\")# Demonstration: importing a specific Excel sheet when using relative pathways with the 'here' package\r\nlinelist_raw <- import(here(\"data\", \"linelist.xlsx\"), which = \"Sheet1\")`  "},{"path":"import-and-export.html","id":"missing-values","chapter":"1 Import and export","heading":"1.5.2 Missing values","text":"may want designate value(s) dataset considered missing. explained page [Missing data], value R missing data NA, perhaps dataset want import uses 99, “Missing”, just empty character space \"\" instead.Use na = argument import() provide value(s) within quotes (even numbers). can specify multiple values including within vector, using c() shown ., value “99” imported dataset considered missing converted NA R., values “Missing”, \"\" (empty cell), \" \" (single space) imported dataset converted NA R.","code":"\nlinelist <- import(here(\"data\", \"my_linelist.xlsx\"), na = \"99\")\nlinelist <- import(here(\"data\", \"my_linelist.csv\"), na = c(\"Missing\", \"\", \" \"))"},{"path":"import-and-export.html","id":"google-sheets","chapter":"1 Import and export","heading":"1.5.3 Google sheets","text":"can import data online Google spreadsheet googlesheet4 package authenticating access spreadsheet., demo Google sheet imported saved. command may prompt confirmation authentification Google account. Follow prompts pop-ups internet browser grant Tidyverse API packages permissions edit, create, delete spreadsheets Google Drive.sheet “viewable anyone link” can try import .sheet can also imported using sheet ID, shorter part URL:Another package, googledrive offers useful functions writing, editing, deleting Google sheets. example, using gs4_create() sheet_write() functions found package.helpful online tutorials:basic importing tutorialmore detailinteraction two packages","code":"\npacman::p_load(\"googlesheets4\")\nGsheets_demo <- read_sheet(\"https://docs.google.com/spreadsheets/d/1scgtzkVLLHAe5a6_eFQEwkZcc14yFUx1KgOMZ4AKUfY/edit#gid=0\")\nGsheets_demo <- read_sheet(\"1scgtzkVLLHAe5a6_eFQEwkZcc14yFUx1KgOMZ4AKUfY\")"},{"path":"import-and-export.html","id":"skip-rows","chapter":"1 Import and export","heading":"1.5.4 Skip rows","text":"Sometimes, may want avoid importing row data. can argument skip = using import() rio .xlsx .csv file. Provide number rows want skip.Unfortunately skip = accepts one integer value, range (e.g. “2:10” work). skip import specific rows consecutive top, consider importing multiple times using bind_rows() dplyr. See example skipping row 2.","code":"\nlinelist_raw <- import(\"linelist_raw.xlsx\", skip = 1)  # does not import header row"},{"path":"import-and-export.html","id":"remove-second-header-row","chapter":"1 Import and export","heading":"Remove second header row","text":"Sometimes, data may second row want remove, example “data dictionary” row shown . situation can problematic can result columns imported class “character”.example kind dataset (first row data dictionary).solve , likely need import data twice.Import data order store correct column namesImport data , skipping first two rows (header second rows)Bind correct names onto reduced dataframeThe exact argument used bind correct column names depends type data file (.csv, .tsv, .xlsx, etc.). rio using different function different file types (see table ).Excel files: (col_names =)CSV files: (col.names =)Backup option - changing column names separate command","code":"\n# import first time; store the column names\nlinelist_raw_names <- import(\"linelist_raw.xlsx\") %>% names()  # save true column names\n\n# import second time; skip row 2, and assign column names to argument col_names =\nlinelist_raw <- import(\"linelist_raw.xlsx\",\n                       skip = 2,\n                       col_names = linelist_raw_names\n                       ) \n# import first time; sotre column names\nlinelist_raw_names <- import(\"linelist_raw.csv\") %>% names() # save true column names\n\n# note argument for csv files is 'col.names = '\nlinelist_raw <- import(\"linelist_raw.csv\",\n                       skip = 2,\n                       col.names = linelist_raw_names\n                       ) \n# assign/overwrite headers using the base 'colnames()' function\ncolnames(linelist_raw) <- linelist_raw_names"},{"path":"import-and-export.html","id":"make-a-data-dictionary","chapter":"1 Import and export","heading":"Make a data dictionary","text":"Bonus! second row data dictionary, can easily create proper data dictionary . tip adapted post.","code":"\ndict <- linelist_2headers %>%             # begin: linelist with dictionary as first row\n  head(1) %>%                             # keep only column names and first dictionary row                \n  pivot_longer(cols = everything(),       # pivot all columns to long format\n               names_to = \"Column\",       # assign new column names\n               values_to = \"Description\")"},{"path":"import-and-export.html","id":"combine-two-header-rows","chapter":"1 Import and export","heading":"Combine two header rows","text":"cases, may receive “messy” raw dataset two header rows. tenable analysis work, may want move values second header row first header row.command define column names combination (pasting together) first (true) headers value immediately underneath (first row).","code":"\nnames(my_data) <- paste(names(my_data), df[1, ], sep = \"_\")"},{"path":"import-and-export.html","id":"multiple-files---import-export-split-combine","chapter":"1 Import and export","heading":"1.6 Multiple files - import, export, split, combine","text":"See page [Iteration, loops, lists] examples import combine multiple files, multiple Excel workbook files. page also examples split data frame parts export one separately, named sheets Excel workbook.","code":""},{"path":"import-and-export.html","id":"import_github","chapter":"1 Import and export","heading":"1.7 Import from Github","text":"Importing data directly Github R can easy can require steps - depending file type. approaches:","code":""},{"path":"import-and-export.html","id":"csv-files","chapter":"1 Import and export","heading":"CSV files","text":"can easy import .csv file directly Github R R command.Go Github repo, locate file interest, click itClick “Raw” button (see “raw” csv data, shown )Copy URL (web address)Use URL import() R command, shown ","code":""},{"path":"import-and-export.html","id":"xlsx-files","chapter":"1 Import and export","heading":"XLSX files","text":"may able view “Raw” data files (e.g. .xlsx, .rds, .nwk, .shp)Go Github repo, locate file interest, click itClick “Download” button, shown belowSave file computer, import R","code":""},{"path":"import-and-export.html","id":"shapefiles","chapter":"1 Import and export","heading":"Shapefiles","text":"Shapefiles many sub-component files, different file extention. One file “.shp” extension, others may “.dbf”, “.prj”, etc. download shapefile Github, need download sub-component files individually, save folder computer. Github, click file individually download clicking “Download” button.saved computer can import shapefile shown [GIS basics] page using st_read() sf package. need provide filepath name “.shp” file - long related files within folder computer., can see shapefile “sle_adm3” consists many files - must downloaded Github.","code":""},{"path":"import-and-export.html","id":"apis","chapter":"1 Import and export","heading":"1.8 APIs","text":"“Automated Programming Interface” (API) can used directly request data website. APIs set rules allow one software application interact another. client () sends “request” receives “response” containing content. R packages httr jsonlite can facilitate process.API-enabled website documentation specifics become familiar . sites publicly available can accessed anyone. Others, platforms user IDs credentials, require authentication access data.Needless say, necessary internet connection import data via API. briefly give examples use APIs import data, link resources.Note: recall data may posted* website without API, may easier retrieve. example posted CSV file may accessible simply providing site URL import() described section importing Github.*","code":""},{"path":"import-and-export.html","id":"http-request","chapter":"1 Import and export","heading":"HTTP request","text":"API exchange commonly done HTTP request. HTTP Hypertext Transfer Protocol, underlying format request/response client server. exact input output may vary depending type API process - “Request” (often HTTP Request) user, often containing query, followed “Response”, containing status information request possibly requested content.components HTTP request:URL API endpointThe “Method” (“Verb”)HeadersBodyThe HTTP request “method” action want perform. two common HTTP methods GET POST others include PUT, DELETE, PATCH, etc. importing data R likely use GET.request, computer receive “response” format similar sent, including URL, HTTP status (Status 200 want!), file type, size, desired content. need parse response turn workable data frame within R environment.","code":""},{"path":"import-and-export.html","id":"packages","chapter":"1 Import and export","heading":"Packages","text":"httr package works well handling HTTP requests R. requires little prior knowledge Web APIs can used people less familiar software development terminology. addition, HTTP response .json, can use jsonlite parse response.","code":"\n# load packages\npacman::p_load(httr, jsonlite, tidyverse)"},{"path":"import-and-export.html","id":"publicly-available-data","chapter":"1 Import and export","heading":"Publicly-available data","text":"example HTTP request, borrowed tutorial Trafford Data Lab. site several resources learn API exercises.Scenario: want import list fast food outlets city Trafford, UK. data can accessed API Food Standards Agency, provides food hygiene rating data United Kingdom.parameters request:HTTP verb: GETAPI endpoint URL: http://api.ratings.food.gov.uk/EstablishmentsSelected parameters: name, address, longitude, latitude, businessTypeId, ratingKey, localAuthorityIdHeaders: “x-api-version”, 2Data format(s): JSON, XMLDocumentation: http://api.ratings.food.gov.uk/helpThe R code follows:can now clean use response data frame, contains one row per fast food facility.","code":"\n# prepare the request\npath <- \"http://api.ratings.food.gov.uk/Establishments\"\nrequest <- GET(url = path,\n             query = list(\n               localAuthorityId = 188,\n               BusinessTypeId = 7844,\n               pageNumber = 1,\n               pageSize = 5000),\n             add_headers(\"x-api-version\" = \"2\"))\n\n# check for any server error (\"200\" is good!)\nrequest$status_code\n\n# submit the request, parse the response, and convert to a data frame\nresponse <- content(request, as = \"text\", encoding = \"UTF-8\") %>%\n  fromJSON(flatten = TRUE) %>%\n  pluck(\"establishments\") %>%\n  as_tibble()"},{"path":"import-and-export.html","id":"authentication-required","chapter":"1 Import and export","heading":"Authentication required","text":"APIs require authentication - prove , can access restricted data. import data, may need first use POST method provide username, password, code. return access token, can used subsequent GET method requests retrieve desired data.example querying data Go.Data, outbreak investigation tool. Go.Data uses API interactions web front-end smartphone applications used data collection. Go.Data used throughout world. outbreak data sensitive able access data outbreak, authentication required.sample R code using httr jsonlite connecting Go.Data API import data contact follow-outbreak.CAUTION: importing large amounts data API requiring authentication, may time-. avoid , retrieve access_token API GET request try using filters limits query. TIP: fromJSON() function jsonlite package fully un-nest first time ’s executed, likely still list items resulting tibble. need un-nest certain variables; depending nested .json . view info , view documentation jsonlite package, flatten() function. details, View documentation LoopBack Explorer, [Contact Tracing] page API tips Go.Data Github repositoryYou can read httr package hereThis section also informed tutorial tutorial.","code":"\n# set credentials for authorization\nurl <- \"https://godatasampleURL.int/\"           # valid Go.Data instance url\nusername <- \"username\"                          # valid Go.Data username \npassword <- \"password\"                          # valid Go,Data password \noutbreak_id <- \"xxxxxx-xxxx-xxxx-xxxx-xxxxxxx\"  # valid Go.Data outbreak ID\n\n# get access token\nurl_request <- paste0(url,\"api/oauth/token?access_token=123\") # define base URL request\n\n# prepare request\nresponse <- POST(\n  url = url_request,  \n  body = list(\n    username = username,    # use saved username/password from above to authorize                               \n    password = password),                                       \n    encode = \"json\")\n\n# execute request and parse response\ncontent <-\n  content(response, as = \"text\") %>%\n  fromJSON(flatten = TRUE) %>%          # flatten nested JSON\n  glimpse()\n\n# Save access token from response\naccess_token <- content$access_token    # save access token to allow subsequent API calls below\n\n# import outbreak contacts\n# Use the access token \nresponse_contacts <- GET(\n  paste0(url,\"api/outbreaks/\",outbreak_id,\"/contacts\"),          # GET request\n  add_headers(\n    Authorization = paste(\"Bearer\", access_token, sep = \" \")))\n\njson_contacts <- content(response_contacts, as = \"text\")         # convert to text JSON\n\ncontacts <- as_tibble(fromJSON(json_contacts, flatten = TRUE))   # flatten JSON to tibble"},{"path":"import-and-export.html","id":"manual-data-entry","chapter":"1 Import and export","heading":"1.9 Manual data entry","text":"","code":""},{"path":"import-and-export.html","id":"entry-by-rows","chapter":"1 Import and export","heading":"Entry by rows","text":"Use tribble function tibble package tidyverse (online tibble reference).Note column headers start tilde (~). Also note column must contain one class data (character, numeric, etc.). can use tabs, spacing, new rows make data entry intuitive readable. Spaces matter values, row represented new line code. example:now display new dataset:","code":"\n# create the dataset manually by row\nmanual_entry_rows <- tibble::tribble(\n  ~colA, ~colB,\n  \"a\",   1,\n  \"b\",   2,\n  \"c\",   3\n  )"},{"path":"import-and-export.html","id":"entry-by-columns","chapter":"1 Import and export","heading":"Entry by columns","text":"Since data frame consists vectors (vertical columns), base approach manual dataframe creation R expects define column bind together. can counter-intuitive epidemiology, usually think data rows ().CAUTION: vectors must length (number values).vectors can bound together using function data.frame():now display new dataset:","code":"\n# define each vector (vertical column) separately, each with its own name\nPatientID <- c(235, 452, 778, 111)\nTreatment <- c(\"Yes\", \"No\", \"Yes\", \"Yes\")\nDeath     <- c(1, 0, 1, 0)\n# combine the columns into a data frame, by referencing the vector names\nmanual_entry_cols <- data.frame(PatientID, Treatment, Death)"},{"path":"import-and-export.html","id":"pasting-from-clipboard","chapter":"1 Import and export","heading":"Pasting from clipboard","text":"copy data elsewhere clipboard, can try one two ways :clipr package, can use read_clip_tbl() import data frame, just just read_clip() import character vector. cases, leave parentheses empty.can also easily export system’s clipboard clipr. See section Export.Alternatively, can use read.table() function base R file = \"clipboard\") import data frame:","code":"\nlinelist <- clipr::read_clip_tbl()  # imports current clipboard as data frame\nlinelist <- clipr::read_clip()      # imports as character vector\ndf_from_clipboard <- read.table(\n  file = \"clipboard\",  # specify this as \"clipboard\"\n  sep = \"t\",           # separator could be tab, or commas, etc.\n  header=TRUE)         # if there is a header row"},{"path":"import-and-export.html","id":"import-most-recent-file","chapter":"1 Import and export","heading":"1.10 Import most recent file","text":"Often may receive daily updates datasets. case want write code imports recent file. present two ways approach :Selecting file based date file nameSelecting file based file metadata (last modification)","code":""},{"path":"import-and-export.html","id":"dates-in-file-name","chapter":"1 Import and export","heading":"Dates in file name","text":"approach depends three premises:trust dates file namesThe dates numeric appear generally format (e.g. year month day)numbers file nameWe explain step, show combined end. First, use dir() base R extract just file names file folder interest. See page [Directory interactions] details dir(). example, folder interest folder “linelists” within folder “example” within “data” within R project.vector names, can extract dates applying str_extract() stringr using regular expression. extracts numbers file name (including characters middle dashes slashes). can read stringr [Strings characters] page.Assuming dates written date general format (e.g. Year Month Day) can use lubridate’s flexible ymd() function (dmy() mdy()) convert dates. functions, dashes, spaces, slashes matter, order numbers. Read [Working dates].base R function .max() can used return index position (e.g. 1st, 2nd, 3rd, …) maximum date value. latest file correctly identified 6th file - “case_linelist_2020-10-08.xlsx”.condense commands, complete code look like . Note . last line placeholder piped object point pipe sequence. point value simply number 6. placed double brackets extract 6th element vector file names produced dir().can now use name finish relative file path, ():can now import latest file:","code":"\nlinelist_filenames <- dir(here(\"data\", \"example\", \"linelists\")) # get file names from folder\nlinelist_filenames                                              # print## [1] \"20201007linelist.csv\"          \"case_linelist_2020-10-02.csv\"  \"case_linelist_2020-10-03.csv\" \r\n## [4] \"case_linelist_2020-10-04.csv\"  \"case_linelist_2020-10-05.csv\"  \"case_linelist_2020-10-08.xlsx\"\r\n## [7] \"case_linelist20201006.csv\"\nlinelist_dates_raw <- stringr::str_extract(linelist_filenames, \"[0-9].*[0-9]\") # extract numbers and any characters in between\nlinelist_dates_raw  # print## [1] \"20201007\"   \"2020-10-02\" \"2020-10-03\" \"2020-10-04\" \"2020-10-05\" \"2020-10-08\" \"20201006\"\nlinelist_dates_clean <- lubridate::ymd(linelist_dates_raw)\nlinelist_dates_clean## [1] \"2020-10-07\" \"2020-10-02\" \"2020-10-03\" \"2020-10-04\" \"2020-10-05\" \"2020-10-08\" \"2020-10-06\"\nindex_latest_file <- which.max(linelist_dates_clean)\nindex_latest_file## [1] 6\n# load packages\npacman::p_load(\n  tidyverse,         # data management\n  stringr,           # work with strings/characters\n  lubridate,         # work with dates\n  rio,               # import / export\n  here,              # relative file paths\n  fs)                # directory interactions\n\n# extract the file name of latest file\nlatest_file <- dir(here(\"data\", \"example\", \"linelists\")) %>%  # file names from \"linelists\" sub-folder          \n  str_extract(\"[0-9].*[0-9]\") %>%                  # pull out dates (numbers)\n  ymd() %>%                                        # convert numbers to dates (assuming year-month-day format)\n  which.max() %>%                                  # get index of max date (latest file)\n  dir(here(\"data\", \"example\", \"linelists\"))[[.]]              # return the filename of latest linelist\n\nlatest_file  # print name of latest file## [1] \"case_linelist_2020-10-08.xlsx\"\nhere(\"data\", \"example\", \"linelists\", latest_file) ## [1] \"C:/Users/Neale/OneDrive - Neale Batra/Documents/Analytic Software/R/Projects/R handbook/Epi_R_handbook/data/example/linelists/case_linelist_2020-10-08.xlsx\"\n# import\nimport(here(\"data\", \"example\", \"linelists\", latest_file)) # import "},{"path":"import-and-export.html","id":"use-the-file-info","chapter":"1 Import and export","heading":"Use the file info","text":"files dates names (trust dates), can try extract last modification date file metadata. Use functions package fs examine metadata information file, includes last modification time file path., provide folder interest fs’s dir_info(). case, folder interest R project folder “data”, sub-folder “example”, sub-folder “linelists”. result data frame one line per file columns modification_time, path, etc. can see visual example page [Directory interactions].can sort data frame files column modification_time, keep top/latest row (file) base R’s head(). can extract file path latest file dplyr function pull() column path. Finally can pass file path import(). imported file saved latest_file.","code":"\nlatest_file <- dir_info(here(\"data\", \"example\", \"linelists\")) %>%  # collect file info on all files in directory\n  arrange(desc(modification_time)) %>%      # sort by modification time\n  head(1) %>%                               # keep only the top (latest) file\n  pull(path) %>%                            # extract only the file path\n  import()                                  # import the file"},{"path":"import-and-export.html","id":"export","chapter":"1 Import and export","heading":"1.11 Export","text":"","code":""},{"path":"import-and-export.html","id":"with-rio-package","chapter":"1 Import and export","heading":"With rio package","text":"rio, can use export() function similar way import(). First give name R object want save (e.g. linelist) quotes put file path including name file extension. example:save dataframe .csv, folder specified relative pathway:","code":"\nexport(linelist, \"my_linelist.xlsx\") # will save to working directoryexport(linelist, here(\"data\",\"clean\", \"my_linelist.csv\")"},{"path":"import-and-export.html","id":"to-clipboard","chapter":"1 Import and export","heading":"To clipboard","text":"export data frame computer’s “clipboard” (paste another software like Excel, Google Spreadsheets, etc.) can use write_clip() clipr package.","code":"\n# export the linelist data frame to your system's clipboard\nclipr::write_clip(linelist)"},{"path":"import-and-export.html","id":"rds-files","chapter":"1 Import and export","heading":"1.12 RDS files","text":"Along .csv, .xlsx, etc, can also export/save R data frames .rds files. file format specific R, useful know work exported data R.classes columns stored, don’t cleaning imported (Excel even CSV file can headache!). also smaller file, useful export import dataset large.example, work Epi team need send files GIS team mapping, use R well, just send .rds file! column classes retained less work .","code":"export(linelist, here(\"data\",\"clean\", \"my_linelist.rds\")"},{"path":"import-and-export.html","id":"rdata-files","chapter":"1 Import and export","heading":"1.13 Rdata files","text":".Rdata files store R objects, can actually store multiple R objects within one file, example multiple dataframes, model results, lists, etc. can useful consolidate share lot data given project.example, multiple R objects stored within exported file “my_objects.Rdata”:Note: trying import list, use import_list() rio import complete original structure contents.","code":"\nrio::export(my_list, my_dataframe, my_vector, \"my_objects.Rdata\")\nrio::import_list(\"my_list.Rdata\")"},{"path":"import-and-export.html","id":"saving-plots","chapter":"1 Import and export","heading":"1.14 Saving plots","text":"save plots, created ggplot() discussed depth [ggplot tips] page.brief, run ggsave(\"my_plot_filepath_and_name.png\") printing plot. can either provide saved plot object plot = argument, specify destination file path (file extension) save recently-displayed plot. can also control width =, height =, units =, dpi =.save network graph, transmission tree, addressed page [Transmission chains].","code":""},{"path":"import-and-export.html","id":"resources","chapter":"1 Import and export","heading":"1.15 Resources","text":"R Data Import/Export ManualR 4 Data Science chapterggsaveBelow table, taken rio online vignette. type data shows: expected file extension, package rio uses import export data, whether functionality included default installed version rio.","code":""}]
